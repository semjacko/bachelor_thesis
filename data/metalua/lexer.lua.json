{
  "_filename": "lexer.lua",
  "_isShebang": false,
  "_isSpec": false,
  "_isTest": false,
  "_path": "modules/metalua/src/compiler/lexer.lua",
  "edges": [ {
    "from": 0,
    "label": "implements",
    "to": 1
  }, {
    "from": 3,
    "label": "has",
    "to": 4
  }, {
    "from": 4,
    "label": "has",
    "to": 5
  }, {
    "from": 5,
    "label": "has",
    "to": 6
  }, {
    "from": 4,
    "label": "has",
    "to": 7
  }, {
    "from": 4,
    "label": "has",
    "to": 8
  }, {
    "from": 4,
    "label": "has",
    "to": 9
  }, {
    "from": 4,
    "label": "has",
    "to": 10
  }, {
    "from": 4,
    "label": "has",
    "to": 11
  }, {
    "from": 11,
    "label": "has",
    "to": 12
  }, {
    "from": 4,
    "label": "has",
    "to": 7
  }, {
    "from": 3,
    "label": "has",
    "to": 13
  }, {
    "from": 13,
    "label": "has",
    "to": 14
  }, {
    "from": 13,
    "label": "has",
    "to": 7
  }, {
    "from": 3,
    "label": "has",
    "to": 7
  }, {
    "from": 3,
    "label": "has",
    "to": 15
  }, {
    "from": 16,
    "label": "has",
    "to": 5
  }, {
    "from": 5,
    "label": "has",
    "to": 6
  }, {
    "from": 16,
    "label": "has",
    "to": 7
  }, {
    "from": 16,
    "label": "has",
    "to": 8
  }, {
    "from": 16,
    "label": "has",
    "to": 9
  }, {
    "from": 16,
    "label": "has",
    "to": 10
  }, {
    "from": 16,
    "label": "has",
    "to": 11
  }, {
    "from": 11,
    "label": "has",
    "to": 12
  }, {
    "from": 16,
    "label": "has",
    "to": 7
  }, {
    "from": 16,
    "label": "has",
    "to": 17
  }, {
    "from": 18,
    "label": "has",
    "to": 14
  }, {
    "from": 18,
    "label": "has",
    "to": 7
  }, {
    "from": 18,
    "label": "has",
    "to": 19
  }, {
    "from": 20,
    "label": "has",
    "to": 21
  }, {
    "from": 20,
    "label": "has",
    "to": 22
  }, {
    "from": 20,
    "label": "has",
    "to": 23
  }, {
    "from": 20,
    "label": "has",
    "to": 24
  }, {
    "from": 24,
    "label": "has",
    "to": 25
  }, {
    "from": 24,
    "label": "has",
    "to": 26
  }, {
    "from": 24,
    "label": "has",
    "to": 27
  }, {
    "from": 27,
    "label": "has",
    "to": 28
  }, {
    "from": 27,
    "label": "has",
    "to": 29
  }, {
    "from": 27,
    "label": "has",
    "to": 30
  }, {
    "from": 27,
    "label": "has",
    "to": 31
  }, {
    "from": 31,
    "label": "has",
    "to": 32
  }, {
    "from": 31,
    "label": "has",
    "to": 33
  }, {
    "from": 27,
    "label": "has",
    "to": 34
  }, {
    "from": 27,
    "label": "has",
    "to": 35
  }, {
    "from": 24,
    "label": "has",
    "to": 36
  }, {
    "from": 24,
    "label": "has",
    "to": 37
  }, {
    "from": 24,
    "label": "has",
    "to": 38
  }, {
    "from": 24,
    "label": "has",
    "to": 39
  }, {
    "from": 24,
    "label": "has",
    "to": 40
  }, {
    "from": 24,
    "label": "has",
    "to": 41
  }, {
    "from": 41,
    "label": "has",
    "to": 42
  }, {
    "from": 24,
    "label": "has",
    "to": 43
  }, {
    "from": 43,
    "label": "has",
    "to": 44
  }, {
    "from": 43,
    "label": "has",
    "to": 45
  }, {
    "from": 43,
    "label": "has",
    "to": 46
  }, {
    "from": 46,
    "label": "has",
    "to": 47
  }, {
    "from": 24,
    "label": "has",
    "to": 48
  }, {
    "from": 24,
    "label": "has",
    "to": 7
  }, {
    "from": 20,
    "label": "has",
    "to": 49
  }, {
    "from": 49,
    "label": "has",
    "to": 50
  }, {
    "from": 49,
    "label": "has",
    "to": 51
  }, {
    "from": 51,
    "label": "has",
    "to": 52
  }, {
    "from": 49,
    "label": "has",
    "to": 53
  }, {
    "from": 20,
    "label": "has",
    "to": 7
  }, {
    "from": 20,
    "label": "has",
    "to": 54
  }, {
    "from": 20,
    "label": "has",
    "to": 55
  }, {
    "from": 56,
    "label": "has",
    "to": 25
  }, {
    "from": 56,
    "label": "has",
    "to": 26
  }, {
    "from": 56,
    "label": "has",
    "to": 27
  }, {
    "from": 27,
    "label": "has",
    "to": 28
  }, {
    "from": 27,
    "label": "has",
    "to": 29
  }, {
    "from": 27,
    "label": "has",
    "to": 30
  }, {
    "from": 27,
    "label": "has",
    "to": 31
  }, {
    "from": 31,
    "label": "has",
    "to": 32
  }, {
    "from": 31,
    "label": "has",
    "to": 33
  }, {
    "from": 27,
    "label": "has",
    "to": 34
  }, {
    "from": 27,
    "label": "has",
    "to": 35
  }, {
    "from": 56,
    "label": "has",
    "to": 36
  }, {
    "from": 56,
    "label": "has",
    "to": 37
  }, {
    "from": 56,
    "label": "has",
    "to": 38
  }, {
    "from": 56,
    "label": "has",
    "to": 39
  }, {
    "from": 56,
    "label": "has",
    "to": 40
  }, {
    "from": 56,
    "label": "has",
    "to": 41
  }, {
    "from": 41,
    "label": "has",
    "to": 42
  }, {
    "from": 56,
    "label": "has",
    "to": 43
  }, {
    "from": 43,
    "label": "has",
    "to": 44
  }, {
    "from": 43,
    "label": "has",
    "to": 45
  }, {
    "from": 43,
    "label": "has",
    "to": 46
  }, {
    "from": 46,
    "label": "has",
    "to": 47
  }, {
    "from": 56,
    "label": "has",
    "to": 48
  }, {
    "from": 56,
    "label": "has",
    "to": 7
  }, {
    "from": 56,
    "label": "has",
    "to": 57
  }, {
    "from": 58,
    "label": "has",
    "to": 59
  }, {
    "from": 58,
    "label": "has",
    "to": 60
  }, {
    "from": 60,
    "label": "has",
    "to": 61
  }, {
    "from": 60,
    "label": "has",
    "to": 62
  }, {
    "from": 60,
    "label": "has",
    "to": 63
  }, {
    "from": 60,
    "label": "has",
    "to": 64
  }, {
    "from": 60,
    "label": "has",
    "to": 65
  }, {
    "from": 60,
    "label": "has",
    "to": 66
  }, {
    "from": 66,
    "label": "has",
    "to": 67
  }, {
    "from": 66,
    "label": "has",
    "to": 68
  }, {
    "from": 66,
    "label": "has",
    "to": 69
  }, {
    "from": 60,
    "label": "has",
    "to": 70
  }, {
    "from": 60,
    "label": "has",
    "to": 71
  }, {
    "from": 71,
    "label": "has",
    "to": 72
  }, {
    "from": 71,
    "label": "has",
    "to": 68
  }, {
    "from": 71,
    "label": "has",
    "to": 69
  }, {
    "from": 60,
    "label": "has",
    "to": 73
  }, {
    "from": 58,
    "label": "has",
    "to": 7
  }, {
    "from": 58,
    "label": "has",
    "to": 74
  }, {
    "from": 58,
    "label": "has",
    "to": 7
  }, {
    "from": 58,
    "label": "has",
    "to": 7
  }, {
    "from": 58,
    "label": "has",
    "to": 75
  }, {
    "from": 76,
    "label": "has",
    "to": 77
  }, {
    "from": 76,
    "label": "has",
    "to": 78
  }, {
    "from": 76,
    "label": "has",
    "to": 7
  }, {
    "from": 76,
    "label": "has",
    "to": 79
  }, {
    "from": 76,
    "label": "has",
    "to": 80
  }, {
    "from": 76,
    "label": "has",
    "to": 81
  }, {
    "from": 81,
    "label": "has",
    "to": 82
  }, {
    "from": 81,
    "label": "has",
    "to": 83
  }, {
    "from": 81,
    "label": "has",
    "to": 84
  }, {
    "from": 84,
    "label": "has",
    "to": 85
  }, {
    "from": 84,
    "label": "has",
    "to": 86
  }, {
    "from": 84,
    "label": "has",
    "to": 87
  }, {
    "from": 76,
    "label": "has",
    "to": 88
  }, {
    "from": 76,
    "label": "has",
    "to": 7
  }, {
    "from": 76,
    "label": "has",
    "to": 89
  }, {
    "from": 90,
    "label": "has",
    "to": 91
  }, {
    "from": 90,
    "label": "has",
    "to": 92
  }, {
    "from": 92,
    "label": "has",
    "to": 88
  }, {
    "from": 92,
    "label": "has",
    "to": 93
  }, {
    "from": 90,
    "label": "has",
    "to": 7
  }, {
    "from": 90,
    "label": "has",
    "to": 7
  }, {
    "from": 90,
    "label": "has",
    "to": 94
  }, {
    "from": 95,
    "label": "has",
    "to": 96
  }, {
    "from": 95,
    "label": "has",
    "to": 97
  }, {
    "from": 97,
    "label": "has",
    "to": 98
  }, {
    "from": 97,
    "label": "has",
    "to": 99
  }, {
    "from": 99,
    "label": "has",
    "to": 100
  }, {
    "from": 95,
    "label": "has",
    "to": 101
  }, {
    "from": 95,
    "label": "has",
    "to": 7
  }, {
    "from": 95,
    "label": "has",
    "to": 102
  }, {
    "from": 95,
    "label": "has",
    "to": 88
  }, {
    "from": 95,
    "label": "has",
    "to": 7
  }, {
    "from": 95,
    "label": "has",
    "to": 103
  }, {
    "from": 104,
    "label": "has",
    "to": 105
  }, {
    "from": 104,
    "label": "has",
    "to": 106
  }, {
    "from": 106,
    "label": "has",
    "to": 88
  }, {
    "from": 104,
    "label": "has",
    "to": 7
  }, {
    "from": 104,
    "label": "has",
    "to": 107
  }, {
    "from": 108,
    "label": "has",
    "to": 109
  }, {
    "from": 108,
    "label": "has",
    "to": 110
  }, {
    "from": 108,
    "label": "has",
    "to": 111
  }, {
    "from": 111,
    "label": "has",
    "to": 112
  }, {
    "from": 108,
    "label": "has",
    "to": 7
  }, {
    "from": 108,
    "label": "has",
    "to": 113
  }, {
    "from": 113,
    "label": "has",
    "to": 114
  }, {
    "from": 114,
    "label": "has",
    "to": 115
  }, {
    "from": 108,
    "label": "has",
    "to": 7
  }, {
    "from": 108,
    "label": "has",
    "to": 116
  }, {
    "from": 108,
    "label": "has",
    "to": 7
  }, {
    "from": 108,
    "label": "has",
    "to": 117
  }, {
    "from": 118,
    "label": "has",
    "to": 119
  }, {
    "from": 118,
    "label": "has",
    "to": 120
  }, {
    "from": 120,
    "label": "has",
    "to": 121
  }, {
    "from": 121,
    "label": "has",
    "to": 122
  }, {
    "from": 120,
    "label": "has",
    "to": 123
  }, {
    "from": 123,
    "label": "has",
    "to": 124
  }, {
    "from": 123,
    "label": "has",
    "to": 125
  }, {
    "from": 123,
    "label": "has",
    "to": 126
  }, {
    "from": 123,
    "label": "has",
    "to": 127
  }, {
    "from": 127,
    "label": "has",
    "to": 128
  }, {
    "from": 127,
    "label": "has",
    "to": 129
  }, {
    "from": 123,
    "label": "has",
    "to": 130
  }, {
    "from": 123,
    "label": "has",
    "to": 131
  }, {
    "from": 118,
    "label": "has",
    "to": 7
  }, {
    "from": 118,
    "label": "has",
    "to": 132
  }, {
    "from": 133,
    "label": "has",
    "to": 134
  }, {
    "from": 134,
    "label": "has",
    "to": 135
  }, {
    "from": 133,
    "label": "has",
    "to": 136
  }, {
    "from": 136,
    "label": "has",
    "to": 137
  }, {
    "from": 137,
    "label": "has",
    "to": 138
  }, {
    "from": 133,
    "label": "has",
    "to": 7
  }, {
    "from": 133,
    "label": "has",
    "to": 139
  }, {
    "from": 140,
    "label": "has",
    "to": 141
  }, {
    "from": 140,
    "label": "has",
    "to": 142
  }, {
    "from": 140,
    "label": "has",
    "to": 143
  }, {
    "from": 140,
    "label": "has",
    "to": 144
  }, {
    "from": 144,
    "label": "has",
    "to": 145
  }, {
    "from": 144,
    "label": "has",
    "to": 146
  }, {
    "from": 144,
    "label": "has",
    "to": 147
  }, {
    "from": 140,
    "label": "has",
    "to": 148
  }, {
    "from": 140,
    "label": "has",
    "to": 7
  }, {
    "from": 140,
    "label": "has",
    "to": 149
  }, {
    "from": 150,
    "label": "has",
    "to": 7
  }, {
    "from": 151,
    "label": "has",
    "to": 152
  }, {
    "from": 151,
    "label": "has",
    "to": 153
  }, {
    "from": 154,
    "label": "has",
    "to": 155
  }, {
    "from": 154,
    "label": "has",
    "to": 156
  }, {
    "from": 156,
    "label": "has",
    "to": 157
  }, {
    "from": 156,
    "label": "has",
    "to": 158
  }, {
    "from": 156,
    "label": "has",
    "to": 159
  }, {
    "from": 156,
    "label": "has",
    "to": 160
  }, {
    "from": 156,
    "label": "has",
    "to": 161
  }, {
    "from": 154,
    "label": "has",
    "to": 162
  }, {
    "from": 163,
    "label": "has",
    "to": 164
  }, {
    "from": 163,
    "label": "has",
    "to": 165
  }, {
    "from": 163,
    "label": "has",
    "to": 7
  }, {
    "from": 163,
    "label": "has",
    "to": 166
  }, {
    "from": 167,
    "label": "has",
    "to": 7
  }, {
    "from": 167,
    "label": "has",
    "to": 168
  }, {
    "from": 169,
    "label": "has",
    "to": 7
  }, {
    "from": 169,
    "label": "has",
    "to": 170
  }, {
    "from": 171,
    "label": "has",
    "to": 172
  }, {
    "from": 171,
    "label": "has",
    "to": 173
  }, {
    "from": 173,
    "label": "has",
    "to": 174
  }, {
    "from": 173,
    "label": "has",
    "to": 175
  }, {
    "from": 173,
    "label": "has",
    "to": 176
  }, {
    "from": 173,
    "label": "has",
    "to": 177
  }, {
    "from": 177,
    "label": "has",
    "to": 178
  }, {
    "from": 173,
    "label": "has",
    "to": 179
  }, {
    "from": 171,
    "label": "has",
    "to": 7
  }, {
    "from": 171,
    "label": "has",
    "to": 7
  }, {
    "from": 171,
    "label": "has",
    "to": 180
  }, {
    "from": 181,
    "label": "has",
    "to": 182
  }, {
    "from": 181,
    "label": "has",
    "to": 7
  }, {
    "from": 181,
    "label": "has",
    "to": 183
  }, {
    "from": 181,
    "label": "has",
    "to": 184
  }, {
    "from": 181,
    "label": "has",
    "to": 7
  }, {
    "from": 181,
    "label": "has",
    "to": 185
  }, {
    "from": 185,
    "label": "has",
    "to": 186
  }, {
    "from": 181,
    "label": "has",
    "to": 7
  }, {
    "from": 181,
    "label": "has",
    "to": 7
  }, {
    "from": 181,
    "label": "has",
    "to": 187
  }, {
    "from": 188,
    "label": "has",
    "to": 183
  }, {
    "from": 188,
    "label": "has",
    "to": 189
  }, {
    "from": 188,
    "label": "has",
    "to": 190
  }, {
    "from": 190,
    "label": "has",
    "to": 191
  }, {
    "from": 188,
    "label": "has",
    "to": 192
  }, {
    "from": 192,
    "label": "has",
    "to": 193
  }, {
    "from": 188,
    "label": "has",
    "to": 184
  }, {
    "from": 188,
    "label": "has",
    "to": 7
  }, {
    "from": 188,
    "label": "has",
    "to": 194
  }, {
    "from": 194,
    "label": "has",
    "to": 186
  }, {
    "from": 188,
    "label": "has",
    "to": 7
  }, {
    "from": 188,
    "label": "has",
    "to": 193
  }, {
    "from": 188,
    "label": "has",
    "to": 195
  }, {
    "from": 196,
    "label": "has",
    "to": 191
  }, {
    "from": 196,
    "label": "has",
    "to": 197
  }, {
    "from": 198,
    "label": "has",
    "to": 199
  }, {
    "from": 198,
    "label": "has",
    "to": 200
  }, {
    "from": 198,
    "label": "has",
    "to": 201
  }, {
    "from": 198,
    "label": "has",
    "to": 7
  }, {
    "from": 198,
    "label": "has",
    "to": 202
  }, {
    "from": 140,
    "label": "calls",
    "to": 216
  }, {
    "from": 56,
    "label": "calls",
    "to": 210
  }, {
    "from": 76,
    "label": "calls",
    "to": 210
  }, {
    "from": 118,
    "label": "calls",
    "to": 210
  }, {
    "from": 171,
    "label": "calls",
    "to": 210
  }, {
    "from": 108,
    "label": "calls",
    "to": 219
  }, {
    "from": 3,
    "label": "calls",
    "to": 209
  }, {
    "from": 118,
    "label": "calls",
    "to": 217
  }, {
    "from": 95,
    "label": "calls",
    "to": 211
  }, {
    "from": 20,
    "label": "calls",
    "to": 208
  }, {
    "from": 196,
    "label": "calls",
    "to": 214
  }, {
    "from": 58,
    "label": "calls",
    "to": 212
  }, {
    "from": 58,
    "label": "calls",
    "to": 212
  }, {
    "from": 198,
    "label": "calls",
    "to": 206
  }, {
    "from": 198,
    "label": "calls",
    "to": 206
  }, {
    "from": 76,
    "label": "calls",
    "to": 3
  }, {
    "from": 20,
    "label": "calls",
    "to": 56
  }, {
    "from": 3,
    "label": "calls",
    "to": 218
  }, {
    "from": 3,
    "label": "calls",
    "to": 218
  }, {
    "from": 20,
    "label": "calls",
    "to": 218
  }, {
    "from": 76,
    "label": "calls",
    "to": 218
  }, {
    "from": 118,
    "label": "calls",
    "to": 218
  }, {
    "from": 196,
    "label": "calls",
    "to": 218
  }, {
    "from": 20,
    "label": "calls",
    "to": 205
  }, {
    "from": 118,
    "label": "calls",
    "to": 205
  }, {
    "from": 181,
    "label": "calls",
    "to": 205
  }, {
    "from": 188,
    "label": "calls",
    "to": 205
  }, {
    "from": 203,
    "label": "calls",
    "to": 221
  }, {
    "from": 56,
    "label": "calls",
    "to": 220
  }, {
    "from": 56,
    "label": "calls",
    "to": 220
  }, {
    "from": 56,
    "label": "calls",
    "to": 220
  }, {
    "from": 171,
    "label": "calls",
    "to": 220
  }, {
    "from": 171,
    "label": "calls",
    "to": 220
  }, {
    "from": 198,
    "label": "calls",
    "to": 220
  }, {
    "from": 3,
    "label": "calls",
    "to": 215
  }, {
    "from": 188,
    "label": "calls",
    "to": 196
  }, {
    "from": 188,
    "label": "calls",
    "to": 196
  }, {
    "from": 118,
    "label": "calls",
    "to": 207
  }, {
    "from": 171,
    "label": "calls",
    "to": 207
  }, {
    "from": 171,
    "label": "calls",
    "to": 207
  }, {
    "from": 171,
    "label": "calls",
    "to": 207
  }, {
    "from": 203,
    "label": "calls",
    "to": 222
  }, {
    "from": 196,
    "label": "calls",
    "to": 204
  }, {
    "from": 150,
    "label": "calls",
    "to": 213
  }, {
    "from": 1,
    "label": "contains",
    "to": 203
  }, {
    "from": 203,
    "label": "declares",
    "to": 2
  }, {
    "from": 203,
    "label": "declares",
    "to": 3
  }, {
    "from": 203,
    "label": "declares",
    "to": 16
  }, {
    "from": 203,
    "label": "declares",
    "to": 18
  }, {
    "from": 203,
    "label": "declares",
    "to": 20
  }, {
    "from": 203,
    "label": "declares",
    "to": 56
  }, {
    "from": 203,
    "label": "declares",
    "to": 58
  }, {
    "from": 203,
    "label": "declares",
    "to": 76
  }, {
    "from": 203,
    "label": "declares",
    "to": 90
  }, {
    "from": 203,
    "label": "declares",
    "to": 95
  }, {
    "from": 203,
    "label": "declares",
    "to": 104
  }, {
    "from": 203,
    "label": "declares",
    "to": 108
  }, {
    "from": 203,
    "label": "declares",
    "to": 118
  }, {
    "from": 203,
    "label": "declares",
    "to": 133
  }, {
    "from": 203,
    "label": "declares",
    "to": 140
  }, {
    "from": 203,
    "label": "declares",
    "to": 150
  }, {
    "from": 203,
    "label": "declares",
    "to": 151
  }, {
    "from": 203,
    "label": "declares",
    "to": 154
  }, {
    "from": 203,
    "label": "declares",
    "to": 163
  }, {
    "from": 203,
    "label": "declares",
    "to": 167
  }, {
    "from": 203,
    "label": "declares",
    "to": 169
  }, {
    "from": 203,
    "label": "declares",
    "to": 171
  }, {
    "from": 203,
    "label": "declares",
    "to": 181
  }, {
    "from": 203,
    "label": "declares",
    "to": 188
  }, {
    "from": 203,
    "label": "declares",
    "to": 196
  }, {
    "from": 203,
    "label": "declares",
    "to": 198
  }, {
    "from": 1,
    "label": "contains",
    "to": 224
  }, {
    "from": 1,
    "label": "contains",
    "to": 225
  }, {
    "from": 224,
    "label": "initializes",
    "to": 226
  }, {
    "from": 226,
    "label": "assigns",
    "to": 227
  }, {
    "from": 224,
    "label": "initializes",
    "to": 228
  }, {
    "from": 228,
    "label": "assigns",
    "to": 229
  }, {
    "from": 224,
    "label": "initializes",
    "to": 230
  }, {
    "from": 230,
    "label": "assigns",
    "to": 231
  }, {
    "from": 224,
    "label": "initializes",
    "to": 232
  }, {
    "from": 232,
    "label": "assigns",
    "to": 233
  }, {
    "from": 224,
    "label": "initializes",
    "to": 234
  }, {
    "from": 234,
    "label": "assigns",
    "to": 235
  }, {
    "from": 224,
    "label": "initializes",
    "to": 236
  }, {
    "from": 236,
    "label": "assigns",
    "to": 237
  }, {
    "from": 224,
    "label": "initializes",
    "to": 238
  }, {
    "from": 238,
    "label": "assigns",
    "to": 239
  }, {
    "from": 225,
    "label": "initializes",
    "to": 223
  }, {
    "from": 223,
    "label": "requires",
    "to": 1
  } ],
  "nodes": [ {
    "id": 0,
    "text": "",
    "type": "file"
  }, {
    "id": 1,
    "text": "lexer",
    "type": "module"
  }, {
    "id": 2,
    "text": "function() end",
    "type": "function"
  }, {
    "id": 3,
    "text": "local function unescape_string (s)\r\n\r\n   -- Turn the digits of an escape sequence into the corresponding\r\n   -- character, e.g. [unesc_digits(\"123\") == string.char(123)].\r\n   local function unesc_digits (backslashes, digits)\r\n      if #backslashes%2==0 then\r\n         -- Even number of backslashes, they escape each other, not the digits.\r\n         -- Return them so that unesc_letter() can treaat them\r\n         return backslashes..digits\r\n      else\r\n         -- Remove the odd backslash, which escapes the number sequence.\r\n         -- The rest will be returned and parsed by unesc_letter()\r\n         backslashes = backslashes :sub (1,-2)\r\n      end\r\n      local k, j, i = digits:reverse():byte(1, 3)\r\n      local z = _G.string.byte \"0\"\r\n      local code = (k or z) + 10*(j or z) + 100*(i or z) - 111*z\r\n      if code > 255 then \r\n      \t error (\"Illegal escape sequence '\\\\\"..digits..\r\n                \"' in string: ASCII codes must be in [0..255]\") \r\n      end\r\n      return backslashes .. string.char (code)\r\n   end\r\n\r\n   -- Take a letter [x], and returns the character represented by the \r\n   -- sequence ['\\\\'..x], e.g. [unesc_letter \"n\" == \"\\n\"].\r\n   local function unesc_letter(x)\r\n      local t = { \r\n         a = \"\\a\", b = \"\\b\", f = \"\\f\",\r\n         n = \"\\n\", r = \"\\r\", t = \"\\t\", v = \"\\v\",\r\n         [\"\\\\\"] = \"\\\\\", [\"'\"] = \"'\", ['\"'] = '\"', [\"\\n\"] = \"\\n\" }\r\n      return t[x] or error([[Unknown escape sequence '\\]]..x..[[']])\r\n   end\r\n\r\n   return s\r\n      :gsub (\"(\\\\+)([0-9][0-9]?[0-9]?)\", unesc_digits)\r\n      :gsub (\"\\\\(%D)\",unesc_letter)\r\nend",
    "type": "function"
  }, {
    "id": 4,
    "text": "local function unesc_digits (backslashes, digits)\r\n      if #backslashes%2==0 then\r\n         -- Even number of backslashes, they escape each other, not the digits.\r\n         -- Return them so that unesc_letter() can treaat them\r\n         return backslashes..digits\r\n      else\r\n         -- Remove the odd backslash, which escapes the number sequence.\r\n         -- The rest will be returned and parsed by unesc_letter()\r\n         backslashes = backslashes :sub (1,-2)\r\n      end\r\n      local k, j, i = digits:reverse():byte(1, 3)\r\n      local z = _G.string.byte \"0\"\r\n      local code = (k or z) + 10*(j or z) + 100*(i or z) - 111*z\r\n      if code > 255 then \r\n      \t error (\"Illegal escape sequence '\\\\\"..digits..\r\n                \"' in string: ASCII codes must be in [0..255]\") \r\n      end\r\n      return backslashes .. string.char (code)\r\n   end",
    "type": "statement:localfunction"
  }, {
    "id": 5,
    "text": "if #backslashes%2==0 then\r\n         -- Even number of backslashes, they escape each other, not the digits.\r\n         -- Return them so that unesc_letter() can treaat them\r\n         return backslashes..digits\r\n      else\r\n         -- Remove the odd backslash, which escapes the number sequence.\r\n         -- The rest will be returned and parsed by unesc_letter()\r\n         backslashes = backslashes :sub (1,-2)\r\n      end",
    "type": "statement:if"
  }, {
    "id": 6,
    "text": "backslashes = backslashes :sub (1,-2)",
    "type": "statement:assign"
  }, {
    "id": 7,
    "text": "return",
    "type": "statement:keyword"
  }, {
    "id": 8,
    "text": "local k, j, i = digits:reverse():byte(1, 3)",
    "type": "statement:localassign"
  }, {
    "id": 9,
    "text": "local z = _G.string.byte \"0\"",
    "type": "statement:localassign"
  }, {
    "id": 10,
    "text": "local code = (k or z) + 10*(j or z) + 100*(i or z) - 111*z",
    "type": "statement:localassign"
  }, {
    "id": 11,
    "text": "if code > 255 then \r\n      \t error (\"Illegal escape sequence '\\\\\"..digits..\r\n                \"' in string: ASCII codes must be in [0..255]\") \r\n      end",
    "type": "statement:if"
  }, {
    "id": 12,
    "text": "error (\"Illegal escape sequence '\\\\\"..digits..\r\n                \"' in string: ASCII codes must be in [0..255]\")",
    "type": "statement:functioncall"
  }, {
    "id": 13,
    "text": "local function unesc_letter(x)\r\n      local t = { \r\n         a = \"\\a\", b = \"\\b\", f = \"\\f\",\r\n         n = \"\\n\", r = \"\\r\", t = \"\\t\", v = \"\\v\",\r\n         [\"\\\\\"] = \"\\\\\", [\"'\"] = \"'\", ['\"'] = '\"', [\"\\n\"] = \"\\n\" }\r\n      return t[x] or error([[Unknown escape sequence '\\]]..x..[[']])\r\n   end",
    "type": "statement:localfunction"
  }, {
    "id": 14,
    "text": "local t = { \r\n         a = \"\\a\", b = \"\\b\", f = \"\\f\",\r\n         n = \"\\n\", r = \"\\r\", t = \"\\t\", v = \"\\v\",\r\n         [\"\\\\\"] = \"\\\\\", [\"'\"] = \"'\", ['\"'] = '\"', [\"\\n\"] = \"\\n\" }",
    "type": "statement:localassign"
  }, {
    "id": 15,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 16,
    "text": "local function unesc_digits (backslashes, digits)\r\n      if #backslashes%2==0 then\r\n         -- Even number of backslashes, they escape each other, not the digits.\r\n         -- Return them so that unesc_letter() can treaat them\r\n         return backslashes..digits\r\n      else\r\n         -- Remove the odd backslash, which escapes the number sequence.\r\n         -- The rest will be returned and parsed by unesc_letter()\r\n         backslashes = backslashes :sub (1,-2)\r\n      end\r\n      local k, j, i = digits:reverse():byte(1, 3)\r\n      local z = _G.string.byte \"0\"\r\n      local code = (k or z) + 10*(j or z) + 100*(i or z) - 111*z\r\n      if code > 255 then \r\n      \t error (\"Illegal escape sequence '\\\\\"..digits..\r\n                \"' in string: ASCII codes must be in [0..255]\") \r\n      end\r\n      return backslashes .. string.char (code)\r\n   end",
    "type": "function"
  }, {
    "id": 17,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 18,
    "text": "local function unesc_letter(x)\r\n      local t = { \r\n         a = \"\\a\", b = \"\\b\", f = \"\\f\",\r\n         n = \"\\n\", r = \"\\r\", t = \"\\t\", v = \"\\v\",\r\n         [\"\\\\\"] = \"\\\\\", [\"'\"] = \"'\", ['\"'] = '\"', [\"\\n\"] = \"\\n\" }\r\n      return t[x] or error([[Unknown escape sequence '\\]]..x..[[']])\r\n   end",
    "type": "function"
  }, {
    "id": 19,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 20,
    "text": "function lexer:extract ()\r\n   local previous_i = self.i\r\n   local loc = self.i\r\n   local eof, token\r\n\r\n   -- Put line info, comments and metatable around the tag and content\r\n   -- provided by extractors, thus returning a complete lexer token.\r\n   -- first_line: line # at the beginning of token\r\n   -- first_column_offset: char # of the last '\\n' before beginning of token\r\n   -- i: scans from beginning of prefix spaces/comments to end of token.\r\n   local function build_token (tag, content)\r\n      assert (tag and content)\r\n      local i, first_line, first_column_offset, previous_line_length =\r\n         previous_i, self.line, self.column_offset, nil\r\n\r\n      -- update self.line and first_line. i := indexes of '\\n' chars\r\n      while true do\r\n         i = self.src :find (\"\\n\", i+1, true)\r\n         if not i or i>self.i then break end -- no more '\\n' until end of token\r\n         previous_line_length = i - self.column_offset\r\n         if loc and i <= loc then -- '\\n' before beginning of token\r\n            first_column_offset = i\r\n            first_line = first_line+1 \r\n         end\r\n         self.line   = self.line+1 \r\n         self.column_offset = i \r\n      end\r\n\r\n      -- lineinfo entries: [1]=line, [2]=column, [3]=char, [4]=filename\r\n      local fli = { first_line, loc-first_column_offset, loc, self.src_name }\r\n      local lli = { self.line, self.i-self.column_offset-1, self.i-1, self.src_name }\r\n      --Pluto barfes when the metatable is set:(\r\n      setmetatable(fli, lexer.lineinfo_metatable)\r\n      setmetatable(lli, lexer.lineinfo_metatable)\r\n      local a = { tag = tag, lineinfo = { first=fli, last=lli }, content } \r\n      if lli[2]==-1 then lli[1], lli[2] = lli[1]-1, previous_line_length-1 end\r\n      if #self.attached_comments > 0 then \r\n         a.lineinfo.comments = self.attached_comments \r\n         fli.comments = self.attached_comments\r\n         if self.lineinfo_last then\r\n            self.lineinfo_last.comments = self.attached_comments\r\n         end\r\n      end\r\n      self.attached_comments = { }\r\n      return setmetatable (a, self.token_metatable)\r\n   end --</function build_token>\r\n\r\n   for ext_idx, extractor in ipairs(self.extractors) do\r\n      -- printf(\"method = %s\", method)\r\n      local tag, content = self [extractor] (self)\r\n      -- [loc] is placed just after the leading whitespaces and comments;\r\n      -- for this to work, the whitespace extractor *must be* at index 1.\r\n      if ext_idx==1 then loc = self.i end\r\n\r\n      if tag then \r\n         --printf(\"`%s{ %q }\\t%i\", tag, content, loc);\r\n         return build_token (tag, content) \r\n      end\r\n   end\r\n\r\n   error \"None of the lexer extractors returned anything!\"\r\nend",
    "type": "function"
  }, {
    "id": 21,
    "text": "local previous_i = self.i",
    "type": "statement:localassign"
  }, {
    "id": 22,
    "text": "local loc = self.i",
    "type": "statement:localassign"
  }, {
    "id": 23,
    "text": "local eof, token",
    "type": "statement:localassign"
  }, {
    "id": 24,
    "text": "local function build_token (tag, content)\r\n      assert (tag and content)\r\n      local i, first_line, first_column_offset, previous_line_length =\r\n         previous_i, self.line, self.column_offset, nil\r\n\r\n      -- update self.line and first_line. i := indexes of '\\n' chars\r\n      while true do\r\n         i = self.src :find (\"\\n\", i+1, true)\r\n         if not i or i>self.i then break end -- no more '\\n' until end of token\r\n         previous_line_length = i - self.column_offset\r\n         if loc and i <= loc then -- '\\n' before beginning of token\r\n            first_column_offset = i\r\n            first_line = first_line+1 \r\n         end\r\n         self.line   = self.line+1 \r\n         self.column_offset = i \r\n      end\r\n\r\n      -- lineinfo entries: [1]=line, [2]=column, [3]=char, [4]=filename\r\n      local fli = { first_line, loc-first_column_offset, loc, self.src_name }\r\n      local lli = { self.line, self.i-self.column_offset-1, self.i-1, self.src_name }\r\n      --Pluto barfes when the metatable is set:(\r\n      setmetatable(fli, lexer.lineinfo_metatable)\r\n      setmetatable(lli, lexer.lineinfo_metatable)\r\n      local a = { tag = tag, lineinfo = { first=fli, last=lli }, content } \r\n      if lli[2]==-1 then lli[1], lli[2] = lli[1]-1, previous_line_length-1 end\r\n      if #self.attached_comments > 0 then \r\n         a.lineinfo.comments = self.attached_comments \r\n         fli.comments = self.attached_comments\r\n         if self.lineinfo_last then\r\n            self.lineinfo_last.comments = self.attached_comments\r\n         end\r\n      end\r\n      self.attached_comments = { }\r\n      return setmetatable (a, self.token_metatable)\r\n   end",
    "type": "statement:localfunction"
  }, {
    "id": 25,
    "text": "assert (tag and content)",
    "type": "statement:functioncall"
  }, {
    "id": 26,
    "text": "local i, first_line, first_column_offset, previous_line_length =\r\n         previous_i, self.line, self.column_offset, nil",
    "type": "statement:localassign"
  }, {
    "id": 27,
    "text": "while true do\r\n         i = self.src :find (\"\\n\", i+1, true)\r\n         if not i or i>self.i then break end -- no more '\\n' until end of token\r\n         previous_line_length = i - self.column_offset\r\n         if loc and i <= loc then -- '\\n' before beginning of token\r\n            first_column_offset = i\r\n            first_line = first_line+1 \r\n         end\r\n         self.line   = self.line+1 \r\n         self.column_offset = i \r\n      end",
    "type": "statement:while"
  }, {
    "id": 28,
    "text": "i = self.src :find (\"\\n\", i+1, true)",
    "type": "statement:assign"
  }, {
    "id": 29,
    "text": "if not i or i>self.i then break end",
    "type": "statement:if"
  }, {
    "id": 30,
    "text": "previous_line_length = i - self.column_offset",
    "type": "statement:assign"
  }, {
    "id": 31,
    "text": "if loc and i <= loc then -- '\\n' before beginning of token\r\n            first_column_offset = i\r\n            first_line = first_line+1 \r\n         end",
    "type": "statement:if"
  }, {
    "id": 32,
    "text": "first_column_offset = i",
    "type": "statement:assign"
  }, {
    "id": 33,
    "text": "first_line = first_line+1",
    "type": "statement:assign"
  }, {
    "id": 34,
    "text": "self.line   = self.line+1",
    "type": "statement:assign"
  }, {
    "id": 35,
    "text": "self.column_offset = i",
    "type": "statement:assign"
  }, {
    "id": 36,
    "text": "local fli = { first_line, loc-first_column_offset, loc, self.src_name }",
    "type": "statement:localassign"
  }, {
    "id": 37,
    "text": "local lli = { self.line, self.i-self.column_offset-1, self.i-1, self.src_name }",
    "type": "statement:localassign"
  }, {
    "id": 38,
    "text": "setmetatable(fli, lexer.lineinfo_metatable)",
    "type": "statement:functioncall"
  }, {
    "id": 39,
    "text": "setmetatable(lli, lexer.lineinfo_metatable)",
    "type": "statement:functioncall"
  }, {
    "id": 40,
    "text": "local a = { tag = tag, lineinfo = { first=fli, last=lli }, content }",
    "type": "statement:localassign"
  }, {
    "id": 41,
    "text": "if lli[2]==-1 then lli[1], lli[2] = lli[1]-1, previous_line_length-1 end",
    "type": "statement:if"
  }, {
    "id": 42,
    "text": "lli[1], lli[2] = lli[1]-1, previous_line_length-1",
    "type": "statement:assign"
  }, {
    "id": 43,
    "text": "if #self.attached_comments > 0 then \r\n         a.lineinfo.comments = self.attached_comments \r\n         fli.comments = self.attached_comments\r\n         if self.lineinfo_last then\r\n            self.lineinfo_last.comments = self.attached_comments\r\n         end\r\n      end",
    "type": "statement:if"
  }, {
    "id": 44,
    "text": "a.lineinfo.comments = self.attached_comments",
    "type": "statement:assign"
  }, {
    "id": 45,
    "text": "fli.comments = self.attached_comments",
    "type": "statement:assign"
  }, {
    "id": 46,
    "text": "if self.lineinfo_last then\r\n            self.lineinfo_last.comments = self.attached_comments\r\n         end",
    "type": "statement:if"
  }, {
    "id": 47,
    "text": "self.lineinfo_last.comments = self.attached_comments",
    "type": "statement:assign"
  }, {
    "id": 48,
    "text": "self.attached_comments = { }",
    "type": "statement:assign"
  }, {
    "id": 49,
    "text": "for ext_idx, extractor in ipairs(self.extractors) do\r\n      -- printf(\"method = %s\", method)\r\n      local tag, content = self [extractor] (self)\r\n      -- [loc] is placed just after the leading whitespaces and comments;\r\n      -- for this to work, the whitespace extractor *must be* at index 1.\r\n      if ext_idx==1 then loc = self.i end\r\n\r\n      if tag then \r\n         --printf(\"`%s{ %q }\\t%i\", tag, content, loc);\r\n         return build_token (tag, content) \r\n      end\r\n   end",
    "type": "statement:genericfor"
  }, {
    "id": 50,
    "text": "local tag, content = self [extractor] (self)",
    "type": "statement:localassign"
  }, {
    "id": 51,
    "text": "if ext_idx==1 then loc = self.i end",
    "type": "statement:if"
  }, {
    "id": 52,
    "text": "loc = self.i",
    "type": "statement:assign"
  }, {
    "id": 53,
    "text": "if tag then \r\n         --printf(\"`%s{ %q }\\t%i\", tag, content, loc);\r\n         return build_token (tag, content) \r\n      end",
    "type": "statement:if"
  }, {
    "id": 54,
    "text": "error \"None of the lexer extractors returned anything!\"",
    "type": "statement:functioncall"
  }, {
    "id": 55,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 56,
    "text": "local function build_token (tag, content)\r\n      assert (tag and content)\r\n      local i, first_line, first_column_offset, previous_line_length =\r\n         previous_i, self.line, self.column_offset, nil\r\n\r\n      -- update self.line and first_line. i := indexes of '\\n' chars\r\n      while true do\r\n         i = self.src :find (\"\\n\", i+1, true)\r\n         if not i or i>self.i then break end -- no more '\\n' until end of token\r\n         previous_line_length = i - self.column_offset\r\n         if loc and i <= loc then -- '\\n' before beginning of token\r\n            first_column_offset = i\r\n            first_line = first_line+1 \r\n         end\r\n         self.line   = self.line+1 \r\n         self.column_offset = i \r\n      end\r\n\r\n      -- lineinfo entries: [1]=line, [2]=column, [3]=char, [4]=filename\r\n      local fli = { first_line, loc-first_column_offset, loc, self.src_name }\r\n      local lli = { self.line, self.i-self.column_offset-1, self.i-1, self.src_name }\r\n      --Pluto barfes when the metatable is set:(\r\n      setmetatable(fli, lexer.lineinfo_metatable)\r\n      setmetatable(lli, lexer.lineinfo_metatable)\r\n      local a = { tag = tag, lineinfo = { first=fli, last=lli }, content } \r\n      if lli[2]==-1 then lli[1], lli[2] = lli[1]-1, previous_line_length-1 end\r\n      if #self.attached_comments > 0 then \r\n         a.lineinfo.comments = self.attached_comments \r\n         fli.comments = self.attached_comments\r\n         if self.lineinfo_last then\r\n            self.lineinfo_last.comments = self.attached_comments\r\n         end\r\n      end\r\n      self.attached_comments = { }\r\n      return setmetatable (a, self.token_metatable)\r\n   end",
    "type": "function"
  }, {
    "id": 57,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 58,
    "text": "function lexer:skip_whitespaces_and_comments()\r\n   local table_insert = _G.table.insert\r\n   repeat -- loop as long as a space or comment chunk is found\r\n      local _, j\r\n      local again = false\r\n      local last_comment_content = nil\r\n      -- skip spaces\r\n      self.i = self.src:match (self.patterns.spaces, self.i)\r\n      -- skip a long comment if any\r\n      _, last_comment_content, j = \r\n         self.src :match (self.patterns.long_comment, self.i)\r\n      if j then \r\n         table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"long\"})\r\n         self.i=j; again=true \r\n      end\r\n      -- skip a short comment if any\r\n      last_comment_content, j = self.src:match (self.patterns.short_comment, self.i)\r\n      if j then\r\n         table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"short\"})\r\n         self.i=j; again=true \r\n      end\r\n      if self.i>#self.src then return \"Eof\", \"eof\" end\r\n   until not again\r\n\r\n   if self.src:match (self.patterns.final_short_comment, self.i) then \r\n      return \"Eof\", \"eof\" end\r\n   --assert (not self.src:match(self.patterns.short_comment, self.i))\r\n   --assert (not self.src:match(self.patterns.long_comment, self.i))\r\n   -- --assert (not self.src:match(self.patterns.spaces, self.i))\r\n   return\r\nend",
    "type": "function"
  }, {
    "id": 59,
    "text": "local table_insert = _G.table.insert",
    "type": "statement:localassign"
  }, {
    "id": 60,
    "text": "repeat -- loop as long as a space or comment chunk is found\r\n      local _, j\r\n      local again = false\r\n      local last_comment_content = nil\r\n      -- skip spaces\r\n      self.i = self.src:match (self.patterns.spaces, self.i)\r\n      -- skip a long comment if any\r\n      _, last_comment_content, j = \r\n         self.src :match (self.patterns.long_comment, self.i)\r\n      if j then \r\n         table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"long\"})\r\n         self.i=j; again=true \r\n      end\r\n      -- skip a short comment if any\r\n      last_comment_content, j = self.src:match (self.patterns.short_comment, self.i)\r\n      if j then\r\n         table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"short\"})\r\n         self.i=j; again=true \r\n      end\r\n      if self.i>#self.src then return \"Eof\", \"eof\" end\r\n   until not again",
    "type": "statement:repeat"
  }, {
    "id": 61,
    "text": "local _, j",
    "type": "statement:localassign"
  }, {
    "id": 62,
    "text": "local again = false",
    "type": "statement:localassign"
  }, {
    "id": 63,
    "text": "local last_comment_content = nil",
    "type": "statement:localassign"
  }, {
    "id": 64,
    "text": "self.i = self.src:match (self.patterns.spaces, self.i)",
    "type": "statement:assign"
  }, {
    "id": 65,
    "text": "_, last_comment_content, j = \r\n         self.src :match (self.patterns.long_comment, self.i)",
    "type": "statement:assign"
  }, {
    "id": 66,
    "text": "if j then \r\n         table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"long\"})\r\n         self.i=j; again=true \r\n      end",
    "type": "statement:if"
  }, {
    "id": 67,
    "text": "table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"long\"})",
    "type": "statement:functioncall"
  }, {
    "id": 68,
    "text": "self.i=j",
    "type": "statement:assign"
  }, {
    "id": 69,
    "text": "again=true",
    "type": "statement:assign"
  }, {
    "id": 70,
    "text": "last_comment_content, j = self.src:match (self.patterns.short_comment, self.i)",
    "type": "statement:assign"
  }, {
    "id": 71,
    "text": "if j then\r\n         table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"short\"})\r\n         self.i=j; again=true \r\n      end",
    "type": "statement:if"
  }, {
    "id": 72,
    "text": "table_insert(self.attached_comments, \r\n                         {last_comment_content, self.i, j, \"short\"})",
    "type": "statement:functioncall"
  }, {
    "id": 73,
    "text": "if self.i>#self.src then return \"Eof\", \"eof\" end",
    "type": "statement:if"
  }, {
    "id": 74,
    "text": "if self.src:match (self.patterns.final_short_comment, self.i) then \r\n      return \"Eof\", \"eof\" end",
    "type": "statement:if"
  }, {
    "id": 75,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 76,
    "text": "function lexer:extract_short_string()\r\n   -- [k] is the first unread char, [self.i] points to [k] in [self.src]\r\n   local j, k = self.i, self.src :sub (self.i,self.i)\r\n   if k~=\"'\" and k~='\"' then return end\r\n   local i = self.i + 1\r\n   local j = i\r\n   while true do\r\n      -- k = opening char: either simple-quote or double-quote\r\n      -- i = index of beginning-of-string\r\n      -- x = next \"interesting\" character\r\n      -- j = position after interesting char\r\n      -- y = char just after x\r\n      local x, y\r\n      x, j, y = self.src :match (\"([\\\\\\r\\n\"..k..\"])()(.?)\", j)\r\n      if x == '\\\\' then j=j+1  -- don't parse escaped char\r\n      elseif x == k then break -- unescaped end of string\r\n      else -- eof or '\\r' or '\\n' reached before end of string\r\n         assert (not x or x==\"\\r\" or x==\"\\n\")\r\n         error \"Unterminated string\"\r\n      end\r\n   end\r\n   self.i = j\r\n\r\n   return \"String\", unescape_string (self.src:sub (i,j-2))\r\nend",
    "type": "function"
  }, {
    "id": 77,
    "text": "local j, k = self.i, self.src :sub (self.i,self.i)",
    "type": "statement:localassign"
  }, {
    "id": 78,
    "text": "if k~=\"'\" and k~='\"' then return end",
    "type": "statement:if"
  }, {
    "id": 79,
    "text": "local i = self.i + 1",
    "type": "statement:localassign"
  }, {
    "id": 80,
    "text": "local j = i",
    "type": "statement:localassign"
  }, {
    "id": 81,
    "text": "while true do\r\n      -- k = opening char: either simple-quote or double-quote\r\n      -- i = index of beginning-of-string\r\n      -- x = next \"interesting\" character\r\n      -- j = position after interesting char\r\n      -- y = char just after x\r\n      local x, y\r\n      x, j, y = self.src :match (\"([\\\\\\r\\n\"..k..\"])()(.?)\", j)\r\n      if x == '\\\\' then j=j+1  -- don't parse escaped char\r\n      elseif x == k then break -- unescaped end of string\r\n      else -- eof or '\\r' or '\\n' reached before end of string\r\n         assert (not x or x==\"\\r\" or x==\"\\n\")\r\n         error \"Unterminated string\"\r\n      end\r\n   end",
    "type": "statement:while"
  }, {
    "id": 82,
    "text": "local x, y",
    "type": "statement:localassign"
  }, {
    "id": 83,
    "text": "x, j, y = self.src :match (\"([\\\\\\r\\n\"..k..\"])()(.?)\", j)",
    "type": "statement:assign"
  }, {
    "id": 84,
    "text": "if x == '\\\\' then j=j+1  -- don't parse escaped char\r\n      elseif x == k then break -- unescaped end of string\r\n      else -- eof or '\\r' or '\\n' reached before end of string\r\n         assert (not x or x==\"\\r\" or x==\"\\n\")\r\n         error \"Unterminated string\"\r\n      end",
    "type": "statement:if"
  }, {
    "id": 85,
    "text": "j=j+1",
    "type": "statement:assign"
  }, {
    "id": 86,
    "text": "assert (not x or x==\"\\r\" or x==\"\\n\")",
    "type": "statement:functioncall"
  }, {
    "id": 87,
    "text": "error \"Unterminated string\"",
    "type": "statement:functioncall"
  }, {
    "id": 88,
    "text": "self.i = j",
    "type": "statement:assign"
  }, {
    "id": 89,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 90,
    "text": "function lexer:extract_word()\r\n   -- Id / keyword\r\n   local word, j = self.src:match (self.patterns.word, self.i)\r\n   if word then\r\n      self.i = j\r\n      if self.alpha [word] then return \"Keyword\", word\r\n      else return \"Id\", word end\r\n   end\r\nend",
    "type": "function"
  }, {
    "id": 91,
    "text": "local word, j = self.src:match (self.patterns.word, self.i)",
    "type": "statement:localassign"
  }, {
    "id": 92,
    "text": "if word then\r\n      self.i = j\r\n      if self.alpha [word] then return \"Keyword\", word\r\n      else return \"Id\", word end\r\n   end",
    "type": "statement:if"
  }, {
    "id": 93,
    "text": "if self.alpha [word] then return \"Keyword\", word\r\n      else return \"Id\", word end",
    "type": "statement:if"
  }, {
    "id": 94,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 95,
    "text": "function lexer:extract_number()\r\n   -- Number\r\n   local j = self.src:match(self.patterns.number_hex, self.i)\r\n   if not j then\r\n      j = self.src:match (self.patterns.number_mantissa[1], self.i) or\r\n          self.src:match (self.patterns.number_mantissa[2], self.i)\r\n      if j then\r\n         j = self.src:match (self.patterns.number_exponant, j) or j;\r\n      end\r\n   end\r\n   if not j then return end\r\n   -- Number found, interpret with tonumber() and return it\r\n   local n = tonumber (self.src:sub (self.i, j-1))\r\n   self.i = j\r\n   return \"Number\", n\r\nend",
    "type": "function"
  }, {
    "id": 96,
    "text": "local j = self.src:match(self.patterns.number_hex, self.i)",
    "type": "statement:localassign"
  }, {
    "id": 97,
    "text": "if not j then\r\n      j = self.src:match (self.patterns.number_mantissa[1], self.i) or\r\n          self.src:match (self.patterns.number_mantissa[2], self.i)\r\n      if j then\r\n         j = self.src:match (self.patterns.number_exponant, j) or j;\r\n      end\r\n   end",
    "type": "statement:if"
  }, {
    "id": 98,
    "text": "j = self.src:match (self.patterns.number_mantissa[1], self.i) or\r\n          self.src:match (self.patterns.number_mantissa[2], self.i)",
    "type": "statement:assign"
  }, {
    "id": 99,
    "text": "if j then\r\n         j = self.src:match (self.patterns.number_exponant, j) or j;\r\n      end",
    "type": "statement:if"
  }, {
    "id": 100,
    "text": "j = self.src:match (self.patterns.number_exponant, j) or j",
    "type": "statement:assign"
  }, {
    "id": 101,
    "text": "if not j then return end",
    "type": "statement:if"
  }, {
    "id": 102,
    "text": "local n = tonumber (self.src:sub (self.i, j-1))",
    "type": "statement:localassign"
  }, {
    "id": 103,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 104,
    "text": "function lexer:extract_long_string()\r\n   -- Long string\r\n   local _, content, j = self.src:match (self.patterns.long_string, self.i)\r\n   if j then self.i = j; return \"String\", content end\r\nend",
    "type": "function"
  }, {
    "id": 105,
    "text": "local _, content, j = self.src:match (self.patterns.long_string, self.i)",
    "type": "statement:localassign"
  }, {
    "id": 106,
    "text": "if j then self.i = j; return \"String\", content end",
    "type": "statement:if"
  }, {
    "id": 107,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 108,
    "text": "function lexer:extract_symbol()\r\n   -- compound symbol\r\n   local k = self.src:sub (self.i,self.i)\r\n   local symk = self.sym [k]\r\n   if not symk then \r\n      self.i = self.i + 1\r\n      return \"Keyword\", k\r\n   end\r\n   for _, sym in pairs (symk) do\r\n      if sym == self.src:sub (self.i, self.i + #sym - 1) then \r\n         self.i = self.i + #sym; \r\n         return \"Keyword\", sym\r\n      end\r\n   end\r\n   -- single char symbol\r\n   self.i = self.i+1\r\n   return \"Keyword\", k\r\nend",
    "type": "function"
  }, {
    "id": 109,
    "text": "local k = self.src:sub (self.i,self.i)",
    "type": "statement:localassign"
  }, {
    "id": 110,
    "text": "local symk = self.sym [k]",
    "type": "statement:localassign"
  }, {
    "id": 111,
    "text": "if not symk then \r\n      self.i = self.i + 1\r\n      return \"Keyword\", k\r\n   end",
    "type": "statement:if"
  }, {
    "id": 112,
    "text": "self.i = self.i + 1",
    "type": "statement:assign"
  }, {
    "id": 113,
    "text": "for _, sym in pairs (symk) do\r\n      if sym == self.src:sub (self.i, self.i + #sym - 1) then \r\n         self.i = self.i + #sym; \r\n         return \"Keyword\", sym\r\n      end\r\n   end",
    "type": "statement:genericfor"
  }, {
    "id": 114,
    "text": "if sym == self.src:sub (self.i, self.i + #sym - 1) then \r\n         self.i = self.i + #sym; \r\n         return \"Keyword\", sym\r\n      end",
    "type": "statement:if"
  }, {
    "id": 115,
    "text": "self.i = self.i + #sym",
    "type": "statement:assign"
  }, {
    "id": 116,
    "text": "self.i = self.i+1",
    "type": "statement:assign"
  }, {
    "id": 117,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 118,
    "text": "function lexer:add (w, ...)\r\n   assert(not ..., \"lexer:add() takes only one arg, although possibly a table\")\r\n   if type (w) == \"table\" then\r\n      for _, x in ipairs (w) do self:add (x) end\r\n   else\r\n      if w:match (self.patterns.word .. \"$\") then self.alpha [w] = true\r\n      elseif w:match \"^%p%p+$\" then \r\n         local k = w:sub(1,1)\r\n         local list = self.sym [k]\r\n         if not list then list = { }; self.sym [k] = list end\r\n         _G.table.insert (list, w)\r\n      elseif w:match \"^%p$\" then return\r\n      else error \"Invalid keyword\" end\r\n   end\r\nend",
    "type": "function"
  }, {
    "id": 119,
    "text": "assert(not ..., \"lexer:add() takes only one arg, although possibly a table\")",
    "type": "statement:functioncall"
  }, {
    "id": 120,
    "text": "if type (w) == \"table\" then\r\n      for _, x in ipairs (w) do self:add (x) end\r\n   else\r\n      if w:match (self.patterns.word .. \"$\") then self.alpha [w] = true\r\n      elseif w:match \"^%p%p+$\" then \r\n         local k = w:sub(1,1)\r\n         local list = self.sym [k]\r\n         if not list then list = { }; self.sym [k] = list end\r\n         _G.table.insert (list, w)\r\n      elseif w:match \"^%p$\" then return\r\n      else error \"Invalid keyword\" end\r\n   end",
    "type": "statement:if"
  }, {
    "id": 121,
    "text": "for _, x in ipairs (w) do self:add (x) end",
    "type": "statement:genericfor"
  }, {
    "id": 122,
    "text": "self:add (x)",
    "type": "statement:functioncall"
  }, {
    "id": 123,
    "text": "if w:match (self.patterns.word .. \"$\") then self.alpha [w] = true\r\n      elseif w:match \"^%p%p+$\" then \r\n         local k = w:sub(1,1)\r\n         local list = self.sym [k]\r\n         if not list then list = { }; self.sym [k] = list end\r\n         _G.table.insert (list, w)\r\n      elseif w:match \"^%p$\" then return\r\n      else error \"Invalid keyword\" end",
    "type": "statement:if"
  }, {
    "id": 124,
    "text": "self.alpha [w] = true",
    "type": "statement:assign"
  }, {
    "id": 125,
    "text": "local k = w:sub(1,1)",
    "type": "statement:localassign"
  }, {
    "id": 126,
    "text": "local list = self.sym [k]",
    "type": "statement:localassign"
  }, {
    "id": 127,
    "text": "if not list then list = { }; self.sym [k] = list end",
    "type": "statement:if"
  }, {
    "id": 128,
    "text": "list = { }",
    "type": "statement:assign"
  }, {
    "id": 129,
    "text": "self.sym [k] = list",
    "type": "statement:assign"
  }, {
    "id": 130,
    "text": "_G.table.insert (list, w)",
    "type": "statement:functioncall"
  }, {
    "id": 131,
    "text": "error \"Invalid keyword\"",
    "type": "statement:functioncall"
  }, {
    "id": 132,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 133,
    "text": "function lexer:peek (n)\r\n   if not n then n=1 end\r\n   if n > #self.peeked then\r\n      for i = #self.peeked+1, n do\r\n         self.peeked [i] = self:extract()\r\n      end\r\n   end\r\n  return self.peeked [n]\r\nend",
    "type": "function"
  }, {
    "id": 134,
    "text": "if not n then n=1 end",
    "type": "statement:if"
  }, {
    "id": 135,
    "text": "n=1",
    "type": "statement:assign"
  }, {
    "id": 136,
    "text": "if n > #self.peeked then\r\n      for i = #self.peeked+1, n do\r\n         self.peeked [i] = self:extract()\r\n      end\r\n   end",
    "type": "statement:if"
  }, {
    "id": 137,
    "text": "for i = #self.peeked+1, n do\r\n         self.peeked [i] = self:extract()\r\n      end",
    "type": "statement:numericfor"
  }, {
    "id": 138,
    "text": "self.peeked [i] = self:extract()",
    "type": "statement:assign"
  }, {
    "id": 139,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 140,
    "text": "function lexer:next (n)\r\n   n = n or 1\r\n   self:peek (n)\r\n   local a\r\n   for i=1,n do \r\n      a = _G.table.remove (self.peeked, 1) \r\n      if a then \r\n         --debugf (\"lexer:next() ==> %s %s\",\r\n         --        table.tostring(a), tostring(a))\r\n      end\r\n      self.lastline = a.lineinfo.last[1]\r\n   end\r\n   self.lineinfo_last = a.lineinfo.last\r\n   return a or eof_token\r\nend",
    "type": "function"
  }, {
    "id": 141,
    "text": "n = n or 1",
    "type": "statement:assign"
  }, {
    "id": 142,
    "text": "self:peek (n)",
    "type": "statement:functioncall"
  }, {
    "id": 143,
    "text": "local a",
    "type": "statement:localassign"
  }, {
    "id": 144,
    "text": "for i=1,n do \r\n      a = _G.table.remove (self.peeked, 1) \r\n      if a then \r\n         --debugf (\"lexer:next() ==> %s %s\",\r\n         --        table.tostring(a), tostring(a))\r\n      end\r\n      self.lastline = a.lineinfo.last[1]\r\n   end",
    "type": "statement:numericfor"
  }, {
    "id": 145,
    "text": "a = _G.table.remove (self.peeked, 1)",
    "type": "statement:assign"
  }, {
    "id": 146,
    "text": "if a then \r\n         --debugf (\"lexer:next() ==> %s %s\",\r\n         --        table.tostring(a), tostring(a))\r\n      end",
    "type": "statement:if"
  }, {
    "id": 147,
    "text": "self.lastline = a.lineinfo.last[1]",
    "type": "statement:assign"
  }, {
    "id": 148,
    "text": "self.lineinfo_last = a.lineinfo.last",
    "type": "statement:assign"
  }, {
    "id": 149,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 150,
    "text": "function lexer:save () return { self.i; _G.table.cat(self.peeked) } end",
    "type": "function"
  }, {
    "id": 151,
    "text": "function lexer:restore (s) self.i=s[1]; self.peeked=s[2] end",
    "type": "function"
  }, {
    "id": 152,
    "text": "self.i=s[1]",
    "type": "statement:assign"
  }, {
    "id": 153,
    "text": "self.peeked=s[2]",
    "type": "statement:assign"
  }, {
    "id": 154,
    "text": "function lexer:sync()\r\n   local p1 = self.peeked[1]\r\n   if p1 then \r\n      li = p1.lineinfo.first\r\n      self.line, self.i = li[1], li[3]\r\n      self.column_offset = self.i - li[2]\r\n      self.peeked = { }\r\n      self.attached_comments = p1.lineinfo.first.comments or { }\r\n   end\r\nend",
    "type": "function"
  }, {
    "id": 155,
    "text": "local p1 = self.peeked[1]",
    "type": "statement:localassign"
  }, {
    "id": 156,
    "text": "if p1 then \r\n      li = p1.lineinfo.first\r\n      self.line, self.i = li[1], li[3]\r\n      self.column_offset = self.i - li[2]\r\n      self.peeked = { }\r\n      self.attached_comments = p1.lineinfo.first.comments or { }\r\n   end",
    "type": "statement:if"
  }, {
    "id": 157,
    "text": "li = p1.lineinfo.first",
    "type": "statement:assign"
  }, {
    "id": 158,
    "text": "self.line, self.i = li[1], li[3]",
    "type": "statement:assign"
  }, {
    "id": 159,
    "text": "self.column_offset = self.i - li[2]",
    "type": "statement:assign"
  }, {
    "id": 160,
    "text": "self.peeked = { }",
    "type": "statement:assign"
  }, {
    "id": 161,
    "text": "self.attached_comments = p1.lineinfo.first.comments or { }",
    "type": "statement:assign"
  }, {
    "id": 162,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 163,
    "text": "function lexer:takeover(old)\r\n   self:sync()\r\n   self.line, self.column_offset, self.i, self.src, self.attached_comments =\r\n      old.line, old.column_offset, old.i, old.src, old.attached_comments\r\n   return self\r\nend",
    "type": "function"
  }, {
    "id": 164,
    "text": "self:sync()",
    "type": "statement:functioncall"
  }, {
    "id": 165,
    "text": "self.line, self.column_offset, self.i, self.src, self.attached_comments =\r\n      old.line, old.column_offset, old.i, old.src, old.attached_comments",
    "type": "statement:assign"
  }, {
    "id": 166,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 167,
    "text": "function lexer:lineinfo_right()\r\n   return self:peek(1).lineinfo.first\r\nend",
    "type": "function"
  }, {
    "id": 168,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 169,
    "text": "function lexer:lineinfo_left()\r\n   return self.lineinfo_last\r\nend",
    "type": "function"
  }, {
    "id": 170,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 171,
    "text": "function lexer:newstream (src_or_stream, name)\r\n   name = name or \"?\"\r\n   if type(src_or_stream)=='table' then -- it's a stream\r\n      return setmetatable ({ }, self) :takeover (src_or_stream)\r\n   elseif type(src_or_stream)=='string' then -- it's a source string\r\n      local src = src_or_stream\r\n      local stream = { \r\n         src_name      = name;   -- Name of the file\r\n         src           = src;    -- The source, as a single string\r\n         peeked        = { };    -- Already peeked, but not discarded yet, tokens\r\n         i             = 1;      -- Character offset in src\r\n         line          = 1;      -- Current line number\r\n         column_offset = 0;      -- distance from beginning of file to last '\\n'\r\n         attached_comments = { },-- comments accumulator\r\n         lineinfo_last = { 1, 1, 1, name }\r\n      }\r\n      setmetatable (stream, self)\r\n\r\n      -- skip initial sharp-bang for unix scripts\r\n      -- FIXME: redundant with mlp.chunk()\r\n      if src and src :match \"^#\" then stream.i = src :find \"\\n\" + 1 end\r\n      return stream\r\n   else\r\n      assert(false, \":newstream() takes a source string or a stream, not a \"..\r\n                    type(src_or_stream))\r\n   end\r\nend",
    "type": "function"
  }, {
    "id": 172,
    "text": "name = name or \"?\"",
    "type": "statement:assign"
  }, {
    "id": 173,
    "text": "if type(src_or_stream)=='table' then -- it's a stream\r\n      return setmetatable ({ }, self) :takeover (src_or_stream)\r\n   elseif type(src_or_stream)=='string' then -- it's a source string\r\n      local src = src_or_stream\r\n      local stream = { \r\n         src_name      = name;   -- Name of the file\r\n         src           = src;    -- The source, as a single string\r\n         peeked        = { };    -- Already peeked, but not discarded yet, tokens\r\n         i             = 1;      -- Character offset in src\r\n         line          = 1;      -- Current line number\r\n         column_offset = 0;      -- distance from beginning of file to last '\\n'\r\n         attached_comments = { },-- comments accumulator\r\n         lineinfo_last = { 1, 1, 1, name }\r\n      }\r\n      setmetatable (stream, self)\r\n\r\n      -- skip initial sharp-bang for unix scripts\r\n      -- FIXME: redundant with mlp.chunk()\r\n      if src and src :match \"^#\" then stream.i = src :find \"\\n\" + 1 end\r\n      return stream\r\n   else\r\n      assert(false, \":newstream() takes a source string or a stream, not a \"..\r\n                    type(src_or_stream))\r\n   end",
    "type": "statement:if"
  }, {
    "id": 174,
    "text": "local src = src_or_stream",
    "type": "statement:localassign"
  }, {
    "id": 175,
    "text": "local stream = { \r\n         src_name      = name;   -- Name of the file\r\n         src           = src;    -- The source, as a single string\r\n         peeked        = { };    -- Already peeked, but not discarded yet, tokens\r\n         i             = 1;      -- Character offset in src\r\n         line          = 1;      -- Current line number\r\n         column_offset = 0;      -- distance from beginning of file to last '\\n'\r\n         attached_comments = { },-- comments accumulator\r\n         lineinfo_last = { 1, 1, 1, name }\r\n      }",
    "type": "statement:localassign"
  }, {
    "id": 176,
    "text": "setmetatable (stream, self)",
    "type": "statement:functioncall"
  }, {
    "id": 177,
    "text": "if src and src :match \"^#\" then stream.i = src :find \"\\n\" + 1 end",
    "type": "statement:if"
  }, {
    "id": 178,
    "text": "stream.i = src :find \"\\n\" + 1",
    "type": "statement:assign"
  }, {
    "id": 179,
    "text": "assert(false, \":newstream() takes a source string or a stream, not a \"..\r\n                    type(src_or_stream))",
    "type": "statement:functioncall"
  }, {
    "id": 180,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 181,
    "text": "function lexer:is_keyword (a, ...)\r\n   if not a or a.tag ~= \"Keyword\" then return false end\r\n   local words = {...}\r\n   if #words == 0 then return a[1] end\r\n   for _, w in ipairs (words) do\r\n      if w == a[1] then return w end\r\n   end\r\n   return false\r\nend",
    "type": "function"
  }, {
    "id": 182,
    "text": "if not a or a.tag ~= \"Keyword\" then return false end",
    "type": "statement:if"
  }, {
    "id": 183,
    "text": "local words = {...}",
    "type": "statement:localassign"
  }, {
    "id": 184,
    "text": "if #words == 0 then return a[1] end",
    "type": "statement:if"
  }, {
    "id": 185,
    "text": "for _, w in ipairs (words) do\r\n      if w == a[1] then return w end\r\n   end",
    "type": "statement:genericfor"
  }, {
    "id": 186,
    "text": "if w == a[1] then return w end",
    "type": "statement:if"
  }, {
    "id": 187,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 188,
    "text": "function lexer:check (...)\r\n   local words = {...}\r\n   local a = self:next()\r\n   local function err ()\r\n      error (\"Got \" .. tostring (a) .. \r\n             \", expected one of these keywords : '\" ..\r\n             _G.table.concat (words,\"', '\") .. \"'\") end\r\n          \r\n   if not a or a.tag ~= \"Keyword\" then err () end\r\n   if #words == 0 then return a[1] end\r\n   for _, w in ipairs (words) do\r\n       if w == a[1] then return w end\r\n   end\r\n   err ()\r\nend",
    "type": "function"
  }, {
    "id": 189,
    "text": "local a = self:next()",
    "type": "statement:localassign"
  }, {
    "id": 190,
    "text": "local function err ()\r\n      error (\"Got \" .. tostring (a) .. \r\n             \", expected one of these keywords : '\" ..\r\n             _G.table.concat (words,\"', '\") .. \"'\") end",
    "type": "statement:localfunction"
  }, {
    "id": 191,
    "text": "error (\"Got \" .. tostring (a) .. \r\n             \", expected one of these keywords : '\" ..\r\n             _G.table.concat (words,\"', '\") .. \"'\")",
    "type": "statement:functioncall"
  }, {
    "id": 192,
    "text": "if not a or a.tag ~= \"Keyword\" then err () end",
    "type": "statement:if"
  }, {
    "id": 193,
    "text": "err ()",
    "type": "statement:functioncall"
  }, {
    "id": 194,
    "text": "for _, w in ipairs (words) do\r\n       if w == a[1] then return w end\r\n   end",
    "type": "statement:genericfor"
  }, {
    "id": 195,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 196,
    "text": "local function err ()\r\n      error (\"Got \" .. tostring (a) .. \r\n             \", expected one of these keywords : '\" ..\r\n             _G.table.concat (words,\"', '\") .. \"'\") end",
    "type": "function"
  }, {
    "id": 197,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 198,
    "text": "function lexer:clone()\r\n   local clone = {\r\n      alpha = table.deep_copy(self.alpha),\r\n      sym   = table.deep_copy(self.sym) }\r\n   setmetatable(clone, self)\r\n   clone.__index = clone\r\n   return clone\r\nend",
    "type": "function"
  }, {
    "id": 199,
    "text": "local clone = {\r\n      alpha = table.deep_copy(self.alpha),\r\n      sym   = table.deep_copy(self.sym) }",
    "type": "statement:localassign"
  }, {
    "id": 200,
    "text": "setmetatable(clone, self)",
    "type": "statement:functioncall"
  }, {
    "id": 201,
    "text": "clone.__index = clone",
    "type": "statement:assign"
  }, {
    "id": 202,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 203,
    "text": "",
    "type": "function container"
  }, {
    "id": 204,
    "text": "tostring",
    "type": "global function"
  }, {
    "id": 205,
    "text": "ipairs",
    "type": "global function"
  }, {
    "id": 206,
    "text": "deep_copy",
    "type": "global function"
  }, {
    "id": 207,
    "text": "type",
    "type": "global function"
  }, {
    "id": 208,
    "text": "self[extractor]",
    "type": "global function"
  }, {
    "id": 209,
    "text": "_G.string.byte",
    "type": "global function"
  }, {
    "id": 210,
    "text": "assert",
    "type": "global function"
  }, {
    "id": 211,
    "text": "tonumber",
    "type": "global function"
  }, {
    "id": 212,
    "text": "table_insert",
    "type": "global function"
  }, {
    "id": 213,
    "text": "_G.table.cat",
    "type": "global function"
  }, {
    "id": 214,
    "text": "_G.table.concat",
    "type": "global function"
  }, {
    "id": 215,
    "text": "char",
    "type": "global function"
  }, {
    "id": 216,
    "text": "_G.table.remove",
    "type": "global function"
  }, {
    "id": 217,
    "text": "_G.table.insert",
    "type": "global function"
  }, {
    "id": 218,
    "text": "error",
    "type": "global function"
  }, {
    "id": 219,
    "text": "pairs",
    "type": "global function"
  }, {
    "id": 220,
    "text": "setmetatable",
    "type": "global function"
  }, {
    "id": 221,
    "text": "module",
    "type": "global function"
  }, {
    "id": 222,
    "text": "require",
    "type": "global function"
  }, {
    "id": 223,
    "text": "",
    "type": "global variable"
  }, {
    "id": 224,
    "text": "",
    "type": "variable container"
  }, {
    "id": 225,
    "text": "",
    "type": "require container"
  }, {
    "id": 226,
    "text": "",
    "type": "local variable"
  }, {
    "id": 227,
    "text": "",
    "type": "n/a"
  }, {
    "id": 228,
    "text": "",
    "type": "global variable"
  }, {
    "id": 229,
    "text": "",
    "type": "n/a"
  }, {
    "id": 230,
    "text": "",
    "type": "global variable"
  }, {
    "id": 231,
    "text": "",
    "type": "n/a"
  }, {
    "id": 232,
    "text": "",
    "type": "global variable"
  }, {
    "id": 233,
    "text": "",
    "type": "n/a"
  }, {
    "id": 234,
    "text": "",
    "type": "global variable"
  }, {
    "id": 235,
    "text": "",
    "type": "n/a"
  }, {
    "id": 236,
    "text": "",
    "type": "global variable"
  }, {
    "id": 237,
    "text": "",
    "type": "n/a"
  }, {
    "id": 238,
    "text": "",
    "type": "global variable"
  }, {
    "id": 239,
    "text": "",
    "type": "n/a"
  } ]
}