{
  "_filename": "optlex.lua",
  "_isShebang": false,
  "_isSpec": false,
  "_isTest": false,
  "_path": "modules/squish/minify/optlex.lua",
  "edges": [ {
    "from": 0,
    "label": "implements",
    "to": 1
  }, {
    "from": 2,
    "label": "has",
    "to": 3
  }, {
    "from": 2,
    "label": "has",
    "to": 4
  }, {
    "from": 2,
    "label": "has",
    "to": 5
  }, {
    "from": 2,
    "label": "has",
    "to": 5
  }, {
    "from": 2,
    "label": "has",
    "to": 5
  }, {
    "from": 2,
    "label": "has",
    "to": 6
  }, {
    "from": 7,
    "label": "has",
    "to": 8
  }, {
    "from": 7,
    "label": "has",
    "to": 9
  }, {
    "from": 7,
    "label": "has",
    "to": 5
  }, {
    "from": 7,
    "label": "has",
    "to": 5
  }, {
    "from": 7,
    "label": "has",
    "to": 5
  }, {
    "from": 7,
    "label": "has",
    "to": 10
  }, {
    "from": 11,
    "label": "has",
    "to": 12
  }, {
    "from": 11,
    "label": "has",
    "to": 13
  }, {
    "from": 11,
    "label": "has",
    "to": 14
  }, {
    "from": 11,
    "label": "has",
    "to": 15
  }, {
    "from": 15,
    "label": "has",
    "to": 16
  }, {
    "from": 15,
    "label": "has",
    "to": 17
  }, {
    "from": 15,
    "label": "has",
    "to": 18
  }, {
    "from": 15,
    "label": "has",
    "to": 19
  }, {
    "from": 15,
    "label": "has",
    "to": 20
  }, {
    "from": 20,
    "label": "has",
    "to": 21
  }, {
    "from": 11,
    "label": "has",
    "to": 5
  }, {
    "from": 11,
    "label": "has",
    "to": 22
  }, {
    "from": 23,
    "label": "has",
    "to": 24
  }, {
    "from": 23,
    "label": "has",
    "to": 25
  }, {
    "from": 23,
    "label": "has",
    "to": 26
  }, {
    "from": 26,
    "label": "has",
    "to": 27
  }, {
    "from": 26,
    "label": "has",
    "to": 28
  }, {
    "from": 28,
    "label": "has",
    "to": 29
  }, {
    "from": 28,
    "label": "has",
    "to": 30
  }, {
    "from": 26,
    "label": "has",
    "to": 31
  }, {
    "from": 26,
    "label": "has",
    "to": 32
  }, {
    "from": 32,
    "label": "has",
    "to": 33
  }, {
    "from": 26,
    "label": "has",
    "to": 34
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 5
  }, {
    "from": 23,
    "label": "has",
    "to": 35
  }, {
    "from": 36,
    "label": "has",
    "to": 37
  }, {
    "from": 36,
    "label": "has",
    "to": 38
  }, {
    "from": 36,
    "label": "has",
    "to": 39
  }, {
    "from": 39,
    "label": "has",
    "to": 40
  }, {
    "from": 39,
    "label": "has",
    "to": 41
  }, {
    "from": 41,
    "label": "has",
    "to": 42
  }, {
    "from": 41,
    "label": "has",
    "to": 43
  }, {
    "from": 36,
    "label": "has",
    "to": 44
  }, {
    "from": 36,
    "label": "has",
    "to": 45
  }, {
    "from": 46,
    "label": "has",
    "to": 47
  }, {
    "from": 46,
    "label": "has",
    "to": 48
  }, {
    "from": 46,
    "label": "has",
    "to": 49
  }, {
    "from": 46,
    "label": "has",
    "to": 50
  }, {
    "from": 50,
    "label": "has",
    "to": 51
  }, {
    "from": 50,
    "label": "has",
    "to": 52
  }, {
    "from": 52,
    "label": "has",
    "to": 53
  }, {
    "from": 46,
    "label": "has",
    "to": 5
  }, {
    "from": 46,
    "label": "has",
    "to": 54
  }, {
    "from": 54,
    "label": "has",
    "to": 55
  }, {
    "from": 54,
    "label": "has",
    "to": 56
  }, {
    "from": 56,
    "label": "has",
    "to": 57
  }, {
    "from": 56,
    "label": "has",
    "to": 58
  }, {
    "from": 56,
    "label": "has",
    "to": 59
  }, {
    "from": 56,
    "label": "has",
    "to": 60
  }, {
    "from": 60,
    "label": "has",
    "to": 61
  }, {
    "from": 56,
    "label": "has",
    "to": 62
  }, {
    "from": 56,
    "label": "has",
    "to": 63
  }, {
    "from": 54,
    "label": "has",
    "to": 64
  }, {
    "from": 54,
    "label": "has",
    "to": 65
  }, {
    "from": 65,
    "label": "has",
    "to": 66
  }, {
    "from": 54,
    "label": "has",
    "to": 67
  }, {
    "from": 67,
    "label": "has",
    "to": 63
  }, {
    "from": 67,
    "label": "has",
    "to": 68
  }, {
    "from": 67,
    "label": "has",
    "to": 69
  }, {
    "from": 69,
    "label": "has",
    "to": 70
  }, {
    "from": 67,
    "label": "has",
    "to": 71
  }, {
    "from": 71,
    "label": "has",
    "to": 72
  }, {
    "from": 71,
    "label": "has",
    "to": 73
  }, {
    "from": 71,
    "label": "has",
    "to": 74
  }, {
    "from": 71,
    "label": "has",
    "to": 75
  }, {
    "from": 71,
    "label": "has",
    "to": 76
  }, {
    "from": 71,
    "label": "has",
    "to": 77
  }, {
    "from": 77,
    "label": "has",
    "to": 78
  }, {
    "from": 54,
    "label": "has",
    "to": 79
  }, {
    "from": 54,
    "label": "has",
    "to": 80
  }, {
    "from": 54,
    "label": "has",
    "to": 81
  }, {
    "from": 54,
    "label": "has",
    "to": 82
  }, {
    "from": 82,
    "label": "has",
    "to": 83
  }, {
    "from": 82,
    "label": "has",
    "to": 84
  }, {
    "from": 54,
    "label": "has",
    "to": 85
  }, {
    "from": 85,
    "label": "has",
    "to": 63
  }, {
    "from": 85,
    "label": "has",
    "to": 86
  }, {
    "from": 85,
    "label": "has",
    "to": 87
  }, {
    "from": 85,
    "label": "has",
    "to": 88
  }, {
    "from": 85,
    "label": "has",
    "to": 89
  }, {
    "from": 89,
    "label": "has",
    "to": 90
  }, {
    "from": 89,
    "label": "has",
    "to": 91
  }, {
    "from": 85,
    "label": "has",
    "to": 92
  }, {
    "from": 85,
    "label": "has",
    "to": 93
  }, {
    "from": 93,
    "label": "has",
    "to": 94
  }, {
    "from": 93,
    "label": "has",
    "to": 95
  }, {
    "from": 93,
    "label": "has",
    "to": 96
  }, {
    "from": 93,
    "label": "has",
    "to": 97
  }, {
    "from": 93,
    "label": "has",
    "to": 98
  }, {
    "from": 93,
    "label": "has",
    "to": 99
  }, {
    "from": 93,
    "label": "has",
    "to": 100
  }, {
    "from": 46,
    "label": "has",
    "to": 101
  }, {
    "from": 101,
    "label": "has",
    "to": 102
  }, {
    "from": 102,
    "label": "has",
    "to": 103
  }, {
    "from": 102,
    "label": "has",
    "to": 104
  }, {
    "from": 101,
    "label": "has",
    "to": 105
  }, {
    "from": 46,
    "label": "has",
    "to": 106
  }, {
    "from": 107,
    "label": "has",
    "to": 108
  }, {
    "from": 107,
    "label": "has",
    "to": 109
  }, {
    "from": 107,
    "label": "has",
    "to": 110
  }, {
    "from": 107,
    "label": "has",
    "to": 111
  }, {
    "from": 107,
    "label": "has",
    "to": 112
  }, {
    "from": 107,
    "label": "has",
    "to": 113
  }, {
    "from": 107,
    "label": "has",
    "to": 114
  }, {
    "from": 114,
    "label": "has",
    "to": 115
  }, {
    "from": 114,
    "label": "has",
    "to": 116
  }, {
    "from": 116,
    "label": "has",
    "to": 117
  }, {
    "from": 116,
    "label": "has",
    "to": 118
  }, {
    "from": 116,
    "label": "has",
    "to": 119
  }, {
    "from": 116,
    "label": "has",
    "to": 120
  }, {
    "from": 120,
    "label": "has",
    "to": 121
  }, {
    "from": 120,
    "label": "has",
    "to": 21
  }, {
    "from": 120,
    "label": "has",
    "to": 122
  }, {
    "from": 120,
    "label": "has",
    "to": 123
  }, {
    "from": 120,
    "label": "has",
    "to": 124
  }, {
    "from": 124,
    "label": "has",
    "to": 125
  }, {
    "from": 124,
    "label": "has",
    "to": 126
  }, {
    "from": 120,
    "label": "has",
    "to": 122
  }, {
    "from": 120,
    "label": "has",
    "to": 127
  }, {
    "from": 127,
    "label": "has",
    "to": 128
  }, {
    "from": 127,
    "label": "has",
    "to": 122
  }, {
    "from": 127,
    "label": "has",
    "to": 129
  }, {
    "from": 127,
    "label": "has",
    "to": 121
  }, {
    "from": 127,
    "label": "has",
    "to": 21
  }, {
    "from": 120,
    "label": "has",
    "to": 130
  }, {
    "from": 120,
    "label": "has",
    "to": 131
  }, {
    "from": 120,
    "label": "has",
    "to": 132
  }, {
    "from": 120,
    "label": "has",
    "to": 133
  }, {
    "from": 120,
    "label": "has",
    "to": 134
  }, {
    "from": 120,
    "label": "has",
    "to": 135
  }, {
    "from": 135,
    "label": "has",
    "to": 136
  }, {
    "from": 135,
    "label": "has",
    "to": 137
  }, {
    "from": 135,
    "label": "has",
    "to": 138
  }, {
    "from": 135,
    "label": "has",
    "to": 128
  }, {
    "from": 135,
    "label": "has",
    "to": 139
  }, {
    "from": 135,
    "label": "has",
    "to": 140
  }, {
    "from": 135,
    "label": "has",
    "to": 141
  }, {
    "from": 141,
    "label": "has",
    "to": 129
  }, {
    "from": 120,
    "label": "has",
    "to": 142
  }, {
    "from": 120,
    "label": "has",
    "to": 143
  }, {
    "from": 116,
    "label": "has",
    "to": 21
  }, {
    "from": 116,
    "label": "has",
    "to": 144
  }, {
    "from": 144,
    "label": "has",
    "to": 129
  }, {
    "from": 107,
    "label": "has",
    "to": 145
  }, {
    "from": 145,
    "label": "has",
    "to": 146
  }, {
    "from": 145,
    "label": "has",
    "to": 147
  }, {
    "from": 147,
    "label": "has",
    "to": 148
  }, {
    "from": 147,
    "label": "has",
    "to": 17
  }, {
    "from": 147,
    "label": "has",
    "to": 149
  }, {
    "from": 149,
    "label": "has",
    "to": 150
  }, {
    "from": 149,
    "label": "has",
    "to": 151
  }, {
    "from": 149,
    "label": "has",
    "to": 152
  }, {
    "from": 149,
    "label": "has",
    "to": 153
  }, {
    "from": 145,
    "label": "has",
    "to": 154
  }, {
    "from": 107,
    "label": "has",
    "to": 155
  }, {
    "from": 107,
    "label": "has",
    "to": 156
  }, {
    "from": 156,
    "label": "has",
    "to": 157
  }, {
    "from": 157,
    "label": "has",
    "to": 158
  }, {
    "from": 157,
    "label": "has",
    "to": 104
  }, {
    "from": 156,
    "label": "has",
    "to": 159
  }, {
    "from": 107,
    "label": "has",
    "to": 160
  }, {
    "from": 161,
    "label": "has",
    "to": 108
  }, {
    "from": 161,
    "label": "has",
    "to": 162
  }, {
    "from": 161,
    "label": "has",
    "to": 163
  }, {
    "from": 161,
    "label": "has",
    "to": 164
  }, {
    "from": 161,
    "label": "has",
    "to": 165
  }, {
    "from": 161,
    "label": "has",
    "to": 166
  }, {
    "from": 161,
    "label": "has",
    "to": 112
  }, {
    "from": 161,
    "label": "has",
    "to": 167
  }, {
    "from": 167,
    "label": "has",
    "to": 16
  }, {
    "from": 167,
    "label": "has",
    "to": 168
  }, {
    "from": 167,
    "label": "has",
    "to": 169
  }, {
    "from": 169,
    "label": "has",
    "to": 170
  }, {
    "from": 169,
    "label": "has",
    "to": 171
  }, {
    "from": 167,
    "label": "has",
    "to": 172
  }, {
    "from": 172,
    "label": "has",
    "to": 173
  }, {
    "from": 173,
    "label": "has",
    "to": 174
  }, {
    "from": 172,
    "label": "has",
    "to": 175
  }, {
    "from": 167,
    "label": "has",
    "to": 176
  }, {
    "from": 167,
    "label": "has",
    "to": 18
  }, {
    "from": 167,
    "label": "has",
    "to": 177
  }, {
    "from": 177,
    "label": "has",
    "to": 178
  }, {
    "from": 178,
    "label": "has",
    "to": 21
  }, {
    "from": 177,
    "label": "has",
    "to": 179
  }, {
    "from": 179,
    "label": "has",
    "to": 180
  }, {
    "from": 161,
    "label": "has",
    "to": 181
  }, {
    "from": 181,
    "label": "has",
    "to": 182
  }, {
    "from": 181,
    "label": "has",
    "to": 183
  }, {
    "from": 183,
    "label": "has",
    "to": 184
  }, {
    "from": 183,
    "label": "has",
    "to": 185
  }, {
    "from": 185,
    "label": "has",
    "to": 186
  }, {
    "from": 183,
    "label": "has",
    "to": 187
  }, {
    "from": 181,
    "label": "has",
    "to": 188
  }, {
    "from": 188,
    "label": "has",
    "to": 189
  }, {
    "from": 188,
    "label": "has",
    "to": 190
  }, {
    "from": 161,
    "label": "has",
    "to": 191
  }, {
    "from": 161,
    "label": "has",
    "to": 192
  }, {
    "from": 193,
    "label": "has",
    "to": 108
  }, {
    "from": 193,
    "label": "has",
    "to": 194
  }, {
    "from": 193,
    "label": "has",
    "to": 163
  }, {
    "from": 193,
    "label": "has",
    "to": 164
  }, {
    "from": 193,
    "label": "has",
    "to": 195
  }, {
    "from": 193,
    "label": "has",
    "to": 166
  }, {
    "from": 193,
    "label": "has",
    "to": 112
  }, {
    "from": 193,
    "label": "has",
    "to": 196
  }, {
    "from": 196,
    "label": "has",
    "to": 16
  }, {
    "from": 196,
    "label": "has",
    "to": 168
  }, {
    "from": 196,
    "label": "has",
    "to": 169
  }, {
    "from": 169,
    "label": "has",
    "to": 170
  }, {
    "from": 169,
    "label": "has",
    "to": 171
  }, {
    "from": 196,
    "label": "has",
    "to": 197
  }, {
    "from": 197,
    "label": "has",
    "to": 198
  }, {
    "from": 197,
    "label": "has",
    "to": 199
  }, {
    "from": 199,
    "label": "has",
    "to": 200
  }, {
    "from": 197,
    "label": "has",
    "to": 175
  }, {
    "from": 196,
    "label": "has",
    "to": 176
  }, {
    "from": 196,
    "label": "has",
    "to": 18
  }, {
    "from": 196,
    "label": "has",
    "to": 201
  }, {
    "from": 201,
    "label": "has",
    "to": 178
  }, {
    "from": 178,
    "label": "has",
    "to": 21
  }, {
    "from": 201,
    "label": "has",
    "to": 180
  }, {
    "from": 193,
    "label": "has",
    "to": 202
  }, {
    "from": 193,
    "label": "has",
    "to": 203
  }, {
    "from": 203,
    "label": "has",
    "to": 182
  }, {
    "from": 203,
    "label": "has",
    "to": 183
  }, {
    "from": 183,
    "label": "has",
    "to": 184
  }, {
    "from": 183,
    "label": "has",
    "to": 185
  }, {
    "from": 185,
    "label": "has",
    "to": 186
  }, {
    "from": 183,
    "label": "has",
    "to": 187
  }, {
    "from": 203,
    "label": "has",
    "to": 204
  }, {
    "from": 204,
    "label": "has",
    "to": 189
  }, {
    "from": 204,
    "label": "has",
    "to": 205
  }, {
    "from": 193,
    "label": "has",
    "to": 191
  }, {
    "from": 193,
    "label": "has",
    "to": 206
  }, {
    "from": 207,
    "label": "has",
    "to": 208
  }, {
    "from": 207,
    "label": "has",
    "to": 209
  }, {
    "from": 207,
    "label": "has",
    "to": 210
  }, {
    "from": 210,
    "label": "has",
    "to": 211
  }, {
    "from": 207,
    "label": "has",
    "to": 212
  }, {
    "from": 207,
    "label": "has",
    "to": 213
  }, {
    "from": 214,
    "label": "has",
    "to": 215
  }, {
    "from": 214,
    "label": "has",
    "to": 5
  }, {
    "from": 214,
    "label": "has",
    "to": 194
  }, {
    "from": 214,
    "label": "has",
    "to": 163
  }, {
    "from": 214,
    "label": "has",
    "to": 164
  }, {
    "from": 214,
    "label": "has",
    "to": 195
  }, {
    "from": 214,
    "label": "has",
    "to": 216
  }, {
    "from": 214,
    "label": "has",
    "to": 5
  }, {
    "from": 214,
    "label": "has",
    "to": 217
  }, {
    "from": 218,
    "label": "has",
    "to": 219
  }, {
    "from": 218,
    "label": "has",
    "to": 220
  }, {
    "from": 218,
    "label": "has",
    "to": 221
  }, {
    "from": 218,
    "label": "has",
    "to": 222
  }, {
    "from": 218,
    "label": "has",
    "to": 223
  }, {
    "from": 218,
    "label": "has",
    "to": 224
  }, {
    "from": 218,
    "label": "has",
    "to": 225
  }, {
    "from": 218,
    "label": "has",
    "to": 226
  }, {
    "from": 218,
    "label": "has",
    "to": 227
  }, {
    "from": 218,
    "label": "has",
    "to": 228
  }, {
    "from": 228,
    "label": "has",
    "to": 229
  }, {
    "from": 228,
    "label": "has",
    "to": 230
  }, {
    "from": 228,
    "label": "has",
    "to": 231
  }, {
    "from": 218,
    "label": "has",
    "to": 232
  }, {
    "from": 218,
    "label": "has",
    "to": 112
  }, {
    "from": 218,
    "label": "has",
    "to": 233
  }, {
    "from": 218,
    "label": "has",
    "to": 234
  }, {
    "from": 218,
    "label": "has",
    "to": 235
  }, {
    "from": 235,
    "label": "has",
    "to": 236
  }, {
    "from": 235,
    "label": "has",
    "to": 237
  }, {
    "from": 235,
    "label": "has",
    "to": 238
  }, {
    "from": 218,
    "label": "has",
    "to": 239
  }, {
    "from": 239,
    "label": "has",
    "to": 240
  }, {
    "from": 239,
    "label": "has",
    "to": 241
  }, {
    "from": 239,
    "label": "has",
    "to": 242
  }, {
    "from": 242,
    "label": "has",
    "to": 243
  }, {
    "from": 239,
    "label": "has",
    "to": 244
  }, {
    "from": 244,
    "label": "has",
    "to": 245
  }, {
    "from": 244,
    "label": "has",
    "to": 246
  }, {
    "from": 246,
    "label": "has",
    "to": 247
  }, {
    "from": 244,
    "label": "has",
    "to": 245
  }, {
    "from": 244,
    "label": "has",
    "to": 248
  }, {
    "from": 248,
    "label": "has",
    "to": 249
  }, {
    "from": 249,
    "label": "has",
    "to": 250
  }, {
    "from": 249,
    "label": "has",
    "to": 251
  }, {
    "from": 244,
    "label": "has",
    "to": 245
  }, {
    "from": 244,
    "label": "has",
    "to": 252
  }, {
    "from": 252,
    "label": "has",
    "to": 253
  }, {
    "from": 253,
    "label": "has",
    "to": 254
  }, {
    "from": 253,
    "label": "has",
    "to": 255
  }, {
    "from": 252,
    "label": "has",
    "to": 254
  }, {
    "from": 244,
    "label": "has",
    "to": 256
  }, {
    "from": 256,
    "label": "has",
    "to": 257
  }, {
    "from": 257,
    "label": "has",
    "to": 258
  }, {
    "from": 256,
    "label": "has",
    "to": 245
  }, {
    "from": 256,
    "label": "has",
    "to": 259
  }, {
    "from": 256,
    "label": "has",
    "to": 260
  }, {
    "from": 260,
    "label": "has",
    "to": 255
  }, {
    "from": 260,
    "label": "has",
    "to": 261
  }, {
    "from": 260,
    "label": "has",
    "to": 262
  }, {
    "from": 256,
    "label": "has",
    "to": 263
  }, {
    "from": 263,
    "label": "has",
    "to": 264
  }, {
    "from": 256,
    "label": "has",
    "to": 265
  }, {
    "from": 265,
    "label": "has",
    "to": 266
  }, {
    "from": 256,
    "label": "has",
    "to": 257
  }, {
    "from": 257,
    "label": "has",
    "to": 258
  }, {
    "from": 256,
    "label": "has",
    "to": 245
  }, {
    "from": 244,
    "label": "has",
    "to": 267
  }, {
    "from": 267,
    "label": "has",
    "to": 255
  }, {
    "from": 267,
    "label": "has",
    "to": 268
  }, {
    "from": 244,
    "label": "has",
    "to": 269
  }, {
    "from": 269,
    "label": "has",
    "to": 270
  }, {
    "from": 270,
    "label": "has",
    "to": 255
  }, {
    "from": 270,
    "label": "has",
    "to": 271
  }, {
    "from": 270,
    "label": "has",
    "to": 272
  }, {
    "from": 272,
    "label": "has",
    "to": 255
  }, {
    "from": 272,
    "label": "has",
    "to": 273
  }, {
    "from": 272,
    "label": "has",
    "to": 274
  }, {
    "from": 274,
    "label": "has",
    "to": 275
  }, {
    "from": 275,
    "label": "has",
    "to": 255
  }, {
    "from": 274,
    "label": "has",
    "to": 276
  }, {
    "from": 274,
    "label": "has",
    "to": 277
  }, {
    "from": 277,
    "label": "has",
    "to": 255
  }, {
    "from": 277,
    "label": "has",
    "to": 262
  }, {
    "from": 244,
    "label": "has",
    "to": 278
  }, {
    "from": 239,
    "label": "has",
    "to": 21
  }, {
    "from": 218,
    "label": "has",
    "to": 279
  }, {
    "from": 218,
    "label": "has",
    "to": 280
  }, {
    "from": 280,
    "label": "has",
    "to": 146
  }, {
    "from": 280,
    "label": "has",
    "to": 281
  }, {
    "from": 281,
    "label": "has",
    "to": 282
  }, {
    "from": 280,
    "label": "has",
    "to": 283
  }, {
    "from": 283,
    "label": "has",
    "to": 240
  }, {
    "from": 283,
    "label": "has",
    "to": 284
  }, {
    "from": 284,
    "label": "has",
    "to": 285
  }, {
    "from": 284,
    "label": "has",
    "to": 286
  }, {
    "from": 286,
    "label": "has",
    "to": 287
  }, {
    "from": 286,
    "label": "has",
    "to": 288
  }, {
    "from": 288,
    "label": "has",
    "to": 255
  }, {
    "from": 283,
    "label": "has",
    "to": 21
  }, {
    "from": 280,
    "label": "has",
    "to": 279
  }, {
    "from": 218,
    "label": "has",
    "to": 289
  }, {
    "from": 289,
    "label": "has",
    "to": 290
  }, {
    "from": 218,
    "label": "has",
    "to": 5
  }, {
    "from": 218,
    "label": "has",
    "to": 291
  }, {
    "from": 292,
    "label": "has",
    "to": 236
  }, {
    "from": 292,
    "label": "has",
    "to": 237
  }, {
    "from": 292,
    "label": "has",
    "to": 238
  }, {
    "from": 292,
    "label": "has",
    "to": 293
  }, {
    "from": 2,
    "label": "calls",
    "to": 2
  }, {
    "from": 218,
    "label": "calls",
    "to": 2
  }, {
    "from": 11,
    "label": "calls",
    "to": 303
  }, {
    "from": 107,
    "label": "calls",
    "to": 303
  }, {
    "from": 107,
    "label": "calls",
    "to": 303
  }, {
    "from": 107,
    "label": "calls",
    "to": 303
  }, {
    "from": 161,
    "label": "calls",
    "to": 303
  }, {
    "from": 193,
    "label": "calls",
    "to": 303
  }, {
    "from": 214,
    "label": "calls",
    "to": 303
  }, {
    "from": 218,
    "label": "calls",
    "to": 11
  }, {
    "from": 218,
    "label": "calls",
    "to": 36
  }, {
    "from": 218,
    "label": "calls",
    "to": 36
  }, {
    "from": 218,
    "label": "calls",
    "to": 304
  }, {
    "from": 7,
    "label": "calls",
    "to": 7
  }, {
    "from": 218,
    "label": "calls",
    "to": 7
  }, {
    "from": 218,
    "label": "calls",
    "to": 107
  }, {
    "from": 11,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 46,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 107,
    "label": "calls",
    "to": 305
  }, {
    "from": 161,
    "label": "calls",
    "to": 305
  }, {
    "from": 161,
    "label": "calls",
    "to": 305
  }, {
    "from": 161,
    "label": "calls",
    "to": 305
  }, {
    "from": 161,
    "label": "calls",
    "to": 305
  }, {
    "from": 193,
    "label": "calls",
    "to": 305
  }, {
    "from": 193,
    "label": "calls",
    "to": 305
  }, {
    "from": 193,
    "label": "calls",
    "to": 305
  }, {
    "from": 193,
    "label": "calls",
    "to": 305
  }, {
    "from": 193,
    "label": "calls",
    "to": 305
  }, {
    "from": 207,
    "label": "calls",
    "to": 305
  }, {
    "from": 214,
    "label": "calls",
    "to": 305
  }, {
    "from": 214,
    "label": "calls",
    "to": 305
  }, {
    "from": 218,
    "label": "calls",
    "to": 305
  }, {
    "from": 218,
    "label": "calls",
    "to": 214
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 292
  }, {
    "from": 218,
    "label": "calls",
    "to": 193
  }, {
    "from": 218,
    "label": "calls",
    "to": 193
  }, {
    "from": 218,
    "label": "calls",
    "to": 46
  }, {
    "from": 46,
    "label": "calls",
    "to": 300
  }, {
    "from": 107,
    "label": "calls",
    "to": 300
  }, {
    "from": 218,
    "label": "calls",
    "to": 300
  }, {
    "from": 218,
    "label": "calls",
    "to": 161
  }, {
    "from": 46,
    "label": "calls",
    "to": 299
  }, {
    "from": 46,
    "label": "calls",
    "to": 299
  }, {
    "from": 161,
    "label": "calls",
    "to": 299
  }, {
    "from": 161,
    "label": "calls",
    "to": 299
  }, {
    "from": 193,
    "label": "calls",
    "to": 299
  }, {
    "from": 193,
    "label": "calls",
    "to": 299
  }, {
    "from": 218,
    "label": "calls",
    "to": 299
  }, {
    "from": 294,
    "label": "calls",
    "to": 302
  }, {
    "from": 46,
    "label": "calls",
    "to": 301
  }, {
    "from": 46,
    "label": "calls",
    "to": 301
  }, {
    "from": 46,
    "label": "calls",
    "to": 301
  }, {
    "from": 46,
    "label": "calls",
    "to": 301
  }, {
    "from": 107,
    "label": "calls",
    "to": 297
  }, {
    "from": 11,
    "label": "calls",
    "to": 298
  }, {
    "from": 23,
    "label": "calls",
    "to": 298
  }, {
    "from": 23,
    "label": "calls",
    "to": 298
  }, {
    "from": 23,
    "label": "calls",
    "to": 298
  }, {
    "from": 23,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 298
  }, {
    "from": 107,
    "label": "calls",
    "to": 298
  }, {
    "from": 161,
    "label": "calls",
    "to": 298
  }, {
    "from": 161,
    "label": "calls",
    "to": 298
  }, {
    "from": 161,
    "label": "calls",
    "to": 298
  }, {
    "from": 193,
    "label": "calls",
    "to": 298
  }, {
    "from": 193,
    "label": "calls",
    "to": 298
  }, {
    "from": 193,
    "label": "calls",
    "to": 298
  }, {
    "from": 207,
    "label": "calls",
    "to": 298
  }, {
    "from": 214,
    "label": "calls",
    "to": 298
  }, {
    "from": 46,
    "label": "calls",
    "to": 306
  }, {
    "from": 46,
    "label": "calls",
    "to": 306
  }, {
    "from": 294,
    "label": "calls",
    "to": 307
  }, {
    "from": 218,
    "label": "calls",
    "to": 23
  }, {
    "from": 218,
    "label": "calls",
    "to": 23
  }, {
    "from": 218,
    "label": "calls",
    "to": 207
  }, {
    "from": 218,
    "label": "calls",
    "to": 207
  }, {
    "from": 1,
    "label": "contains",
    "to": 294
  }, {
    "from": 294,
    "label": "declares",
    "to": 2
  }, {
    "from": 294,
    "label": "declares",
    "to": 7
  }, {
    "from": 294,
    "label": "declares",
    "to": 11
  }, {
    "from": 294,
    "label": "declares",
    "to": 23
  }, {
    "from": 294,
    "label": "declares",
    "to": 36
  }, {
    "from": 294,
    "label": "declares",
    "to": 46
  }, {
    "from": 294,
    "label": "declares",
    "to": 107
  }, {
    "from": 294,
    "label": "declares",
    "to": 161
  }, {
    "from": 294,
    "label": "declares",
    "to": 193
  }, {
    "from": 294,
    "label": "declares",
    "to": 207
  }, {
    "from": 294,
    "label": "declares",
    "to": 214
  }, {
    "from": 294,
    "label": "declares",
    "to": 218
  }, {
    "from": 294,
    "label": "declares",
    "to": 292
  }, {
    "from": 295,
    "label": "calls",
    "to": 218
  }, {
    "from": 295,
    "label": "calls",
    "to": 218
  }, {
    "from": 1,
    "label": "contains",
    "to": 308
  }, {
    "from": 1,
    "label": "contains",
    "to": 309
  }, {
    "from": 308,
    "label": "initializes",
    "to": 310
  }, {
    "from": 310,
    "label": "assigns",
    "to": 311
  }, {
    "from": 308,
    "label": "initializes",
    "to": 312
  }, {
    "from": 312,
    "label": "assigns",
    "to": 313
  }, {
    "from": 308,
    "label": "initializes",
    "to": 314
  }, {
    "from": 314,
    "label": "assigns",
    "to": 315
  }, {
    "from": 308,
    "label": "initializes",
    "to": 316
  }, {
    "from": 316,
    "label": "assigns",
    "to": 317
  }, {
    "from": 308,
    "label": "initializes",
    "to": 318
  }, {
    "from": 318,
    "label": "assigns",
    "to": 319
  }, {
    "from": 308,
    "label": "initializes",
    "to": 320
  }, {
    "from": 308,
    "label": "initializes",
    "to": 321
  }, {
    "from": 308,
    "label": "initializes",
    "to": 322
  }, {
    "from": 308,
    "label": "initializes",
    "to": 323
  }, {
    "from": 308,
    "label": "initializes",
    "to": 324
  }, {
    "from": 324,
    "label": "assigns",
    "to": 325
  }, {
    "from": 325,
    "label": "assigns",
    "to": 326
  }, {
    "from": 326,
    "label": "assigns",
    "to": 327
  }, {
    "from": 325,
    "label": "assigns",
    "to": 328
  }, {
    "from": 328,
    "label": "assigns",
    "to": 329
  }, {
    "from": 325,
    "label": "assigns",
    "to": 330
  }, {
    "from": 330,
    "label": "assigns",
    "to": 331
  }, {
    "from": 325,
    "label": "assigns",
    "to": 332
  }, {
    "from": 332,
    "label": "assigns",
    "to": 333
  }, {
    "from": 325,
    "label": "assigns",
    "to": 334
  }, {
    "from": 334,
    "label": "assigns",
    "to": 335
  }, {
    "from": 325,
    "label": "assigns",
    "to": 336
  }, {
    "from": 336,
    "label": "assigns",
    "to": 337
  }, {
    "from": 325,
    "label": "assigns",
    "to": 338
  }, {
    "from": 338,
    "label": "assigns",
    "to": 339
  }, {
    "from": 308,
    "label": "initializes",
    "to": 340
  }, {
    "from": 340,
    "label": "assigns",
    "to": 341
  }, {
    "from": 341,
    "label": "assigns",
    "to": 342
  }, {
    "from": 342,
    "label": "assigns",
    "to": 343
  }, {
    "from": 341,
    "label": "assigns",
    "to": 344
  }, {
    "from": 344,
    "label": "assigns",
    "to": 345
  }, {
    "from": 341,
    "label": "assigns",
    "to": 346
  }, {
    "from": 346,
    "label": "assigns",
    "to": 347
  }, {
    "from": 341,
    "label": "assigns",
    "to": 348
  }, {
    "from": 348,
    "label": "assigns",
    "to": 349
  }, {
    "from": 308,
    "label": "initializes",
    "to": 350
  }, {
    "from": 308,
    "label": "initializes",
    "to": 351
  }, {
    "from": 351,
    "label": "assigns",
    "to": 352
  }, {
    "from": 308,
    "label": "initializes",
    "to": 353
  }, {
    "from": 353,
    "label": "assigns",
    "to": 354
  }, {
    "from": 309,
    "label": "initializes",
    "to": 355
  }, {
    "from": 355,
    "label": "requires",
    "to": 296
  }, {
    "from": 356,
    "label": "requires",
    "to": 1
  } ],
  "nodes": [ {
    "id": 0,
    "text": "",
    "type": "file"
  }, {
    "id": 1,
    "text": "optlex",
    "type": "module"
  }, {
    "id": 2,
    "text": "local function atlinestart(i)\r\n  local tok = stoks[i - 1]\r\n  if i <= 1 or tok == \"TK_EOL\" then\r\n    return true\r\n  elseif tok == \"\" then\r\n    return atlinestart(i - 1)\r\n  end\r\n  return false\r\nend",
    "type": "function"
  }, {
    "id": 3,
    "text": "local tok = stoks[i - 1]",
    "type": "statement:localassign"
  }, {
    "id": 4,
    "text": "if i <= 1 or tok == \"TK_EOL\" then\r\n    return true\r\n  elseif tok == \"\" then\r\n    return atlinestart(i - 1)\r\n  end",
    "type": "statement:if"
  }, {
    "id": 5,
    "text": "return",
    "type": "statement:keyword"
  }, {
    "id": 6,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 7,
    "text": "local function atlineend(i)\r\n  local tok = stoks[i + 1]\r\n  if i >= #stoks or tok == \"TK_EOL\" or tok == \"TK_EOS\" then\r\n    return true\r\n  elseif tok == \"\" then\r\n    return atlineend(i + 1)\r\n  end\r\n  return false\r\nend",
    "type": "function"
  }, {
    "id": 8,
    "text": "local tok = stoks[i + 1]",
    "type": "statement:localassign"
  }, {
    "id": 9,
    "text": "if i >= #stoks or tok == \"TK_EOL\" or tok == \"TK_EOS\" then\r\n    return true\r\n  elseif tok == \"\" then\r\n    return atlineend(i + 1)\r\n  end",
    "type": "statement:if"
  }, {
    "id": 10,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 11,
    "text": "local function commenteols(lcomment)\r\n  local sep = #match(lcomment, \"^%-%-%[=*%[\")\r\n  local z = sub(lcomment, sep + 1, -(sep - 1))  -- remove delims\r\n  local i, c = 1, 0\r\n  while true do\r\n    local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)\r\n    if not p then break end     -- if no matches, done\r\n    i = p + 1\r\n    c = c + 1\r\n    if #s > 0 and r ~= s then   -- skip CRLF or LFCR\r\n      i = i + 1\r\n    end\r\n  end\r\n  return c\r\nend",
    "type": "function"
  }, {
    "id": 12,
    "text": "local sep = #match(lcomment, \"^%-%-%[=*%[\")",
    "type": "statement:localassign"
  }, {
    "id": 13,
    "text": "local z = sub(lcomment, sep + 1, -(sep - 1))",
    "type": "statement:localassign"
  }, {
    "id": 14,
    "text": "local i, c = 1, 0",
    "type": "statement:localassign"
  }, {
    "id": 15,
    "text": "while true do\r\n    local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)\r\n    if not p then break end     -- if no matches, done\r\n    i = p + 1\r\n    c = c + 1\r\n    if #s > 0 and r ~= s then   -- skip CRLF or LFCR\r\n      i = i + 1\r\n    end\r\n  end",
    "type": "statement:while"
  }, {
    "id": 16,
    "text": "local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)",
    "type": "statement:localassign"
  }, {
    "id": 17,
    "text": "if not p then break end",
    "type": "statement:if"
  }, {
    "id": 18,
    "text": "i = p + 1",
    "type": "statement:assign"
  }, {
    "id": 19,
    "text": "c = c + 1",
    "type": "statement:assign"
  }, {
    "id": 20,
    "text": "if #s > 0 and r ~= s then   -- skip CRLF or LFCR\r\n      i = i + 1\r\n    end",
    "type": "statement:if"
  }, {
    "id": 21,
    "text": "i = i + 1",
    "type": "statement:assign"
  }, {
    "id": 22,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 23,
    "text": "local function checkpair(i, j)\r\n  local match = match\r\n  local t1, t2 = stoks[i], stoks[j]\r\n  --------------------------------------------------------------------\r\n  if t1 == \"TK_STRING\" or t1 == \"TK_LSTRING\" or\r\n     t2 == \"TK_STRING\" or t2 == \"TK_LSTRING\" then\r\n    return \"\"\r\n  --------------------------------------------------------------------\r\n  elseif t1 == \"TK_OP\" or t2 == \"TK_OP\" then\r\n    if (t1 == \"TK_OP\" and (t2 == \"TK_KEYWORD\" or t2 == \"TK_NAME\")) or\r\n       (t2 == \"TK_OP\" and (t1 == \"TK_KEYWORD\" or t1 == \"TK_NAME\")) then\r\n      return \"\"\r\n    end\r\n    if t1 == \"TK_OP\" and t2 == \"TK_OP\" then\r\n      -- for TK_OP/TK_OP pairs, see notes in technotes.txt\r\n      local op, op2 = sinfos[i], sinfos[j]\r\n      if (match(op, \"^%.%.?$\") and match(op2, \"^%.\")) or\r\n         (match(op, \"^[~=<>]$\") and op2 == \"=\") or\r\n         (op == \"[\" and (op2 == \"[\" or op2 == \"=\")) then\r\n        return \" \"\r\n      end\r\n      return \"\"\r\n    end\r\n    -- \"TK_OP\" + \"TK_NUMBER\" case\r\n    local op = sinfos[i]\r\n    if t2 == \"TK_OP\" then op = sinfos[j] end\r\n    if match(op, \"^%.%.?%.?$\") then\r\n      return \" \"\r\n    end\r\n    return \"\"\r\n  --------------------------------------------------------------------\r\n  else-- \"TK_KEYWORD\" | \"TK_NAME\" | \"TK_NUMBER\" then\r\n    return \" \"\r\n  --------------------------------------------------------------------\r\n  end\r\nend",
    "type": "function"
  }, {
    "id": 24,
    "text": "local match = match",
    "type": "statement:localassign"
  }, {
    "id": 25,
    "text": "local t1, t2 = stoks[i], stoks[j]",
    "type": "statement:localassign"
  }, {
    "id": 26,
    "text": "if t1 == \"TK_STRING\" or t1 == \"TK_LSTRING\" or\r\n     t2 == \"TK_STRING\" or t2 == \"TK_LSTRING\" then\r\n    return \"\"\r\n  --------------------------------------------------------------------\r\n  elseif t1 == \"TK_OP\" or t2 == \"TK_OP\" then\r\n    if (t1 == \"TK_OP\" and (t2 == \"TK_KEYWORD\" or t2 == \"TK_NAME\")) or\r\n       (t2 == \"TK_OP\" and (t1 == \"TK_KEYWORD\" or t1 == \"TK_NAME\")) then\r\n      return \"\"\r\n    end\r\n    if t1 == \"TK_OP\" and t2 == \"TK_OP\" then\r\n      -- for TK_OP/TK_OP pairs, see notes in technotes.txt\r\n      local op, op2 = sinfos[i], sinfos[j]\r\n      if (match(op, \"^%.%.?$\") and match(op2, \"^%.\")) or\r\n         (match(op, \"^[~=<>]$\") and op2 == \"=\") or\r\n         (op == \"[\" and (op2 == \"[\" or op2 == \"=\")) then\r\n        return \" \"\r\n      end\r\n      return \"\"\r\n    end\r\n    -- \"TK_OP\" + \"TK_NUMBER\" case\r\n    local op = sinfos[i]\r\n    if t2 == \"TK_OP\" then op = sinfos[j] end\r\n    if match(op, \"^%.%.?%.?$\") then\r\n      return \" \"\r\n    end\r\n    return \"\"\r\n  --------------------------------------------------------------------\r\n  else-- \"TK_KEYWORD\" | \"TK_NAME\" | \"TK_NUMBER\" then\r\n    return \" \"\r\n  --------------------------------------------------------------------\r\n  end",
    "type": "statement:if"
  }, {
    "id": 27,
    "text": "if (t1 == \"TK_OP\" and (t2 == \"TK_KEYWORD\" or t2 == \"TK_NAME\")) or\r\n       (t2 == \"TK_OP\" and (t1 == \"TK_KEYWORD\" or t1 == \"TK_NAME\")) then\r\n      return \"\"\r\n    end",
    "type": "statement:if"
  }, {
    "id": 28,
    "text": "if t1 == \"TK_OP\" and t2 == \"TK_OP\" then\r\n      -- for TK_OP/TK_OP pairs, see notes in technotes.txt\r\n      local op, op2 = sinfos[i], sinfos[j]\r\n      if (match(op, \"^%.%.?$\") and match(op2, \"^%.\")) or\r\n         (match(op, \"^[~=<>]$\") and op2 == \"=\") or\r\n         (op == \"[\" and (op2 == \"[\" or op2 == \"=\")) then\r\n        return \" \"\r\n      end\r\n      return \"\"\r\n    end",
    "type": "statement:if"
  }, {
    "id": 29,
    "text": "local op, op2 = sinfos[i], sinfos[j]",
    "type": "statement:localassign"
  }, {
    "id": 30,
    "text": "if (match(op, \"^%.%.?$\") and match(op2, \"^%.\")) or\r\n         (match(op, \"^[~=<>]$\") and op2 == \"=\") or\r\n         (op == \"[\" and (op2 == \"[\" or op2 == \"=\")) then\r\n        return \" \"\r\n      end",
    "type": "statement:if"
  }, {
    "id": 31,
    "text": "local op = sinfos[i]",
    "type": "statement:localassign"
  }, {
    "id": 32,
    "text": "if t2 == \"TK_OP\" then op = sinfos[j] end",
    "type": "statement:if"
  }, {
    "id": 33,
    "text": "op = sinfos[j]",
    "type": "statement:assign"
  }, {
    "id": 34,
    "text": "if match(op, \"^%.%.?%.?$\") then\r\n      return \" \"\r\n    end",
    "type": "statement:if"
  }, {
    "id": 35,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 36,
    "text": "local function repack_tokens()\r\n  local dtoks, dinfos, dtoklns = {}, {}, {}\r\n  local j = 1\r\n  for i = 1, #stoks do\r\n    local tok = stoks[i]\r\n    if tok ~= \"\" then\r\n      dtoks[j], dinfos[j], dtoklns[j] = tok, sinfos[i], stoklns[i]\r\n      j = j + 1\r\n    end\r\n  end\r\n  stoks, sinfos, stoklns = dtoks, dinfos, dtoklns\r\nend",
    "type": "function"
  }, {
    "id": 37,
    "text": "local dtoks, dinfos, dtoklns = {}, {}, {}",
    "type": "statement:localassign"
  }, {
    "id": 38,
    "text": "local j = 1",
    "type": "statement:localassign"
  }, {
    "id": 39,
    "text": "for i = 1, #stoks do\r\n    local tok = stoks[i]\r\n    if tok ~= \"\" then\r\n      dtoks[j], dinfos[j], dtoklns[j] = tok, sinfos[i], stoklns[i]\r\n      j = j + 1\r\n    end\r\n  end",
    "type": "statement:numericfor"
  }, {
    "id": 40,
    "text": "local tok = stoks[i]",
    "type": "statement:localassign"
  }, {
    "id": 41,
    "text": "if tok ~= \"\" then\r\n      dtoks[j], dinfos[j], dtoklns[j] = tok, sinfos[i], stoklns[i]\r\n      j = j + 1\r\n    end",
    "type": "statement:if"
  }, {
    "id": 42,
    "text": "dtoks[j], dinfos[j], dtoklns[j] = tok, sinfos[i], stoklns[i]",
    "type": "statement:assign"
  }, {
    "id": 43,
    "text": "j = j + 1",
    "type": "statement:assign"
  }, {
    "id": 44,
    "text": "stoks, sinfos, stoklns = dtoks, dinfos, dtoklns",
    "type": "statement:assign"
  }, {
    "id": 45,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 46,
    "text": "local function do_number(i)\r\n  local before = sinfos[i]      -- 'before'\r\n  local z = before              -- working representation\r\n  local y                       -- 'after', if better\r\n  --------------------------------------------------------------------\r\n  if match(z, \"^0[xX]\") then            -- hexadecimal number\r\n    local v = base.tostring(base.tonumber(z))\r\n    if #v <= #z then\r\n      z = v  -- change to integer, AND continue\r\n    else\r\n      return  -- no change; stick to hex\r\n    end\r\n  end\r\n  --------------------------------------------------------------------\r\n  if match(z, \"^%d+%.?0*$\") then        -- integer or has useless frac\r\n    z = match(z, \"^(%d+)%.?0*$\")  -- int portion only\r\n    if z + 0 > 0 then\r\n      z = match(z, \"^0*([1-9]%d*)$\")  -- remove leading zeros\r\n      local v = #match(z, \"0*$\")\r\n      local nv = base.tostring(v)\r\n      if v > #nv + 1 then  -- scientific is shorter\r\n        z = sub(z, 1, #z - v)..\"e\"..nv\r\n      end\r\n      y = z\r\n    else\r\n      y = \"0\"  -- basic zero\r\n    end\r\n  --------------------------------------------------------------------\r\n  elseif not match(z, \"[eE]\") then      -- number with fraction part\r\n    local p, q = match(z, \"^(%d*)%.(%d+)$\")  -- split\r\n    if p == \"\" then p = 0 end  -- int part zero\r\n    if q + 0 == 0 and p == 0 then\r\n      y = \"0\"  -- degenerate .000 case\r\n    else\r\n      -- now, q > 0 holds and p is a number\r\n      local v = #match(q, \"0*$\")  -- remove trailing zeros\r\n      if v > 0 then\r\n        q = sub(q, 1, #q - v)\r\n      end\r\n      -- if p > 0, nothing else we can do to simplify p.q case\r\n      if p + 0 > 0 then\r\n        y = p..\".\"..q\r\n      else\r\n        y = \".\"..q  -- tentative, e.g. .000123\r\n        local v = #match(q, \"^0*\")  -- # leading spaces\r\n        local w = #q - v            -- # significant digits\r\n        local nv = base.tostring(#q)\r\n        -- e.g. compare 123e-6 versus .000123\r\n        if w + 2 + #nv < 1 + #q then\r\n          y = sub(q, -w)..\"e-\"..nv\r\n        end\r\n      end\r\n    end\r\n  --------------------------------------------------------------------\r\n  else                                  -- scientific number\r\n    local sig, ex = match(z, \"^([^eE]+)[eE]([%+%-]?%d+)$\")\r\n    ex = base.tonumber(ex)\r\n    -- if got \".\", shift out fractional portion of significand\r\n    local p, q = match(sig, \"^(%d*)%.(%d*)$\")\r\n    if p then\r\n      ex = ex - #q\r\n      sig = p..q\r\n    end\r\n    if sig + 0 == 0 then\r\n      y = \"0\"  -- basic zero\r\n    else\r\n      local v = #match(sig, \"^0*\")  -- remove leading zeros\r\n      sig = sub(sig, v + 1)\r\n      v = #match(sig, \"0*$\") -- shift out trailing zeros\r\n      if v > 0 then\r\n        sig = sub(sig, 1, #sig - v)\r\n        ex = ex + v\r\n      end\r\n      -- examine exponent and determine which format is best\r\n      local nex = base.tostring(ex)\r\n      if ex == 0 then  -- it's just an integer\r\n        y = sig\r\n      elseif ex > 0 and (ex <= 1 + #nex) then  -- a number\r\n        y = sig..rep(\"0\", ex)\r\n      elseif ex < 0 and (ex >= -#sig) then  -- fraction, e.g. .123\r\n        v = #sig + ex\r\n        y = sub(sig, 1, v)..\".\"..sub(sig, v + 1)\r\n      elseif ex < 0 and (#nex >= -ex - #sig) then\r\n        -- e.g. compare 1234e-5 versus .01234\r\n        -- gives: #sig + 1 + #nex >= 1 + (-ex - #sig) + #sig\r\n        --     -> #nex >= -ex - #sig\r\n        v = -ex - #sig\r\n        y = \".\"..rep(\"0\", v)..sig\r\n      else  -- non-canonical scientific representation\r\n        y = sig..\"e\"..ex\r\n      end\r\n    end--if sig\r\n  end\r\n  --------------------------------------------------------------------\r\n  if y and y ~= sinfos[i] then\r\n    if opt_details then\r\n      print(\"<number> (line \"..stoklns[i]..\") \"..sinfos[i]..\" -> \"..y)\r\n      opt_details = opt_details + 1\r\n    end\r\n    sinfos[i] = y\r\n  end\r\nend",
    "type": "function"
  }, {
    "id": 47,
    "text": "local before = sinfos[i]",
    "type": "statement:localassign"
  }, {
    "id": 48,
    "text": "local z = before",
    "type": "statement:localassign"
  }, {
    "id": 49,
    "text": "local y",
    "type": "statement:localassign"
  }, {
    "id": 50,
    "text": "if match(z, \"^0[xX]\") then            -- hexadecimal number\r\n    local v = base.tostring(base.tonumber(z))\r\n    if #v <= #z then\r\n      z = v  -- change to integer, AND continue\r\n    else\r\n      return  -- no change; stick to hex\r\n    end\r\n  end",
    "type": "statement:if"
  }, {
    "id": 51,
    "text": "local v = base.tostring(base.tonumber(z))",
    "type": "statement:localassign"
  }, {
    "id": 52,
    "text": "if #v <= #z then\r\n      z = v  -- change to integer, AND continue\r\n    else\r\n      return  -- no change; stick to hex\r\n    end",
    "type": "statement:if"
  }, {
    "id": 53,
    "text": "z = v",
    "type": "statement:assign"
  }, {
    "id": 54,
    "text": "if match(z, \"^%d+%.?0*$\") then        -- integer or has useless frac\r\n    z = match(z, \"^(%d+)%.?0*$\")  -- int portion only\r\n    if z + 0 > 0 then\r\n      z = match(z, \"^0*([1-9]%d*)$\")  -- remove leading zeros\r\n      local v = #match(z, \"0*$\")\r\n      local nv = base.tostring(v)\r\n      if v > #nv + 1 then  -- scientific is shorter\r\n        z = sub(z, 1, #z - v)..\"e\"..nv\r\n      end\r\n      y = z\r\n    else\r\n      y = \"0\"  -- basic zero\r\n    end\r\n  --------------------------------------------------------------------\r\n  elseif not match(z, \"[eE]\") then      -- number with fraction part\r\n    local p, q = match(z, \"^(%d*)%.(%d+)$\")  -- split\r\n    if p == \"\" then p = 0 end  -- int part zero\r\n    if q + 0 == 0 and p == 0 then\r\n      y = \"0\"  -- degenerate .000 case\r\n    else\r\n      -- now, q > 0 holds and p is a number\r\n      local v = #match(q, \"0*$\")  -- remove trailing zeros\r\n      if v > 0 then\r\n        q = sub(q, 1, #q - v)\r\n      end\r\n      -- if p > 0, nothing else we can do to simplify p.q case\r\n      if p + 0 > 0 then\r\n        y = p..\".\"..q\r\n      else\r\n        y = \".\"..q  -- tentative, e.g. .000123\r\n        local v = #match(q, \"^0*\")  -- # leading spaces\r\n        local w = #q - v            -- # significant digits\r\n        local nv = base.tostring(#q)\r\n        -- e.g. compare 123e-6 versus .000123\r\n        if w + 2 + #nv < 1 + #q then\r\n          y = sub(q, -w)..\"e-\"..nv\r\n        end\r\n      end\r\n    end\r\n  --------------------------------------------------------------------\r\n  else                                  -- scientific number\r\n    local sig, ex = match(z, \"^([^eE]+)[eE]([%+%-]?%d+)$\")\r\n    ex = base.tonumber(ex)\r\n    -- if got \".\", shift out fractional portion of significand\r\n    local p, q = match(sig, \"^(%d*)%.(%d*)$\")\r\n    if p then\r\n      ex = ex - #q\r\n      sig = p..q\r\n    end\r\n    if sig + 0 == 0 then\r\n      y = \"0\"  -- basic zero\r\n    else\r\n      local v = #match(sig, \"^0*\")  -- remove leading zeros\r\n      sig = sub(sig, v + 1)\r\n      v = #match(sig, \"0*$\") -- shift out trailing zeros\r\n      if v > 0 then\r\n        sig = sub(sig, 1, #sig - v)\r\n        ex = ex + v\r\n      end\r\n      -- examine exponent and determine which format is best\r\n      local nex = base.tostring(ex)\r\n      if ex == 0 then  -- it's just an integer\r\n        y = sig\r\n      elseif ex > 0 and (ex <= 1 + #nex) then  -- a number\r\n        y = sig..rep(\"0\", ex)\r\n      elseif ex < 0 and (ex >= -#sig) then  -- fraction, e.g. .123\r\n        v = #sig + ex\r\n        y = sub(sig, 1, v)..\".\"..sub(sig, v + 1)\r\n      elseif ex < 0 and (#nex >= -ex - #sig) then\r\n        -- e.g. compare 1234e-5 versus .01234\r\n        -- gives: #sig + 1 + #nex >= 1 + (-ex - #sig) + #sig\r\n        --     -> #nex >= -ex - #sig\r\n        v = -ex - #sig\r\n        y = \".\"..rep(\"0\", v)..sig\r\n      else  -- non-canonical scientific representation\r\n        y = sig..\"e\"..ex\r\n      end\r\n    end--if sig\r\n  end",
    "type": "statement:if"
  }, {
    "id": 55,
    "text": "z = match(z, \"^(%d+)%.?0*$\")",
    "type": "statement:assign"
  }, {
    "id": 56,
    "text": "if z + 0 > 0 then\r\n      z = match(z, \"^0*([1-9]%d*)$\")  -- remove leading zeros\r\n      local v = #match(z, \"0*$\")\r\n      local nv = base.tostring(v)\r\n      if v > #nv + 1 then  -- scientific is shorter\r\n        z = sub(z, 1, #z - v)..\"e\"..nv\r\n      end\r\n      y = z\r\n    else\r\n      y = \"0\"  -- basic zero\r\n    end",
    "type": "statement:if"
  }, {
    "id": 57,
    "text": "z = match(z, \"^0*([1-9]%d*)$\")",
    "type": "statement:assign"
  }, {
    "id": 58,
    "text": "local v = #match(z, \"0*$\")",
    "type": "statement:localassign"
  }, {
    "id": 59,
    "text": "local nv = base.tostring(v)",
    "type": "statement:localassign"
  }, {
    "id": 60,
    "text": "if v > #nv + 1 then  -- scientific is shorter\r\n        z = sub(z, 1, #z - v)..\"e\"..nv\r\n      end",
    "type": "statement:if"
  }, {
    "id": 61,
    "text": "z = sub(z, 1, #z - v)..\"e\"..nv",
    "type": "statement:assign"
  }, {
    "id": 62,
    "text": "y = z",
    "type": "statement:assign"
  }, {
    "id": 63,
    "text": "y = \"0\"",
    "type": "statement:assign"
  }, {
    "id": 64,
    "text": "local p, q = match(z, \"^(%d*)%.(%d+)$\")",
    "type": "statement:localassign"
  }, {
    "id": 65,
    "text": "if p == \"\" then p = 0 end",
    "type": "statement:if"
  }, {
    "id": 66,
    "text": "p = 0",
    "type": "statement:assign"
  }, {
    "id": 67,
    "text": "if q + 0 == 0 and p == 0 then\r\n      y = \"0\"  -- degenerate .000 case\r\n    else\r\n      -- now, q > 0 holds and p is a number\r\n      local v = #match(q, \"0*$\")  -- remove trailing zeros\r\n      if v > 0 then\r\n        q = sub(q, 1, #q - v)\r\n      end\r\n      -- if p > 0, nothing else we can do to simplify p.q case\r\n      if p + 0 > 0 then\r\n        y = p..\".\"..q\r\n      else\r\n        y = \".\"..q  -- tentative, e.g. .000123\r\n        local v = #match(q, \"^0*\")  -- # leading spaces\r\n        local w = #q - v            -- # significant digits\r\n        local nv = base.tostring(#q)\r\n        -- e.g. compare 123e-6 versus .000123\r\n        if w + 2 + #nv < 1 + #q then\r\n          y = sub(q, -w)..\"e-\"..nv\r\n        end\r\n      end\r\n    end",
    "type": "statement:if"
  }, {
    "id": 68,
    "text": "local v = #match(q, \"0*$\")",
    "type": "statement:localassign"
  }, {
    "id": 69,
    "text": "if v > 0 then\r\n        q = sub(q, 1, #q - v)\r\n      end",
    "type": "statement:if"
  }, {
    "id": 70,
    "text": "q = sub(q, 1, #q - v)",
    "type": "statement:assign"
  }, {
    "id": 71,
    "text": "if p + 0 > 0 then\r\n        y = p..\".\"..q\r\n      else\r\n        y = \".\"..q  -- tentative, e.g. .000123\r\n        local v = #match(q, \"^0*\")  -- # leading spaces\r\n        local w = #q - v            -- # significant digits\r\n        local nv = base.tostring(#q)\r\n        -- e.g. compare 123e-6 versus .000123\r\n        if w + 2 + #nv < 1 + #q then\r\n          y = sub(q, -w)..\"e-\"..nv\r\n        end\r\n      end",
    "type": "statement:if"
  }, {
    "id": 72,
    "text": "y = p..\".\"..q",
    "type": "statement:assign"
  }, {
    "id": 73,
    "text": "y = \".\"..q",
    "type": "statement:assign"
  }, {
    "id": 74,
    "text": "local v = #match(q, \"^0*\")",
    "type": "statement:localassign"
  }, {
    "id": 75,
    "text": "local w = #q - v",
    "type": "statement:localassign"
  }, {
    "id": 76,
    "text": "local nv = base.tostring(#q)",
    "type": "statement:localassign"
  }, {
    "id": 77,
    "text": "if w + 2 + #nv < 1 + #q then\r\n          y = sub(q, -w)..\"e-\"..nv\r\n        end",
    "type": "statement:if"
  }, {
    "id": 78,
    "text": "y = sub(q, -w)..\"e-\"..nv",
    "type": "statement:assign"
  }, {
    "id": 79,
    "text": "local sig, ex = match(z, \"^([^eE]+)[eE]([%+%-]?%d+)$\")",
    "type": "statement:localassign"
  }, {
    "id": 80,
    "text": "ex = base.tonumber(ex)",
    "type": "statement:assign"
  }, {
    "id": 81,
    "text": "local p, q = match(sig, \"^(%d*)%.(%d*)$\")",
    "type": "statement:localassign"
  }, {
    "id": 82,
    "text": "if p then\r\n      ex = ex - #q\r\n      sig = p..q\r\n    end",
    "type": "statement:if"
  }, {
    "id": 83,
    "text": "ex = ex - #q",
    "type": "statement:assign"
  }, {
    "id": 84,
    "text": "sig = p..q",
    "type": "statement:assign"
  }, {
    "id": 85,
    "text": "if sig + 0 == 0 then\r\n      y = \"0\"  -- basic zero\r\n    else\r\n      local v = #match(sig, \"^0*\")  -- remove leading zeros\r\n      sig = sub(sig, v + 1)\r\n      v = #match(sig, \"0*$\") -- shift out trailing zeros\r\n      if v > 0 then\r\n        sig = sub(sig, 1, #sig - v)\r\n        ex = ex + v\r\n      end\r\n      -- examine exponent and determine which format is best\r\n      local nex = base.tostring(ex)\r\n      if ex == 0 then  -- it's just an integer\r\n        y = sig\r\n      elseif ex > 0 and (ex <= 1 + #nex) then  -- a number\r\n        y = sig..rep(\"0\", ex)\r\n      elseif ex < 0 and (ex >= -#sig) then  -- fraction, e.g. .123\r\n        v = #sig + ex\r\n        y = sub(sig, 1, v)..\".\"..sub(sig, v + 1)\r\n      elseif ex < 0 and (#nex >= -ex - #sig) then\r\n        -- e.g. compare 1234e-5 versus .01234\r\n        -- gives: #sig + 1 + #nex >= 1 + (-ex - #sig) + #sig\r\n        --     -> #nex >= -ex - #sig\r\n        v = -ex - #sig\r\n        y = \".\"..rep(\"0\", v)..sig\r\n      else  -- non-canonical scientific representation\r\n        y = sig..\"e\"..ex\r\n      end\r\n    end",
    "type": "statement:if"
  }, {
    "id": 86,
    "text": "local v = #match(sig, \"^0*\")",
    "type": "statement:localassign"
  }, {
    "id": 87,
    "text": "sig = sub(sig, v + 1)",
    "type": "statement:assign"
  }, {
    "id": 88,
    "text": "v = #match(sig, \"0*$\")",
    "type": "statement:assign"
  }, {
    "id": 89,
    "text": "if v > 0 then\r\n        sig = sub(sig, 1, #sig - v)\r\n        ex = ex + v\r\n      end",
    "type": "statement:if"
  }, {
    "id": 90,
    "text": "sig = sub(sig, 1, #sig - v)",
    "type": "statement:assign"
  }, {
    "id": 91,
    "text": "ex = ex + v",
    "type": "statement:assign"
  }, {
    "id": 92,
    "text": "local nex = base.tostring(ex)",
    "type": "statement:localassign"
  }, {
    "id": 93,
    "text": "if ex == 0 then  -- it's just an integer\r\n        y = sig\r\n      elseif ex > 0 and (ex <= 1 + #nex) then  -- a number\r\n        y = sig..rep(\"0\", ex)\r\n      elseif ex < 0 and (ex >= -#sig) then  -- fraction, e.g. .123\r\n        v = #sig + ex\r\n        y = sub(sig, 1, v)..\".\"..sub(sig, v + 1)\r\n      elseif ex < 0 and (#nex >= -ex - #sig) then\r\n        -- e.g. compare 1234e-5 versus .01234\r\n        -- gives: #sig + 1 + #nex >= 1 + (-ex - #sig) + #sig\r\n        --     -> #nex >= -ex - #sig\r\n        v = -ex - #sig\r\n        y = \".\"..rep(\"0\", v)..sig\r\n      else  -- non-canonical scientific representation\r\n        y = sig..\"e\"..ex\r\n      end",
    "type": "statement:if"
  }, {
    "id": 94,
    "text": "y = sig",
    "type": "statement:assign"
  }, {
    "id": 95,
    "text": "y = sig..rep(\"0\", ex)",
    "type": "statement:assign"
  }, {
    "id": 96,
    "text": "v = #sig + ex",
    "type": "statement:assign"
  }, {
    "id": 97,
    "text": "y = sub(sig, 1, v)..\".\"..sub(sig, v + 1)",
    "type": "statement:assign"
  }, {
    "id": 98,
    "text": "v = -ex - #sig",
    "type": "statement:assign"
  }, {
    "id": 99,
    "text": "y = \".\"..rep(\"0\", v)..sig",
    "type": "statement:assign"
  }, {
    "id": 100,
    "text": "y = sig..\"e\"..ex",
    "type": "statement:assign"
  }, {
    "id": 101,
    "text": "if y and y ~= sinfos[i] then\r\n    if opt_details then\r\n      print(\"<number> (line \"..stoklns[i]..\") \"..sinfos[i]..\" -> \"..y)\r\n      opt_details = opt_details + 1\r\n    end\r\n    sinfos[i] = y\r\n  end",
    "type": "statement:if"
  }, {
    "id": 102,
    "text": "if opt_details then\r\n      print(\"<number> (line \"..stoklns[i]..\") \"..sinfos[i]..\" -> \"..y)\r\n      opt_details = opt_details + 1\r\n    end",
    "type": "statement:if"
  }, {
    "id": 103,
    "text": "print(\"<number> (line \"..stoklns[i]..\") \"..sinfos[i]..\" -> \"..y)",
    "type": "statement:functioncall"
  }, {
    "id": 104,
    "text": "opt_details = opt_details + 1",
    "type": "statement:assign"
  }, {
    "id": 105,
    "text": "sinfos[i] = y",
    "type": "statement:assign"
  }, {
    "id": 106,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 107,
    "text": "local function do_string(I)\r\n  local info = sinfos[I]\r\n  local delim = sub(info, 1, 1)                 -- delimiter used\r\n  local ndelim = (delim == \"'\") and '\"' or \"'\"  -- opposite \" <-> '\r\n  local z = sub(info, 2, -2)                    -- actual string\r\n  local i = 1\r\n  local c_delim, c_ndelim = 0, 0                -- \"/' counts\r\n  --------------------------------------------------------------------\r\n  while i <= #z do\r\n    local c = sub(z, i, i)\r\n    ----------------------------------------------------------------\r\n    if c == \"\\\\\" then                   -- escaped stuff\r\n      local j = i + 1\r\n      local d = sub(z, j, j)\r\n      local p = find(\"abfnrtv\\\\\\n\\r\\\"\\'0123456789\", d, 1, true)\r\n      ------------------------------------------------------------\r\n      if not p then                     -- \\<char> -- remove \\\r\n        z = sub(z, 1, i - 1)..sub(z, j)\r\n        i = i + 1\r\n      ------------------------------------------------------------\r\n      elseif p <= 8 then                -- \\a\\b\\f\\n\\r\\t\\v\\\\\r\n        i = i + 2                       -- no change\r\n      ------------------------------------------------------------\r\n      elseif p <= 10 then               -- \\<eol> -- normalize EOL\r\n        local eol = sub(z, j, j + 1)\r\n        if eol == \"\\r\\n\" or eol == \"\\n\\r\" then\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 2)\r\n        elseif p == 10 then  -- \\r case\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 1)\r\n        end\r\n        i = i + 2\r\n      ------------------------------------------------------------\r\n      elseif p <= 12 then               -- \\\"\\' -- remove \\ for ndelim\r\n        if d == delim then\r\n          c_delim = c_delim + 1\r\n          i = i + 2\r\n        else\r\n          c_ndelim = c_ndelim + 1\r\n          z = sub(z, 1, i - 1)..sub(z, j)\r\n          i = i + 1\r\n        end\r\n      ------------------------------------------------------------\r\n      else                              -- \\ddd -- various steps\r\n        local s = match(z, \"^(%d%d?%d?)\", j)\r\n        j = i + 1 + #s                  -- skip to location\r\n        local cv = s + 0\r\n        local cc = string.char(cv)\r\n        local p = find(\"\\a\\b\\f\\n\\r\\t\\v\", cc, 1, true)\r\n        if p then                       -- special escapes\r\n          s = \"\\\\\"..sub(\"abfnrtv\", p, p)\r\n        elseif cv < 32 then             -- normalized \\ddd\r\n          s = \"\\\\\"..cv\r\n        elseif cc == delim then         -- \\<delim>\r\n          s = \"\\\\\"..cc\r\n          c_delim = c_delim + 1\r\n        elseif cc == \"\\\\\" then          -- \\\\\r\n          s = \"\\\\\\\\\"\r\n        else                            -- literal character\r\n          s = cc\r\n          if cc == ndelim then\r\n            c_ndelim = c_ndelim + 1\r\n          end\r\n        end\r\n        z = sub(z, 1, i - 1)..s..sub(z, j)\r\n        i = i + #s\r\n      ------------------------------------------------------------\r\n      end--if p\r\n    ----------------------------------------------------------------\r\n    else-- c ~= \"\\\\\"                    -- <other> -- no change\r\n      i = i + 1\r\n      if c == ndelim then  -- count ndelim, for switching delimiters\r\n        c_ndelim = c_ndelim + 1\r\n      end\r\n    ----------------------------------------------------------------\r\n    end--if c\r\n  end--while\r\n  --------------------------------------------------------------------\r\n  -- switching delimiters, a long-winded derivation:\r\n  -- (1) delim takes 2+2*c_delim bytes, ndelim takes c_ndelim bytes\r\n  -- (2) delim becomes c_delim bytes, ndelim becomes 2+2*c_ndelim bytes\r\n  -- simplifying the condition (1)>(2) --> c_delim > c_ndelim\r\n  if c_delim > c_ndelim then\r\n    i = 1\r\n    while i <= #z do\r\n      local p, q, r = find(z, \"([\\'\\\"])\", i)\r\n      if not p then break end\r\n      if r == delim then                -- \\<delim> -> <delim>\r\n        z = sub(z, 1, p - 2)..sub(z, p)\r\n        i = p\r\n      else-- r == ndelim                -- <ndelim> -> \\<ndelim>\r\n        z = sub(z, 1, p - 1)..\"\\\\\"..sub(z, p)\r\n        i = p + 2\r\n      end\r\n    end--while\r\n    delim = ndelim  -- actually change delimiters\r\n  end\r\n  --------------------------------------------------------------------\r\n  z = delim..z..delim\r\n  if z ~= sinfos[I] then\r\n    if opt_details then\r\n      print(\"<string> (line \"..stoklns[I]..\") \"..sinfos[I]..\" -> \"..z)\r\n      opt_details = opt_details + 1\r\n    end\r\n    sinfos[I] = z\r\n  end\r\nend",
    "type": "function"
  }, {
    "id": 108,
    "text": "local info = sinfos[I]",
    "type": "statement:localassign"
  }, {
    "id": 109,
    "text": "local delim = sub(info, 1, 1)",
    "type": "statement:localassign"
  }, {
    "id": 110,
    "text": "local ndelim = (delim == \"'\") and '\"' or \"'\"",
    "type": "statement:localassign"
  }, {
    "id": 111,
    "text": "local z = sub(info, 2, -2)",
    "type": "statement:localassign"
  }, {
    "id": 112,
    "text": "local i = 1",
    "type": "statement:localassign"
  }, {
    "id": 113,
    "text": "local c_delim, c_ndelim = 0, 0",
    "type": "statement:localassign"
  }, {
    "id": 114,
    "text": "while i <= #z do\r\n    local c = sub(z, i, i)\r\n    ----------------------------------------------------------------\r\n    if c == \"\\\\\" then                   -- escaped stuff\r\n      local j = i + 1\r\n      local d = sub(z, j, j)\r\n      local p = find(\"abfnrtv\\\\\\n\\r\\\"\\'0123456789\", d, 1, true)\r\n      ------------------------------------------------------------\r\n      if not p then                     -- \\<char> -- remove \\\r\n        z = sub(z, 1, i - 1)..sub(z, j)\r\n        i = i + 1\r\n      ------------------------------------------------------------\r\n      elseif p <= 8 then                -- \\a\\b\\f\\n\\r\\t\\v\\\\\r\n        i = i + 2                       -- no change\r\n      ------------------------------------------------------------\r\n      elseif p <= 10 then               -- \\<eol> -- normalize EOL\r\n        local eol = sub(z, j, j + 1)\r\n        if eol == \"\\r\\n\" or eol == \"\\n\\r\" then\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 2)\r\n        elseif p == 10 then  -- \\r case\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 1)\r\n        end\r\n        i = i + 2\r\n      ------------------------------------------------------------\r\n      elseif p <= 12 then               -- \\\"\\' -- remove \\ for ndelim\r\n        if d == delim then\r\n          c_delim = c_delim + 1\r\n          i = i + 2\r\n        else\r\n          c_ndelim = c_ndelim + 1\r\n          z = sub(z, 1, i - 1)..sub(z, j)\r\n          i = i + 1\r\n        end\r\n      ------------------------------------------------------------\r\n      else                              -- \\ddd -- various steps\r\n        local s = match(z, \"^(%d%d?%d?)\", j)\r\n        j = i + 1 + #s                  -- skip to location\r\n        local cv = s + 0\r\n        local cc = string.char(cv)\r\n        local p = find(\"\\a\\b\\f\\n\\r\\t\\v\", cc, 1, true)\r\n        if p then                       -- special escapes\r\n          s = \"\\\\\"..sub(\"abfnrtv\", p, p)\r\n        elseif cv < 32 then             -- normalized \\ddd\r\n          s = \"\\\\\"..cv\r\n        elseif cc == delim then         -- \\<delim>\r\n          s = \"\\\\\"..cc\r\n          c_delim = c_delim + 1\r\n        elseif cc == \"\\\\\" then          -- \\\\\r\n          s = \"\\\\\\\\\"\r\n        else                            -- literal character\r\n          s = cc\r\n          if cc == ndelim then\r\n            c_ndelim = c_ndelim + 1\r\n          end\r\n        end\r\n        z = sub(z, 1, i - 1)..s..sub(z, j)\r\n        i = i + #s\r\n      ------------------------------------------------------------\r\n      end--if p\r\n    ----------------------------------------------------------------\r\n    else-- c ~= \"\\\\\"                    -- <other> -- no change\r\n      i = i + 1\r\n      if c == ndelim then  -- count ndelim, for switching delimiters\r\n        c_ndelim = c_ndelim + 1\r\n      end\r\n    ----------------------------------------------------------------\r\n    end--if c\r\n  end",
    "type": "statement:while"
  }, {
    "id": 115,
    "text": "local c = sub(z, i, i)",
    "type": "statement:localassign"
  }, {
    "id": 116,
    "text": "if c == \"\\\\\" then                   -- escaped stuff\r\n      local j = i + 1\r\n      local d = sub(z, j, j)\r\n      local p = find(\"abfnrtv\\\\\\n\\r\\\"\\'0123456789\", d, 1, true)\r\n      ------------------------------------------------------------\r\n      if not p then                     -- \\<char> -- remove \\\r\n        z = sub(z, 1, i - 1)..sub(z, j)\r\n        i = i + 1\r\n      ------------------------------------------------------------\r\n      elseif p <= 8 then                -- \\a\\b\\f\\n\\r\\t\\v\\\\\r\n        i = i + 2                       -- no change\r\n      ------------------------------------------------------------\r\n      elseif p <= 10 then               -- \\<eol> -- normalize EOL\r\n        local eol = sub(z, j, j + 1)\r\n        if eol == \"\\r\\n\" or eol == \"\\n\\r\" then\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 2)\r\n        elseif p == 10 then  -- \\r case\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 1)\r\n        end\r\n        i = i + 2\r\n      ------------------------------------------------------------\r\n      elseif p <= 12 then               -- \\\"\\' -- remove \\ for ndelim\r\n        if d == delim then\r\n          c_delim = c_delim + 1\r\n          i = i + 2\r\n        else\r\n          c_ndelim = c_ndelim + 1\r\n          z = sub(z, 1, i - 1)..sub(z, j)\r\n          i = i + 1\r\n        end\r\n      ------------------------------------------------------------\r\n      else                              -- \\ddd -- various steps\r\n        local s = match(z, \"^(%d%d?%d?)\", j)\r\n        j = i + 1 + #s                  -- skip to location\r\n        local cv = s + 0\r\n        local cc = string.char(cv)\r\n        local p = find(\"\\a\\b\\f\\n\\r\\t\\v\", cc, 1, true)\r\n        if p then                       -- special escapes\r\n          s = \"\\\\\"..sub(\"abfnrtv\", p, p)\r\n        elseif cv < 32 then             -- normalized \\ddd\r\n          s = \"\\\\\"..cv\r\n        elseif cc == delim then         -- \\<delim>\r\n          s = \"\\\\\"..cc\r\n          c_delim = c_delim + 1\r\n        elseif cc == \"\\\\\" then          -- \\\\\r\n          s = \"\\\\\\\\\"\r\n        else                            -- literal character\r\n          s = cc\r\n          if cc == ndelim then\r\n            c_ndelim = c_ndelim + 1\r\n          end\r\n        end\r\n        z = sub(z, 1, i - 1)..s..sub(z, j)\r\n        i = i + #s\r\n      ------------------------------------------------------------\r\n      end--if p\r\n    ----------------------------------------------------------------\r\n    else-- c ~= \"\\\\\"                    -- <other> -- no change\r\n      i = i + 1\r\n      if c == ndelim then  -- count ndelim, for switching delimiters\r\n        c_ndelim = c_ndelim + 1\r\n      end\r\n    ----------------------------------------------------------------\r\n    end",
    "type": "statement:if"
  }, {
    "id": 117,
    "text": "local j = i + 1",
    "type": "statement:localassign"
  }, {
    "id": 118,
    "text": "local d = sub(z, j, j)",
    "type": "statement:localassign"
  }, {
    "id": 119,
    "text": "local p = find(\"abfnrtv\\\\\\n\\r\\\"\\'0123456789\", d, 1, true)",
    "type": "statement:localassign"
  }, {
    "id": 120,
    "text": "if not p then                     -- \\<char> -- remove \\\r\n        z = sub(z, 1, i - 1)..sub(z, j)\r\n        i = i + 1\r\n      ------------------------------------------------------------\r\n      elseif p <= 8 then                -- \\a\\b\\f\\n\\r\\t\\v\\\\\r\n        i = i + 2                       -- no change\r\n      ------------------------------------------------------------\r\n      elseif p <= 10 then               -- \\<eol> -- normalize EOL\r\n        local eol = sub(z, j, j + 1)\r\n        if eol == \"\\r\\n\" or eol == \"\\n\\r\" then\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 2)\r\n        elseif p == 10 then  -- \\r case\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 1)\r\n        end\r\n        i = i + 2\r\n      ------------------------------------------------------------\r\n      elseif p <= 12 then               -- \\\"\\' -- remove \\ for ndelim\r\n        if d == delim then\r\n          c_delim = c_delim + 1\r\n          i = i + 2\r\n        else\r\n          c_ndelim = c_ndelim + 1\r\n          z = sub(z, 1, i - 1)..sub(z, j)\r\n          i = i + 1\r\n        end\r\n      ------------------------------------------------------------\r\n      else                              -- \\ddd -- various steps\r\n        local s = match(z, \"^(%d%d?%d?)\", j)\r\n        j = i + 1 + #s                  -- skip to location\r\n        local cv = s + 0\r\n        local cc = string.char(cv)\r\n        local p = find(\"\\a\\b\\f\\n\\r\\t\\v\", cc, 1, true)\r\n        if p then                       -- special escapes\r\n          s = \"\\\\\"..sub(\"abfnrtv\", p, p)\r\n        elseif cv < 32 then             -- normalized \\ddd\r\n          s = \"\\\\\"..cv\r\n        elseif cc == delim then         -- \\<delim>\r\n          s = \"\\\\\"..cc\r\n          c_delim = c_delim + 1\r\n        elseif cc == \"\\\\\" then          -- \\\\\r\n          s = \"\\\\\\\\\"\r\n        else                            -- literal character\r\n          s = cc\r\n          if cc == ndelim then\r\n            c_ndelim = c_ndelim + 1\r\n          end\r\n        end\r\n        z = sub(z, 1, i - 1)..s..sub(z, j)\r\n        i = i + #s\r\n      ------------------------------------------------------------\r\n      end",
    "type": "statement:if"
  }, {
    "id": 121,
    "text": "z = sub(z, 1, i - 1)..sub(z, j)",
    "type": "statement:assign"
  }, {
    "id": 122,
    "text": "i = i + 2",
    "type": "statement:assign"
  }, {
    "id": 123,
    "text": "local eol = sub(z, j, j + 1)",
    "type": "statement:localassign"
  }, {
    "id": 124,
    "text": "if eol == \"\\r\\n\" or eol == \"\\n\\r\" then\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 2)\r\n        elseif p == 10 then  -- \\r case\r\n          z = sub(z, 1, i)..\"\\n\"..sub(z, j + 1)\r\n        end",
    "type": "statement:if"
  }, {
    "id": 125,
    "text": "z = sub(z, 1, i)..\"\\n\"..sub(z, j + 2)",
    "type": "statement:assign"
  }, {
    "id": 126,
    "text": "z = sub(z, 1, i)..\"\\n\"..sub(z, j + 1)",
    "type": "statement:assign"
  }, {
    "id": 127,
    "text": "if d == delim then\r\n          c_delim = c_delim + 1\r\n          i = i + 2\r\n        else\r\n          c_ndelim = c_ndelim + 1\r\n          z = sub(z, 1, i - 1)..sub(z, j)\r\n          i = i + 1\r\n        end",
    "type": "statement:if"
  }, {
    "id": 128,
    "text": "c_delim = c_delim + 1",
    "type": "statement:assign"
  }, {
    "id": 129,
    "text": "c_ndelim = c_ndelim + 1",
    "type": "statement:assign"
  }, {
    "id": 130,
    "text": "local s = match(z, \"^(%d%d?%d?)\", j)",
    "type": "statement:localassign"
  }, {
    "id": 131,
    "text": "j = i + 1 + #s",
    "type": "statement:assign"
  }, {
    "id": 132,
    "text": "local cv = s + 0",
    "type": "statement:localassign"
  }, {
    "id": 133,
    "text": "local cc = string.char(cv)",
    "type": "statement:localassign"
  }, {
    "id": 134,
    "text": "local p = find(\"\\a\\b\\f\\n\\r\\t\\v\", cc, 1, true)",
    "type": "statement:localassign"
  }, {
    "id": 135,
    "text": "if p then                       -- special escapes\r\n          s = \"\\\\\"..sub(\"abfnrtv\", p, p)\r\n        elseif cv < 32 then             -- normalized \\ddd\r\n          s = \"\\\\\"..cv\r\n        elseif cc == delim then         -- \\<delim>\r\n          s = \"\\\\\"..cc\r\n          c_delim = c_delim + 1\r\n        elseif cc == \"\\\\\" then          -- \\\\\r\n          s = \"\\\\\\\\\"\r\n        else                            -- literal character\r\n          s = cc\r\n          if cc == ndelim then\r\n            c_ndelim = c_ndelim + 1\r\n          end\r\n        end",
    "type": "statement:if"
  }, {
    "id": 136,
    "text": "s = \"\\\\\"..sub(\"abfnrtv\", p, p)",
    "type": "statement:assign"
  }, {
    "id": 137,
    "text": "s = \"\\\\\"..cv",
    "type": "statement:assign"
  }, {
    "id": 138,
    "text": "s = \"\\\\\"..cc",
    "type": "statement:assign"
  }, {
    "id": 139,
    "text": "s = \"\\\\\\\\\"",
    "type": "statement:assign"
  }, {
    "id": 140,
    "text": "s = cc",
    "type": "statement:assign"
  }, {
    "id": 141,
    "text": "if cc == ndelim then\r\n            c_ndelim = c_ndelim + 1\r\n          end",
    "type": "statement:if"
  }, {
    "id": 142,
    "text": "z = sub(z, 1, i - 1)..s..sub(z, j)",
    "type": "statement:assign"
  }, {
    "id": 143,
    "text": "i = i + #s",
    "type": "statement:assign"
  }, {
    "id": 144,
    "text": "if c == ndelim then  -- count ndelim, for switching delimiters\r\n        c_ndelim = c_ndelim + 1\r\n      end",
    "type": "statement:if"
  }, {
    "id": 145,
    "text": "if c_delim > c_ndelim then\r\n    i = 1\r\n    while i <= #z do\r\n      local p, q, r = find(z, \"([\\'\\\"])\", i)\r\n      if not p then break end\r\n      if r == delim then                -- \\<delim> -> <delim>\r\n        z = sub(z, 1, p - 2)..sub(z, p)\r\n        i = p\r\n      else-- r == ndelim                -- <ndelim> -> \\<ndelim>\r\n        z = sub(z, 1, p - 1)..\"\\\\\"..sub(z, p)\r\n        i = p + 2\r\n      end\r\n    end--while\r\n    delim = ndelim  -- actually change delimiters\r\n  end",
    "type": "statement:if"
  }, {
    "id": 146,
    "text": "i = 1",
    "type": "statement:assign"
  }, {
    "id": 147,
    "text": "while i <= #z do\r\n      local p, q, r = find(z, \"([\\'\\\"])\", i)\r\n      if not p then break end\r\n      if r == delim then                -- \\<delim> -> <delim>\r\n        z = sub(z, 1, p - 2)..sub(z, p)\r\n        i = p\r\n      else-- r == ndelim                -- <ndelim> -> \\<ndelim>\r\n        z = sub(z, 1, p - 1)..\"\\\\\"..sub(z, p)\r\n        i = p + 2\r\n      end\r\n    end",
    "type": "statement:while"
  }, {
    "id": 148,
    "text": "local p, q, r = find(z, \"([\\'\\\"])\", i)",
    "type": "statement:localassign"
  }, {
    "id": 149,
    "text": "if r == delim then                -- \\<delim> -> <delim>\r\n        z = sub(z, 1, p - 2)..sub(z, p)\r\n        i = p\r\n      else-- r == ndelim                -- <ndelim> -> \\<ndelim>\r\n        z = sub(z, 1, p - 1)..\"\\\\\"..sub(z, p)\r\n        i = p + 2\r\n      end",
    "type": "statement:if"
  }, {
    "id": 150,
    "text": "z = sub(z, 1, p - 2)..sub(z, p)",
    "type": "statement:assign"
  }, {
    "id": 151,
    "text": "i = p",
    "type": "statement:assign"
  }, {
    "id": 152,
    "text": "z = sub(z, 1, p - 1)..\"\\\\\"..sub(z, p)",
    "type": "statement:assign"
  }, {
    "id": 153,
    "text": "i = p + 2",
    "type": "statement:assign"
  }, {
    "id": 154,
    "text": "delim = ndelim",
    "type": "statement:assign"
  }, {
    "id": 155,
    "text": "z = delim..z..delim",
    "type": "statement:assign"
  }, {
    "id": 156,
    "text": "if z ~= sinfos[I] then\r\n    if opt_details then\r\n      print(\"<string> (line \"..stoklns[I]..\") \"..sinfos[I]..\" -> \"..z)\r\n      opt_details = opt_details + 1\r\n    end\r\n    sinfos[I] = z\r\n  end",
    "type": "statement:if"
  }, {
    "id": 157,
    "text": "if opt_details then\r\n      print(\"<string> (line \"..stoklns[I]..\") \"..sinfos[I]..\" -> \"..z)\r\n      opt_details = opt_details + 1\r\n    end",
    "type": "statement:if"
  }, {
    "id": 158,
    "text": "print(\"<string> (line \"..stoklns[I]..\") \"..sinfos[I]..\" -> \"..z)",
    "type": "statement:functioncall"
  }, {
    "id": 159,
    "text": "sinfos[I] = z",
    "type": "statement:assign"
  }, {
    "id": 160,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 161,
    "text": "local function do_lstring(I)\r\n  local info = sinfos[I]\r\n  local delim1 = match(info, \"^%[=*%[\")  -- cut out delimiters\r\n  local sep = #delim1\r\n  local delim2 = sub(info, -sep, -1)\r\n  local z = sub(info, sep + 1, -(sep + 1))  -- lstring without delims\r\n  local y = \"\"\r\n  local i = 1\r\n  --------------------------------------------------------------------\r\n  while true do\r\n    local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)\r\n    -- deal with a single line\r\n    local ln\r\n    if not p then\r\n      ln = sub(z, i)\r\n    elseif p >= i then\r\n      ln = sub(z, i, p - 1)\r\n    end\r\n    if ln ~= \"\" then\r\n      -- flag a warning if there are trailing spaces, won't optimize!\r\n      if match(ln, \"%s+$\") then\r\n        warn.lstring = \"trailing whitespace in long string near line \"..stoklns[I]\r\n      end\r\n      y = y..ln\r\n    end\r\n    if not p then  -- done if no more EOLs\r\n      break\r\n    end\r\n    -- deal with line endings, normalize them\r\n    i = p + 1\r\n    if p then\r\n      if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end\r\n      -- skip first newline, which can be safely deleted\r\n      if not(i == 1 and i == p) then\r\n        y = y..\"\\n\"\r\n      end\r\n    end\r\n  end--while\r\n  --------------------------------------------------------------------\r\n  -- handle possible deletion of one or more '=' separators\r\n  if sep >= 3 then\r\n    local chk, okay = sep - 1\r\n    -- loop to test ending delimiter with less of '=' down to zero\r\n    while chk >= 2 do\r\n      local delim = \"%]\"..rep(\"=\", chk - 2)..\"%]\"\r\n      if not match(y, delim) then okay = chk end\r\n      chk = chk - 1\r\n    end\r\n    if okay then  -- change delimiters\r\n      sep = rep(\"=\", okay - 2)\r\n      delim1, delim2 = \"[\"..sep..\"[\", \"]\"..sep..\"]\"\r\n    end\r\n  end\r\n  --------------------------------------------------------------------\r\n  sinfos[I] = delim1..y..delim2\r\nend",
    "type": "function"
  }, {
    "id": 162,
    "text": "local delim1 = match(info, \"^%[=*%[\")",
    "type": "statement:localassign"
  }, {
    "id": 163,
    "text": "local sep = #delim1",
    "type": "statement:localassign"
  }, {
    "id": 164,
    "text": "local delim2 = sub(info, -sep, -1)",
    "type": "statement:localassign"
  }, {
    "id": 165,
    "text": "local z = sub(info, sep + 1, -(sep + 1))",
    "type": "statement:localassign"
  }, {
    "id": 166,
    "text": "local y = \"\"",
    "type": "statement:localassign"
  }, {
    "id": 167,
    "text": "while true do\r\n    local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)\r\n    -- deal with a single line\r\n    local ln\r\n    if not p then\r\n      ln = sub(z, i)\r\n    elseif p >= i then\r\n      ln = sub(z, i, p - 1)\r\n    end\r\n    if ln ~= \"\" then\r\n      -- flag a warning if there are trailing spaces, won't optimize!\r\n      if match(ln, \"%s+$\") then\r\n        warn.lstring = \"trailing whitespace in long string near line \"..stoklns[I]\r\n      end\r\n      y = y..ln\r\n    end\r\n    if not p then  -- done if no more EOLs\r\n      break\r\n    end\r\n    -- deal with line endings, normalize them\r\n    i = p + 1\r\n    if p then\r\n      if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end\r\n      -- skip first newline, which can be safely deleted\r\n      if not(i == 1 and i == p) then\r\n        y = y..\"\\n\"\r\n      end\r\n    end\r\n  end",
    "type": "statement:while"
  }, {
    "id": 168,
    "text": "local ln",
    "type": "statement:localassign"
  }, {
    "id": 169,
    "text": "if not p then\r\n      ln = sub(z, i)\r\n    elseif p >= i then\r\n      ln = sub(z, i, p - 1)\r\n    end",
    "type": "statement:if"
  }, {
    "id": 170,
    "text": "ln = sub(z, i)",
    "type": "statement:assign"
  }, {
    "id": 171,
    "text": "ln = sub(z, i, p - 1)",
    "type": "statement:assign"
  }, {
    "id": 172,
    "text": "if ln ~= \"\" then\r\n      -- flag a warning if there are trailing spaces, won't optimize!\r\n      if match(ln, \"%s+$\") then\r\n        warn.lstring = \"trailing whitespace in long string near line \"..stoklns[I]\r\n      end\r\n      y = y..ln\r\n    end",
    "type": "statement:if"
  }, {
    "id": 173,
    "text": "if match(ln, \"%s+$\") then\r\n        warn.lstring = \"trailing whitespace in long string near line \"..stoklns[I]\r\n      end",
    "type": "statement:if"
  }, {
    "id": 174,
    "text": "warn.lstring = \"trailing whitespace in long string near line \"..stoklns[I]",
    "type": "statement:assign"
  }, {
    "id": 175,
    "text": "y = y..ln",
    "type": "statement:assign"
  }, {
    "id": 176,
    "text": "if not p then  -- done if no more EOLs\r\n      break\r\n    end",
    "type": "statement:if"
  }, {
    "id": 177,
    "text": "if p then\r\n      if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end\r\n      -- skip first newline, which can be safely deleted\r\n      if not(i == 1 and i == p) then\r\n        y = y..\"\\n\"\r\n      end\r\n    end",
    "type": "statement:if"
  }, {
    "id": 178,
    "text": "if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end",
    "type": "statement:if"
  }, {
    "id": 179,
    "text": "if not(i == 1 and i == p) then\r\n        y = y..\"\\n\"\r\n      end",
    "type": "statement:if"
  }, {
    "id": 180,
    "text": "y = y..\"\\n\"",
    "type": "statement:assign"
  }, {
    "id": 181,
    "text": "if sep >= 3 then\r\n    local chk, okay = sep - 1\r\n    -- loop to test ending delimiter with less of '=' down to zero\r\n    while chk >= 2 do\r\n      local delim = \"%]\"..rep(\"=\", chk - 2)..\"%]\"\r\n      if not match(y, delim) then okay = chk end\r\n      chk = chk - 1\r\n    end\r\n    if okay then  -- change delimiters\r\n      sep = rep(\"=\", okay - 2)\r\n      delim1, delim2 = \"[\"..sep..\"[\", \"]\"..sep..\"]\"\r\n    end\r\n  end",
    "type": "statement:if"
  }, {
    "id": 182,
    "text": "local chk, okay = sep - 1",
    "type": "statement:localassign"
  }, {
    "id": 183,
    "text": "while chk >= 2 do\r\n      local delim = \"%]\"..rep(\"=\", chk - 2)..\"%]\"\r\n      if not match(y, delim) then okay = chk end\r\n      chk = chk - 1\r\n    end",
    "type": "statement:while"
  }, {
    "id": 184,
    "text": "local delim = \"%]\"..rep(\"=\", chk - 2)..\"%]\"",
    "type": "statement:localassign"
  }, {
    "id": 185,
    "text": "if not match(y, delim) then okay = chk end",
    "type": "statement:if"
  }, {
    "id": 186,
    "text": "okay = chk",
    "type": "statement:assign"
  }, {
    "id": 187,
    "text": "chk = chk - 1",
    "type": "statement:assign"
  }, {
    "id": 188,
    "text": "if okay then  -- change delimiters\r\n      sep = rep(\"=\", okay - 2)\r\n      delim1, delim2 = \"[\"..sep..\"[\", \"]\"..sep..\"]\"\r\n    end",
    "type": "statement:if"
  }, {
    "id": 189,
    "text": "sep = rep(\"=\", okay - 2)",
    "type": "statement:assign"
  }, {
    "id": 190,
    "text": "delim1, delim2 = \"[\"..sep..\"[\", \"]\"..sep..\"]\"",
    "type": "statement:assign"
  }, {
    "id": 191,
    "text": "sinfos[I] = delim1..y..delim2",
    "type": "statement:assign"
  }, {
    "id": 192,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 193,
    "text": "local function do_lcomment(I)\r\n  local info = sinfos[I]\r\n  local delim1 = match(info, \"^%-%-%[=*%[\")  -- cut out delimiters\r\n  local sep = #delim1\r\n  local delim2 = sub(info, -sep, -1)\r\n  local z = sub(info, sep + 1, -(sep - 1))  -- comment without delims\r\n  local y = \"\"\r\n  local i = 1\r\n  --------------------------------------------------------------------\r\n  while true do\r\n    local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)\r\n    -- deal with a single line, extract and check trailing whitespace\r\n    local ln\r\n    if not p then\r\n      ln = sub(z, i)\r\n    elseif p >= i then\r\n      ln = sub(z, i, p - 1)\r\n    end\r\n    if ln ~= \"\" then\r\n      -- trim trailing whitespace if non-empty line\r\n      local ws = match(ln, \"%s*$\")\r\n      if #ws > 0 then ln = sub(ln, 1, -(ws + 1)) end\r\n      y = y..ln\r\n    end\r\n    if not p then  -- done if no more EOLs\r\n      break\r\n    end\r\n    -- deal with line endings, normalize them\r\n    i = p + 1\r\n    if p then\r\n      if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end\r\n      y = y..\"\\n\"\r\n    end\r\n  end--while\r\n  --------------------------------------------------------------------\r\n  -- handle possible deletion of one or more '=' separators\r\n  sep = sep - 2\r\n  if sep >= 3 then\r\n    local chk, okay = sep - 1\r\n    -- loop to test ending delimiter with less of '=' down to zero\r\n    while chk >= 2 do\r\n      local delim = \"%]\"..rep(\"=\", chk - 2)..\"%]\"\r\n      if not match(y, delim) then okay = chk end\r\n      chk = chk - 1\r\n    end\r\n    if okay then  -- change delimiters\r\n      sep = rep(\"=\", okay - 2)\r\n      delim1, delim2 = \"--[\"..sep..\"[\", \"]\"..sep..\"]\"\r\n    end\r\n  end\r\n  --------------------------------------------------------------------\r\n  sinfos[I] = delim1..y..delim2\r\nend",
    "type": "function"
  }, {
    "id": 194,
    "text": "local delim1 = match(info, \"^%-%-%[=*%[\")",
    "type": "statement:localassign"
  }, {
    "id": 195,
    "text": "local z = sub(info, sep + 1, -(sep - 1))",
    "type": "statement:localassign"
  }, {
    "id": 196,
    "text": "while true do\r\n    local p, q, r, s = find(z, \"([\\r\\n])([\\r\\n]?)\", i)\r\n    -- deal with a single line, extract and check trailing whitespace\r\n    local ln\r\n    if not p then\r\n      ln = sub(z, i)\r\n    elseif p >= i then\r\n      ln = sub(z, i, p - 1)\r\n    end\r\n    if ln ~= \"\" then\r\n      -- trim trailing whitespace if non-empty line\r\n      local ws = match(ln, \"%s*$\")\r\n      if #ws > 0 then ln = sub(ln, 1, -(ws + 1)) end\r\n      y = y..ln\r\n    end\r\n    if not p then  -- done if no more EOLs\r\n      break\r\n    end\r\n    -- deal with line endings, normalize them\r\n    i = p + 1\r\n    if p then\r\n      if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end\r\n      y = y..\"\\n\"\r\n    end\r\n  end",
    "type": "statement:while"
  }, {
    "id": 197,
    "text": "if ln ~= \"\" then\r\n      -- trim trailing whitespace if non-empty line\r\n      local ws = match(ln, \"%s*$\")\r\n      if #ws > 0 then ln = sub(ln, 1, -(ws + 1)) end\r\n      y = y..ln\r\n    end",
    "type": "statement:if"
  }, {
    "id": 198,
    "text": "local ws = match(ln, \"%s*$\")",
    "type": "statement:localassign"
  }, {
    "id": 199,
    "text": "if #ws > 0 then ln = sub(ln, 1, -(ws + 1)) end",
    "type": "statement:if"
  }, {
    "id": 200,
    "text": "ln = sub(ln, 1, -(ws + 1))",
    "type": "statement:assign"
  }, {
    "id": 201,
    "text": "if p then\r\n      if #s > 0 and r ~= s then  -- skip CRLF or LFCR\r\n        i = i + 1\r\n      end\r\n      y = y..\"\\n\"\r\n    end",
    "type": "statement:if"
  }, {
    "id": 202,
    "text": "sep = sep - 2",
    "type": "statement:assign"
  }, {
    "id": 203,
    "text": "if sep >= 3 then\r\n    local chk, okay = sep - 1\r\n    -- loop to test ending delimiter with less of '=' down to zero\r\n    while chk >= 2 do\r\n      local delim = \"%]\"..rep(\"=\", chk - 2)..\"%]\"\r\n      if not match(y, delim) then okay = chk end\r\n      chk = chk - 1\r\n    end\r\n    if okay then  -- change delimiters\r\n      sep = rep(\"=\", okay - 2)\r\n      delim1, delim2 = \"--[\"..sep..\"[\", \"]\"..sep..\"]\"\r\n    end\r\n  end",
    "type": "statement:if"
  }, {
    "id": 204,
    "text": "if okay then  -- change delimiters\r\n      sep = rep(\"=\", okay - 2)\r\n      delim1, delim2 = \"--[\"..sep..\"[\", \"]\"..sep..\"]\"\r\n    end",
    "type": "statement:if"
  }, {
    "id": 205,
    "text": "delim1, delim2 = \"--[\"..sep..\"[\", \"]\"..sep..\"]\"",
    "type": "statement:assign"
  }, {
    "id": 206,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 207,
    "text": "local function do_comment(i)\r\n  local info = sinfos[i]\r\n  local ws = match(info, \"%s*$\")        -- just look from end of string\r\n  if #ws > 0 then\r\n    info = sub(info, 1, -(ws + 1))      -- trim trailing whitespace\r\n  end\r\n  sinfos[i] = info\r\nend",
    "type": "function"
  }, {
    "id": 208,
    "text": "local info = sinfos[i]",
    "type": "statement:localassign"
  }, {
    "id": 209,
    "text": "local ws = match(info, \"%s*$\")",
    "type": "statement:localassign"
  }, {
    "id": 210,
    "text": "if #ws > 0 then\r\n    info = sub(info, 1, -(ws + 1))      -- trim trailing whitespace\r\n  end",
    "type": "statement:if"
  }, {
    "id": 211,
    "text": "info = sub(info, 1, -(ws + 1))",
    "type": "statement:assign"
  }, {
    "id": 212,
    "text": "sinfos[i] = info",
    "type": "statement:assign"
  }, {
    "id": 213,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 214,
    "text": "local function keep_lcomment(opt_keep, info)\r\n  if not opt_keep then return false end  -- option not set\r\n  local delim1 = match(info, \"^%-%-%[=*%[\")  -- cut out delimiters\r\n  local sep = #delim1\r\n  local delim2 = sub(info, -sep, -1)\r\n  local z = sub(info, sep + 1, -(sep - 1))  -- comment without delims\r\n  if find(z, opt_keep, 1, true) then  -- try to match\r\n    return true\r\n  end\r\nend",
    "type": "function"
  }, {
    "id": 215,
    "text": "if not opt_keep then return false end",
    "type": "statement:if"
  }, {
    "id": 216,
    "text": "if find(z, opt_keep, 1, true) then  -- try to match\r\n    return true\r\n  end",
    "type": "statement:if"
  }, {
    "id": 217,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 218,
    "text": "function optimize(option, toklist, semlist, toklnlist)\r\n  --------------------------------------------------------------------\r\n  -- set option flags\r\n  --------------------------------------------------------------------\r\n  local opt_comments = option[\"opt-comments\"]\r\n  local opt_whitespace = option[\"opt-whitespace\"]\r\n  local opt_emptylines = option[\"opt-emptylines\"]\r\n  local opt_eols = option[\"opt-eols\"]\r\n  local opt_strings = option[\"opt-strings\"]\r\n  local opt_numbers = option[\"opt-numbers\"]\r\n  local opt_keep = option.KEEP\r\n  opt_details = option.DETAILS and 0  -- upvalues for details display\r\n  print = print or base.print\r\n  if opt_eols then  -- forced settings, otherwise won't work properly\r\n    opt_comments = true\r\n    opt_whitespace = true\r\n    opt_emptylines = true\r\n  end\r\n  --------------------------------------------------------------------\r\n  -- variable initialization\r\n  --------------------------------------------------------------------\r\n  stoks, sinfos, stoklns                -- set source lists\r\n    = toklist, semlist, toklnlist\r\n  local i = 1                           -- token position\r\n  local tok, info                       -- current token\r\n  local prev    -- position of last grammar token\r\n                -- on same line (for TK_SPACE stuff)\r\n  --------------------------------------------------------------------\r\n  -- changes a token, info pair\r\n  --------------------------------------------------------------------\r\n  local function settoken(tok, info, I)\r\n    I = I or i\r\n    stoks[I] = tok or \"\"\r\n    sinfos[I] = info or \"\"\r\n  end\r\n  --------------------------------------------------------------------\r\n  -- processing loop (PASS 1)\r\n  --------------------------------------------------------------------\r\n  while true do\r\n    tok, info = stoks[i], sinfos[i]\r\n    ----------------------------------------------------------------\r\n    local atstart = atlinestart(i)      -- set line begin flag\r\n    if atstart then prev = nil end\r\n    ----------------------------------------------------------------\r\n    if tok == \"TK_EOS\" then             -- end of stream/pass\r\n      break\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_KEYWORD\" or       -- keywords, identifiers,\r\n           tok == \"TK_NAME\" or          -- operators\r\n           tok == \"TK_OP\" then\r\n      -- TK_KEYWORD and TK_OP can't be optimized without a big\r\n      -- optimization framework; it would be more of an optimizing\r\n      -- compiler, not a source code compressor\r\n      -- TK_NAME that are locals needs parser to analyze/optimize\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_NUMBER\" then      -- numbers\r\n      if opt_numbers then\r\n        do_number(i)  -- optimize\r\n      end\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_STRING\" or        -- strings, long strings\r\n           tok == \"TK_LSTRING\" then\r\n      if opt_strings then\r\n        if tok == \"TK_STRING\" then\r\n          do_string(i)  -- optimize\r\n        else\r\n          do_lstring(i)  -- optimize\r\n        end\r\n      end\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_COMMENT\" then     -- short comments\r\n      if opt_comments then\r\n        if i == 1 and sub(info, 1, 1) == \"#\" then\r\n          -- keep shbang comment, trim whitespace\r\n          do_comment(i)\r\n        else\r\n          -- safe to delete, as a TK_EOL (or TK_EOS) always follows\r\n          settoken()  -- remove entirely\r\n        end\r\n      elseif opt_whitespace then        -- trim whitespace only\r\n        do_comment(i)\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_LCOMMENT\" then    -- long comments\r\n      if keep_lcomment(opt_keep, info) then\r\n        ------------------------------------------------------------\r\n        -- if --keep, we keep a long comment if <msg> is found;\r\n        -- this is a feature to keep copyright or license texts\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      elseif opt_comments then\r\n        local eols = commenteols(info)\r\n        ------------------------------------------------------------\r\n        -- prepare opt_emptylines case first, if a disposable token\r\n        -- follows, current one is safe to dump, else keep a space;\r\n        -- it is implied that the operation is safe for '-', because\r\n        -- current is a TK_LCOMMENT, and must be separate from a '-'\r\n        if is_faketoken[stoks[i + 1]] then\r\n          settoken()  -- remove entirely\r\n          tok = \"\"\r\n        else\r\n          settoken(\"TK_SPACE\", \" \")\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if there are embedded EOLs to keep and opt_emptylines is\r\n        -- disabled, then switch the token into one or more EOLs\r\n        if not opt_emptylines and eols > 0 then\r\n          settoken(\"TK_EOL\", rep(\"\\n\", eols))\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if optimizing whitespaces, force reinterpretation of the\r\n        -- token to give a chance for the space to be optimized away\r\n        if opt_whitespace and tok ~= \"\" then\r\n          i = i - 1  -- to reinterpret\r\n        end\r\n        ------------------------------------------------------------\r\n      else                              -- disabled case\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_EOL\" then         -- line endings\r\n      if atstart and opt_emptylines then\r\n        settoken()  -- remove entirely\r\n      elseif info == \"\\r\\n\" or info == \"\\n\\r\" then\r\n        -- normalize the rest of the EOLs for CRLF/LFCR only\r\n        -- (note that TK_LCOMMENT can change into several EOLs)\r\n        settoken(\"TK_EOL\", \"\\n\")\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_SPACE\" then       -- whitespace\r\n      if opt_whitespace then\r\n        if atstart or atlineend(i) then\r\n          -- delete leading and trailing whitespace\r\n          settoken()  -- remove entirely\r\n        else\r\n          ------------------------------------------------------------\r\n          -- at this point, since leading whitespace have been removed,\r\n          -- there should be a either a real token or a TK_LCOMMENT\r\n          -- prior to hitting this whitespace; the TK_LCOMMENT case\r\n          -- only happens if opt_comments is disabled; so prev ~= nil\r\n          local ptok = stoks[prev]\r\n          if ptok == \"TK_LCOMMENT\" then\r\n            -- previous TK_LCOMMENT can abut with anything\r\n            settoken()  -- remove entirely\r\n          else\r\n            -- prev must be a grammar token; consecutive TK_SPACE\r\n            -- tokens is impossible when optimizing whitespace\r\n            local ntok = stoks[i + 1]\r\n            if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end\r\n          end\r\n          ------------------------------------------------------------\r\n        end\r\n      end\r\n    ----------------------------------------------------------------\r\n    else\r\n      error(\"unidentified token encountered\")\r\n    end\r\n    ----------------------------------------------------------------\r\n    i = i + 1\r\n  end--while\r\n  repack_tokens()\r\n  --------------------------------------------------------------------\r\n  -- processing loop (PASS 2)\r\n  --------------------------------------------------------------------\r\n  if opt_eols then\r\n    i = 1\r\n    -- aggressive EOL removal only works with most non-grammar tokens\r\n    -- optimized away because it is a rather simple scheme -- basically\r\n    -- it just checks 'real' token pairs around EOLs\r\n    if stoks[1] == \"TK_COMMENT\" then\r\n      -- first comment still existing must be shbang, skip whole line\r\n      i = 3\r\n    end\r\n    while true do\r\n      tok, info = stoks[i], sinfos[i]\r\n      --------------------------------------------------------------\r\n      if tok == \"TK_EOS\" then           -- end of stream/pass\r\n        break\r\n      --------------------------------------------------------------\r\n      elseif tok == \"TK_EOL\" then       -- consider each TK_EOL\r\n        local t1, t2 = stoks[i - 1], stoks[i + 1]\r\n        if is_realtoken[t1] and is_realtoken[t2] then  -- sanity check\r\n          local s = checkpair(i - 1, i + 1)\r\n          if s == \"\" then\r\n            settoken()  -- remove entirely\r\n          end\r\n        end\r\n      end--if tok\r\n      --------------------------------------------------------------\r\n      i = i + 1\r\n    end--while\r\n    repack_tokens()\r\n  end\r\n  --------------------------------------------------------------------\r\n  if opt_details and opt_details > 0 then print() end -- spacing\r\n  return stoks, sinfos, stoklns\r\nend",
    "type": "function"
  }, {
    "id": 219,
    "text": "local opt_comments = option[\"opt-comments\"]",
    "type": "statement:localassign"
  }, {
    "id": 220,
    "text": "local opt_whitespace = option[\"opt-whitespace\"]",
    "type": "statement:localassign"
  }, {
    "id": 221,
    "text": "local opt_emptylines = option[\"opt-emptylines\"]",
    "type": "statement:localassign"
  }, {
    "id": 222,
    "text": "local opt_eols = option[\"opt-eols\"]",
    "type": "statement:localassign"
  }, {
    "id": 223,
    "text": "local opt_strings = option[\"opt-strings\"]",
    "type": "statement:localassign"
  }, {
    "id": 224,
    "text": "local opt_numbers = option[\"opt-numbers\"]",
    "type": "statement:localassign"
  }, {
    "id": 225,
    "text": "local opt_keep = option.KEEP",
    "type": "statement:localassign"
  }, {
    "id": 226,
    "text": "opt_details = option.DETAILS and 0",
    "type": "statement:assign"
  }, {
    "id": 227,
    "text": "print = print or base.print",
    "type": "statement:assign"
  }, {
    "id": 228,
    "text": "if opt_eols then  -- forced settings, otherwise won't work properly\r\n    opt_comments = true\r\n    opt_whitespace = true\r\n    opt_emptylines = true\r\n  end",
    "type": "statement:if"
  }, {
    "id": 229,
    "text": "opt_comments = true",
    "type": "statement:assign"
  }, {
    "id": 230,
    "text": "opt_whitespace = true",
    "type": "statement:assign"
  }, {
    "id": 231,
    "text": "opt_emptylines = true",
    "type": "statement:assign"
  }, {
    "id": 232,
    "text": "stoks, sinfos, stoklns                -- set source lists\r\n    = toklist, semlist, toklnlist",
    "type": "statement:assign"
  }, {
    "id": 233,
    "text": "local tok, info",
    "type": "statement:localassign"
  }, {
    "id": 234,
    "text": "local prev",
    "type": "statement:localassign"
  }, {
    "id": 235,
    "text": "local function settoken(tok, info, I)\r\n    I = I or i\r\n    stoks[I] = tok or \"\"\r\n    sinfos[I] = info or \"\"\r\n  end",
    "type": "statement:localfunction"
  }, {
    "id": 236,
    "text": "I = I or i",
    "type": "statement:assign"
  }, {
    "id": 237,
    "text": "stoks[I] = tok or \"\"",
    "type": "statement:assign"
  }, {
    "id": 238,
    "text": "sinfos[I] = info or \"\"",
    "type": "statement:assign"
  }, {
    "id": 239,
    "text": "while true do\r\n    tok, info = stoks[i], sinfos[i]\r\n    ----------------------------------------------------------------\r\n    local atstart = atlinestart(i)      -- set line begin flag\r\n    if atstart then prev = nil end\r\n    ----------------------------------------------------------------\r\n    if tok == \"TK_EOS\" then             -- end of stream/pass\r\n      break\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_KEYWORD\" or       -- keywords, identifiers,\r\n           tok == \"TK_NAME\" or          -- operators\r\n           tok == \"TK_OP\" then\r\n      -- TK_KEYWORD and TK_OP can't be optimized without a big\r\n      -- optimization framework; it would be more of an optimizing\r\n      -- compiler, not a source code compressor\r\n      -- TK_NAME that are locals needs parser to analyze/optimize\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_NUMBER\" then      -- numbers\r\n      if opt_numbers then\r\n        do_number(i)  -- optimize\r\n      end\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_STRING\" or        -- strings, long strings\r\n           tok == \"TK_LSTRING\" then\r\n      if opt_strings then\r\n        if tok == \"TK_STRING\" then\r\n          do_string(i)  -- optimize\r\n        else\r\n          do_lstring(i)  -- optimize\r\n        end\r\n      end\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_COMMENT\" then     -- short comments\r\n      if opt_comments then\r\n        if i == 1 and sub(info, 1, 1) == \"#\" then\r\n          -- keep shbang comment, trim whitespace\r\n          do_comment(i)\r\n        else\r\n          -- safe to delete, as a TK_EOL (or TK_EOS) always follows\r\n          settoken()  -- remove entirely\r\n        end\r\n      elseif opt_whitespace then        -- trim whitespace only\r\n        do_comment(i)\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_LCOMMENT\" then    -- long comments\r\n      if keep_lcomment(opt_keep, info) then\r\n        ------------------------------------------------------------\r\n        -- if --keep, we keep a long comment if <msg> is found;\r\n        -- this is a feature to keep copyright or license texts\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      elseif opt_comments then\r\n        local eols = commenteols(info)\r\n        ------------------------------------------------------------\r\n        -- prepare opt_emptylines case first, if a disposable token\r\n        -- follows, current one is safe to dump, else keep a space;\r\n        -- it is implied that the operation is safe for '-', because\r\n        -- current is a TK_LCOMMENT, and must be separate from a '-'\r\n        if is_faketoken[stoks[i + 1]] then\r\n          settoken()  -- remove entirely\r\n          tok = \"\"\r\n        else\r\n          settoken(\"TK_SPACE\", \" \")\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if there are embedded EOLs to keep and opt_emptylines is\r\n        -- disabled, then switch the token into one or more EOLs\r\n        if not opt_emptylines and eols > 0 then\r\n          settoken(\"TK_EOL\", rep(\"\\n\", eols))\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if optimizing whitespaces, force reinterpretation of the\r\n        -- token to give a chance for the space to be optimized away\r\n        if opt_whitespace and tok ~= \"\" then\r\n          i = i - 1  -- to reinterpret\r\n        end\r\n        ------------------------------------------------------------\r\n      else                              -- disabled case\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_EOL\" then         -- line endings\r\n      if atstart and opt_emptylines then\r\n        settoken()  -- remove entirely\r\n      elseif info == \"\\r\\n\" or info == \"\\n\\r\" then\r\n        -- normalize the rest of the EOLs for CRLF/LFCR only\r\n        -- (note that TK_LCOMMENT can change into several EOLs)\r\n        settoken(\"TK_EOL\", \"\\n\")\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_SPACE\" then       -- whitespace\r\n      if opt_whitespace then\r\n        if atstart or atlineend(i) then\r\n          -- delete leading and trailing whitespace\r\n          settoken()  -- remove entirely\r\n        else\r\n          ------------------------------------------------------------\r\n          -- at this point, since leading whitespace have been removed,\r\n          -- there should be a either a real token or a TK_LCOMMENT\r\n          -- prior to hitting this whitespace; the TK_LCOMMENT case\r\n          -- only happens if opt_comments is disabled; so prev ~= nil\r\n          local ptok = stoks[prev]\r\n          if ptok == \"TK_LCOMMENT\" then\r\n            -- previous TK_LCOMMENT can abut with anything\r\n            settoken()  -- remove entirely\r\n          else\r\n            -- prev must be a grammar token; consecutive TK_SPACE\r\n            -- tokens is impossible when optimizing whitespace\r\n            local ntok = stoks[i + 1]\r\n            if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end\r\n          end\r\n          ------------------------------------------------------------\r\n        end\r\n      end\r\n    ----------------------------------------------------------------\r\n    else\r\n      error(\"unidentified token encountered\")\r\n    end\r\n    ----------------------------------------------------------------\r\n    i = i + 1\r\n  end",
    "type": "statement:while"
  }, {
    "id": 240,
    "text": "tok, info = stoks[i], sinfos[i]",
    "type": "statement:assign"
  }, {
    "id": 241,
    "text": "local atstart = atlinestart(i)",
    "type": "statement:localassign"
  }, {
    "id": 242,
    "text": "if atstart then prev = nil end",
    "type": "statement:if"
  }, {
    "id": 243,
    "text": "prev = nil",
    "type": "statement:assign"
  }, {
    "id": 244,
    "text": "if tok == \"TK_EOS\" then             -- end of stream/pass\r\n      break\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_KEYWORD\" or       -- keywords, identifiers,\r\n           tok == \"TK_NAME\" or          -- operators\r\n           tok == \"TK_OP\" then\r\n      -- TK_KEYWORD and TK_OP can't be optimized without a big\r\n      -- optimization framework; it would be more of an optimizing\r\n      -- compiler, not a source code compressor\r\n      -- TK_NAME that are locals needs parser to analyze/optimize\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_NUMBER\" then      -- numbers\r\n      if opt_numbers then\r\n        do_number(i)  -- optimize\r\n      end\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_STRING\" or        -- strings, long strings\r\n           tok == \"TK_LSTRING\" then\r\n      if opt_strings then\r\n        if tok == \"TK_STRING\" then\r\n          do_string(i)  -- optimize\r\n        else\r\n          do_lstring(i)  -- optimize\r\n        end\r\n      end\r\n      prev = i\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_COMMENT\" then     -- short comments\r\n      if opt_comments then\r\n        if i == 1 and sub(info, 1, 1) == \"#\" then\r\n          -- keep shbang comment, trim whitespace\r\n          do_comment(i)\r\n        else\r\n          -- safe to delete, as a TK_EOL (or TK_EOS) always follows\r\n          settoken()  -- remove entirely\r\n        end\r\n      elseif opt_whitespace then        -- trim whitespace only\r\n        do_comment(i)\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_LCOMMENT\" then    -- long comments\r\n      if keep_lcomment(opt_keep, info) then\r\n        ------------------------------------------------------------\r\n        -- if --keep, we keep a long comment if <msg> is found;\r\n        -- this is a feature to keep copyright or license texts\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      elseif opt_comments then\r\n        local eols = commenteols(info)\r\n        ------------------------------------------------------------\r\n        -- prepare opt_emptylines case first, if a disposable token\r\n        -- follows, current one is safe to dump, else keep a space;\r\n        -- it is implied that the operation is safe for '-', because\r\n        -- current is a TK_LCOMMENT, and must be separate from a '-'\r\n        if is_faketoken[stoks[i + 1]] then\r\n          settoken()  -- remove entirely\r\n          tok = \"\"\r\n        else\r\n          settoken(\"TK_SPACE\", \" \")\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if there are embedded EOLs to keep and opt_emptylines is\r\n        -- disabled, then switch the token into one or more EOLs\r\n        if not opt_emptylines and eols > 0 then\r\n          settoken(\"TK_EOL\", rep(\"\\n\", eols))\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if optimizing whitespaces, force reinterpretation of the\r\n        -- token to give a chance for the space to be optimized away\r\n        if opt_whitespace and tok ~= \"\" then\r\n          i = i - 1  -- to reinterpret\r\n        end\r\n        ------------------------------------------------------------\r\n      else                              -- disabled case\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_EOL\" then         -- line endings\r\n      if atstart and opt_emptylines then\r\n        settoken()  -- remove entirely\r\n      elseif info == \"\\r\\n\" or info == \"\\n\\r\" then\r\n        -- normalize the rest of the EOLs for CRLF/LFCR only\r\n        -- (note that TK_LCOMMENT can change into several EOLs)\r\n        settoken(\"TK_EOL\", \"\\n\")\r\n      end\r\n    ----------------------------------------------------------------\r\n    elseif tok == \"TK_SPACE\" then       -- whitespace\r\n      if opt_whitespace then\r\n        if atstart or atlineend(i) then\r\n          -- delete leading and trailing whitespace\r\n          settoken()  -- remove entirely\r\n        else\r\n          ------------------------------------------------------------\r\n          -- at this point, since leading whitespace have been removed,\r\n          -- there should be a either a real token or a TK_LCOMMENT\r\n          -- prior to hitting this whitespace; the TK_LCOMMENT case\r\n          -- only happens if opt_comments is disabled; so prev ~= nil\r\n          local ptok = stoks[prev]\r\n          if ptok == \"TK_LCOMMENT\" then\r\n            -- previous TK_LCOMMENT can abut with anything\r\n            settoken()  -- remove entirely\r\n          else\r\n            -- prev must be a grammar token; consecutive TK_SPACE\r\n            -- tokens is impossible when optimizing whitespace\r\n            local ntok = stoks[i + 1]\r\n            if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end\r\n          end\r\n          ------------------------------------------------------------\r\n        end\r\n      end\r\n    ----------------------------------------------------------------\r\n    else\r\n      error(\"unidentified token encountered\")\r\n    end",
    "type": "statement:if"
  }, {
    "id": 245,
    "text": "prev = i",
    "type": "statement:assign"
  }, {
    "id": 246,
    "text": "if opt_numbers then\r\n        do_number(i)  -- optimize\r\n      end",
    "type": "statement:if"
  }, {
    "id": 247,
    "text": "do_number(i)",
    "type": "statement:functioncall"
  }, {
    "id": 248,
    "text": "if opt_strings then\r\n        if tok == \"TK_STRING\" then\r\n          do_string(i)  -- optimize\r\n        else\r\n          do_lstring(i)  -- optimize\r\n        end\r\n      end",
    "type": "statement:if"
  }, {
    "id": 249,
    "text": "if tok == \"TK_STRING\" then\r\n          do_string(i)  -- optimize\r\n        else\r\n          do_lstring(i)  -- optimize\r\n        end",
    "type": "statement:if"
  }, {
    "id": 250,
    "text": "do_string(i)",
    "type": "statement:functioncall"
  }, {
    "id": 251,
    "text": "do_lstring(i)",
    "type": "statement:functioncall"
  }, {
    "id": 252,
    "text": "if opt_comments then\r\n        if i == 1 and sub(info, 1, 1) == \"#\" then\r\n          -- keep shbang comment, trim whitespace\r\n          do_comment(i)\r\n        else\r\n          -- safe to delete, as a TK_EOL (or TK_EOS) always follows\r\n          settoken()  -- remove entirely\r\n        end\r\n      elseif opt_whitespace then        -- trim whitespace only\r\n        do_comment(i)\r\n      end",
    "type": "statement:if"
  }, {
    "id": 253,
    "text": "if i == 1 and sub(info, 1, 1) == \"#\" then\r\n          -- keep shbang comment, trim whitespace\r\n          do_comment(i)\r\n        else\r\n          -- safe to delete, as a TK_EOL (or TK_EOS) always follows\r\n          settoken()  -- remove entirely\r\n        end",
    "type": "statement:if"
  }, {
    "id": 254,
    "text": "do_comment(i)",
    "type": "statement:functioncall"
  }, {
    "id": 255,
    "text": "settoken()",
    "type": "statement:functioncall"
  }, {
    "id": 256,
    "text": "if keep_lcomment(opt_keep, info) then\r\n        ------------------------------------------------------------\r\n        -- if --keep, we keep a long comment if <msg> is found;\r\n        -- this is a feature to keep copyright or license texts\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      elseif opt_comments then\r\n        local eols = commenteols(info)\r\n        ------------------------------------------------------------\r\n        -- prepare opt_emptylines case first, if a disposable token\r\n        -- follows, current one is safe to dump, else keep a space;\r\n        -- it is implied that the operation is safe for '-', because\r\n        -- current is a TK_LCOMMENT, and must be separate from a '-'\r\n        if is_faketoken[stoks[i + 1]] then\r\n          settoken()  -- remove entirely\r\n          tok = \"\"\r\n        else\r\n          settoken(\"TK_SPACE\", \" \")\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if there are embedded EOLs to keep and opt_emptylines is\r\n        -- disabled, then switch the token into one or more EOLs\r\n        if not opt_emptylines and eols > 0 then\r\n          settoken(\"TK_EOL\", rep(\"\\n\", eols))\r\n        end\r\n        ------------------------------------------------------------\r\n        -- if optimizing whitespaces, force reinterpretation of the\r\n        -- token to give a chance for the space to be optimized away\r\n        if opt_whitespace and tok ~= \"\" then\r\n          i = i - 1  -- to reinterpret\r\n        end\r\n        ------------------------------------------------------------\r\n      else                              -- disabled case\r\n        if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end\r\n        prev = i\r\n      end",
    "type": "statement:if"
  }, {
    "id": 257,
    "text": "if opt_whitespace then          -- trim whitespace only\r\n          do_lcomment(i)\r\n        end",
    "type": "statement:if"
  }, {
    "id": 258,
    "text": "do_lcomment(i)",
    "type": "statement:functioncall"
  }, {
    "id": 259,
    "text": "local eols = commenteols(info)",
    "type": "statement:localassign"
  }, {
    "id": 260,
    "text": "if is_faketoken[stoks[i + 1]] then\r\n          settoken()  -- remove entirely\r\n          tok = \"\"\r\n        else\r\n          settoken(\"TK_SPACE\", \" \")\r\n        end",
    "type": "statement:if"
  }, {
    "id": 261,
    "text": "tok = \"\"",
    "type": "statement:assign"
  }, {
    "id": 262,
    "text": "settoken(\"TK_SPACE\", \" \")",
    "type": "statement:functioncall"
  }, {
    "id": 263,
    "text": "if not opt_emptylines and eols > 0 then\r\n          settoken(\"TK_EOL\", rep(\"\\n\", eols))\r\n        end",
    "type": "statement:if"
  }, {
    "id": 264,
    "text": "settoken(\"TK_EOL\", rep(\"\\n\", eols))",
    "type": "statement:functioncall"
  }, {
    "id": 265,
    "text": "if opt_whitespace and tok ~= \"\" then\r\n          i = i - 1  -- to reinterpret\r\n        end",
    "type": "statement:if"
  }, {
    "id": 266,
    "text": "i = i - 1",
    "type": "statement:assign"
  }, {
    "id": 267,
    "text": "if atstart and opt_emptylines then\r\n        settoken()  -- remove entirely\r\n      elseif info == \"\\r\\n\" or info == \"\\n\\r\" then\r\n        -- normalize the rest of the EOLs for CRLF/LFCR only\r\n        -- (note that TK_LCOMMENT can change into several EOLs)\r\n        settoken(\"TK_EOL\", \"\\n\")\r\n      end",
    "type": "statement:if"
  }, {
    "id": 268,
    "text": "settoken(\"TK_EOL\", \"\\n\")",
    "type": "statement:functioncall"
  }, {
    "id": 269,
    "text": "if opt_whitespace then\r\n        if atstart or atlineend(i) then\r\n          -- delete leading and trailing whitespace\r\n          settoken()  -- remove entirely\r\n        else\r\n          ------------------------------------------------------------\r\n          -- at this point, since leading whitespace have been removed,\r\n          -- there should be a either a real token or a TK_LCOMMENT\r\n          -- prior to hitting this whitespace; the TK_LCOMMENT case\r\n          -- only happens if opt_comments is disabled; so prev ~= nil\r\n          local ptok = stoks[prev]\r\n          if ptok == \"TK_LCOMMENT\" then\r\n            -- previous TK_LCOMMENT can abut with anything\r\n            settoken()  -- remove entirely\r\n          else\r\n            -- prev must be a grammar token; consecutive TK_SPACE\r\n            -- tokens is impossible when optimizing whitespace\r\n            local ntok = stoks[i + 1]\r\n            if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end\r\n          end\r\n          ------------------------------------------------------------\r\n        end\r\n      end",
    "type": "statement:if"
  }, {
    "id": 270,
    "text": "if atstart or atlineend(i) then\r\n          -- delete leading and trailing whitespace\r\n          settoken()  -- remove entirely\r\n        else\r\n          ------------------------------------------------------------\r\n          -- at this point, since leading whitespace have been removed,\r\n          -- there should be a either a real token or a TK_LCOMMENT\r\n          -- prior to hitting this whitespace; the TK_LCOMMENT case\r\n          -- only happens if opt_comments is disabled; so prev ~= nil\r\n          local ptok = stoks[prev]\r\n          if ptok == \"TK_LCOMMENT\" then\r\n            -- previous TK_LCOMMENT can abut with anything\r\n            settoken()  -- remove entirely\r\n          else\r\n            -- prev must be a grammar token; consecutive TK_SPACE\r\n            -- tokens is impossible when optimizing whitespace\r\n            local ntok = stoks[i + 1]\r\n            if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end\r\n          end\r\n          ------------------------------------------------------------\r\n        end",
    "type": "statement:if"
  }, {
    "id": 271,
    "text": "local ptok = stoks[prev]",
    "type": "statement:localassign"
  }, {
    "id": 272,
    "text": "if ptok == \"TK_LCOMMENT\" then\r\n            -- previous TK_LCOMMENT can abut with anything\r\n            settoken()  -- remove entirely\r\n          else\r\n            -- prev must be a grammar token; consecutive TK_SPACE\r\n            -- tokens is impossible when optimizing whitespace\r\n            local ntok = stoks[i + 1]\r\n            if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end\r\n          end",
    "type": "statement:if"
  }, {
    "id": 273,
    "text": "local ntok = stoks[i + 1]",
    "type": "statement:localassign"
  }, {
    "id": 274,
    "text": "if is_faketoken[ntok] then\r\n              -- handle special case where a '-' cannot abut with\r\n              -- either a short comment or a long comment\r\n              if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end\r\n            else--is_realtoken\r\n              -- check a pair of grammar tokens, if can abut, then\r\n              -- delete space token entirely, otherwise keep one space\r\n              local s = checkpair(prev, i + 1)\r\n              if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end\r\n            end",
    "type": "statement:if"
  }, {
    "id": 275,
    "text": "if (ntok == \"TK_COMMENT\" or ntok == \"TK_LCOMMENT\") and\r\n                 ptok == \"TK_OP\" and sinfos[prev] == \"-\" then\r\n                -- keep token\r\n              else\r\n                settoken()  -- remove entirely\r\n              end",
    "type": "statement:if"
  }, {
    "id": 276,
    "text": "local s = checkpair(prev, i + 1)",
    "type": "statement:localassign"
  }, {
    "id": 277,
    "text": "if s == \"\" then\r\n                settoken()  -- remove entirely\r\n              else\r\n                settoken(\"TK_SPACE\", \" \")\r\n              end",
    "type": "statement:if"
  }, {
    "id": 278,
    "text": "error(\"unidentified token encountered\")",
    "type": "statement:functioncall"
  }, {
    "id": 279,
    "text": "repack_tokens()",
    "type": "statement:functioncall"
  }, {
    "id": 280,
    "text": "if opt_eols then\r\n    i = 1\r\n    -- aggressive EOL removal only works with most non-grammar tokens\r\n    -- optimized away because it is a rather simple scheme -- basically\r\n    -- it just checks 'real' token pairs around EOLs\r\n    if stoks[1] == \"TK_COMMENT\" then\r\n      -- first comment still existing must be shbang, skip whole line\r\n      i = 3\r\n    end\r\n    while true do\r\n      tok, info = stoks[i], sinfos[i]\r\n      --------------------------------------------------------------\r\n      if tok == \"TK_EOS\" then           -- end of stream/pass\r\n        break\r\n      --------------------------------------------------------------\r\n      elseif tok == \"TK_EOL\" then       -- consider each TK_EOL\r\n        local t1, t2 = stoks[i - 1], stoks[i + 1]\r\n        if is_realtoken[t1] and is_realtoken[t2] then  -- sanity check\r\n          local s = checkpair(i - 1, i + 1)\r\n          if s == \"\" then\r\n            settoken()  -- remove entirely\r\n          end\r\n        end\r\n      end--if tok\r\n      --------------------------------------------------------------\r\n      i = i + 1\r\n    end--while\r\n    repack_tokens()\r\n  end",
    "type": "statement:if"
  }, {
    "id": 281,
    "text": "if stoks[1] == \"TK_COMMENT\" then\r\n      -- first comment still existing must be shbang, skip whole line\r\n      i = 3\r\n    end",
    "type": "statement:if"
  }, {
    "id": 282,
    "text": "i = 3",
    "type": "statement:assign"
  }, {
    "id": 283,
    "text": "while true do\r\n      tok, info = stoks[i], sinfos[i]\r\n      --------------------------------------------------------------\r\n      if tok == \"TK_EOS\" then           -- end of stream/pass\r\n        break\r\n      --------------------------------------------------------------\r\n      elseif tok == \"TK_EOL\" then       -- consider each TK_EOL\r\n        local t1, t2 = stoks[i - 1], stoks[i + 1]\r\n        if is_realtoken[t1] and is_realtoken[t2] then  -- sanity check\r\n          local s = checkpair(i - 1, i + 1)\r\n          if s == \"\" then\r\n            settoken()  -- remove entirely\r\n          end\r\n        end\r\n      end--if tok\r\n      --------------------------------------------------------------\r\n      i = i + 1\r\n    end",
    "type": "statement:while"
  }, {
    "id": 284,
    "text": "if tok == \"TK_EOS\" then           -- end of stream/pass\r\n        break\r\n      --------------------------------------------------------------\r\n      elseif tok == \"TK_EOL\" then       -- consider each TK_EOL\r\n        local t1, t2 = stoks[i - 1], stoks[i + 1]\r\n        if is_realtoken[t1] and is_realtoken[t2] then  -- sanity check\r\n          local s = checkpair(i - 1, i + 1)\r\n          if s == \"\" then\r\n            settoken()  -- remove entirely\r\n          end\r\n        end\r\n      end",
    "type": "statement:if"
  }, {
    "id": 285,
    "text": "local t1, t2 = stoks[i - 1], stoks[i + 1]",
    "type": "statement:localassign"
  }, {
    "id": 286,
    "text": "if is_realtoken[t1] and is_realtoken[t2] then  -- sanity check\r\n          local s = checkpair(i - 1, i + 1)\r\n          if s == \"\" then\r\n            settoken()  -- remove entirely\r\n          end\r\n        end",
    "type": "statement:if"
  }, {
    "id": 287,
    "text": "local s = checkpair(i - 1, i + 1)",
    "type": "statement:localassign"
  }, {
    "id": 288,
    "text": "if s == \"\" then\r\n            settoken()  -- remove entirely\r\n          end",
    "type": "statement:if"
  }, {
    "id": 289,
    "text": "if opt_details and opt_details > 0 then print() end",
    "type": "statement:if"
  }, {
    "id": 290,
    "text": "print()",
    "type": "statement:functioncall"
  }, {
    "id": 291,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 292,
    "text": "local function settoken(tok, info, I)\r\n    I = I or i\r\n    stoks[I] = tok or \"\"\r\n    sinfos[I] = info or \"\"\r\n  end",
    "type": "function"
  }, {
    "id": 293,
    "text": "",
    "type": "blank lines"
  }, {
    "id": 294,
    "text": "",
    "type": "function container"
  }, {
    "id": 295,
    "text": "function minify_string(dat)\r\n\tllex.init(dat)\r\n\tllex.llex()\r\n\tlocal toklist, seminfolist, toklnlist\r\n\t= llex.tok, llex.seminfo, llex.tokln\r\n\tif option[\"opt-locals\"] then\r\n\t\toptparser.print = print  -- hack\r\n\t\tlparser.init(toklist, seminfolist, toklnlist)\r\n\t\tlocal globalinfo, localinfo = lparser.parser()\r\n\t\toptparser.optimize(option, toklist, seminfolist, globalinfo, localinfo)\r\n\tend\r\n\toptlex.print = print  -- hack\r\n\ttoklist, seminfolist, toklnlist\r\n\t\t= optlex.optimize(option, toklist, seminfolist, toklnlist)\r\n\tlocal dat = table.concat(seminfolist)\r\n\t-- depending on options selected, embedded EOLs in long strings and\r\n\t-- long comments may not have been translated to \\n, tack a warning\r\n\tif string.find(dat, \"\\r\\n\", 1, 1) or\r\n\t\tstring.find(dat, \"\\n\\r\", 1, 1) then\r\n\t\toptlex.warn.mixedeol = true\r\n\tend\r\n\treturn dat;\r\nend",
    "type": "function"
  }, {
    "id": 296,
    "text": "string",
    "type": "module"
  }, {
    "id": 297,
    "text": "char",
    "type": "global function"
  }, {
    "id": 298,
    "text": "match",
    "type": "global function"
  }, {
    "id": 299,
    "text": "rep",
    "type": "global function"
  }, {
    "id": 300,
    "text": "print",
    "type": "global function"
  }, {
    "id": 301,
    "text": "tostring",
    "type": "global function"
  }, {
    "id": 302,
    "text": "module",
    "type": "global function"
  }, {
    "id": 303,
    "text": "find",
    "type": "global function"
  }, {
    "id": 304,
    "text": "error",
    "type": "global function"
  }, {
    "id": 305,
    "text": "sub",
    "type": "global function"
  }, {
    "id": 306,
    "text": "tonumber",
    "type": "global function"
  }, {
    "id": 307,
    "text": "require",
    "type": "global function"
  }, {
    "id": 308,
    "text": "",
    "type": "variable container"
  }, {
    "id": 309,
    "text": "",
    "type": "require container"
  }, {
    "id": 310,
    "text": "",
    "type": "local variable"
  }, {
    "id": 311,
    "text": "",
    "type": "n/a"
  }, {
    "id": 312,
    "text": "",
    "type": "local variable"
  }, {
    "id": 313,
    "text": "",
    "type": "n/a"
  }, {
    "id": 314,
    "text": "",
    "type": "local variable"
  }, {
    "id": 315,
    "text": "",
    "type": "n/a"
  }, {
    "id": 316,
    "text": "",
    "type": "local variable"
  }, {
    "id": 317,
    "text": "",
    "type": "n/a"
  }, {
    "id": 318,
    "text": "",
    "type": "local variable"
  }, {
    "id": 319,
    "text": "",
    "type": "n/a"
  }, {
    "id": 320,
    "text": "",
    "type": "local variable"
  }, {
    "id": 321,
    "text": "",
    "type": "local variable"
  }, {
    "id": 322,
    "text": "",
    "type": "local variable"
  }, {
    "id": 323,
    "text": "",
    "type": "local variable"
  }, {
    "id": 324,
    "text": "",
    "type": "local variable"
  }, {
    "id": 325,
    "text": "",
    "type": "tableconstructor"
  }, {
    "id": 326,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 327,
    "text": "",
    "type": "boolean"
  }, {
    "id": 328,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 329,
    "text": "",
    "type": "boolean"
  }, {
    "id": 330,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 331,
    "text": "",
    "type": "boolean"
  }, {
    "id": 332,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 333,
    "text": "",
    "type": "boolean"
  }, {
    "id": 334,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 335,
    "text": "",
    "type": "boolean"
  }, {
    "id": 336,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 337,
    "text": "",
    "type": "boolean"
  }, {
    "id": 338,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 339,
    "text": "",
    "type": "boolean"
  }, {
    "id": 340,
    "text": "",
    "type": "local variable"
  }, {
    "id": 341,
    "text": "",
    "type": "tableconstructor"
  }, {
    "id": 342,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 343,
    "text": "",
    "type": "boolean"
  }, {
    "id": 344,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 345,
    "text": "",
    "type": "boolean"
  }, {
    "id": 346,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 347,
    "text": "",
    "type": "boolean"
  }, {
    "id": 348,
    "text": "",
    "type": "table assign node"
  }, {
    "id": 349,
    "text": "",
    "type": "boolean"
  }, {
    "id": 350,
    "text": "",
    "type": "local variable"
  }, {
    "id": 351,
    "text": "",
    "type": "global variable"
  }, {
    "id": 352,
    "text": "",
    "type": "n/a"
  }, {
    "id": 353,
    "text": "",
    "type": "global variable"
  }, {
    "id": 354,
    "text": "",
    "type": "n/a"
  }, {
    "id": 355,
    "text": "",
    "type": "require local variable"
  }, {
    "id": 356,
    "text": "",
    "type": "require local variable"
  } ]
}